#!/usr/bin/env bash
KUBASH_VERSION='v1.12.2'
# set default fall-through variables
# if set in the environment these variables will fall-through and retain their value
# otherwise use the defaults here
: ${KUBE_VERSION:='v1.12.2'}
: ${KUBE_MAJOR_VER:=1}
: ${KUBE_MINOR_VER:=12}
: ${KUBASH_CLUSTER_NAME=default}
: ${KUBASH_DIR:=$HOME/.kubash}
: ${KUBASH_HISTORY:=$KUBASH_DIR/.kubash_history}
: ${KUBASH_HISTORY_LIMIT:=5000}
: ${KUBASH_BIN:=$KUBASH_DIR/bin}
: ${KUBASH_CLUSTERS_DIR:=$KUBASH_DIR/clusters}
: ${KUBASH_CLUSTER_DIR:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME}
: ${KUBASH_CSV_VER_FILE:=$KUBASH_CLUSTER_DIR/csv_version}
: ${KUBASH_CLUSTER_CONFIG:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/config}
: ${KUBASH_HOSTS_CSV:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/hosts.csv}
: ${KUBASH_ANSIBLE_HOSTS:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/hosts}
: ${KUBASH_PROVISION_CSV:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/provision.csv}
: ${KUBASH_USERS_CSV:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/users.csv}
: ${KUBASH_INGRESS_NAME:='kubashingress'}
: ${KUBASH_OIDC_AUTH:='false'}
#: ${KUBEADMIN_IGNORE_PREFLIGHT_CHECKS:='--ignore-preflight-errors cri'}
: ${KUBEADMIN_IGNORE_PREFLIGHT_CHECKS:='--ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-etcd.yaml,ExternalEtcdVersion,cri'}
: ${VERBOSITY:=0}
: ${KVM_builderBasePath:=/var/lib/libvirt/images}
: ${KVM_builderHost:=localhost}
: ${KVM_builderPort:=22}
: ${KVM_builderUser:=coopadmin}
: ${KVM_builderTMP:=$KVM_builderBasePath/kubashtmp}
: ${KVM_builderDir:=$KVM_builderBasePath/kubashbuilds}
: ${KVM_BASE_IMG:=kubash.qcow2}
: ${KVM_RAM:=4096}
: ${KVM_CPU:=2}
: ${KVM_NET:='default'}
: ${PSEUDO:=sudo}
: ${K8S_user:=root}
: ${K8S_SU_USER:=coopadmin}
: ${K8S_NET:=calico}
: ${K8S_provisionerPort:=22}
: ${K8S_SU_PATH:='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin'}
: ${my_DOMAIN:=example.com}
: ${GOPATH:=~/.go}
: ${KUTIME:="/usr/bin/time -v"}
: ${PARALLEL_JOBS:=5}
: ${PARALLEL:="parallel"}
: ${OPENSHIFT_REGION:=lab}
: ${OPENSHIFT_ZONE:=baremetal}
: ${MASTERS_AS_ETCD:='true'}
: ${BROADCAST_TO_NETWORK:='10.0.23.0/24'}
: ${INTERFACE_NET:='eth0'}
: ${DO_KEEPALIVED:='false'}
: ${DO_CRICTL:='true'}
: ${ETCD_VERSION:=v3.2.7}
: ${ETCD_TLS:='true'}
: ${KUBASH_RSYNC_OPTS:='-L -H -aze'}
: ${CALICO_VER:=v3.3}
: ${CALICO_URL:=https://docs.projectcalico.org/$CALICO_VER/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml}
: ${CALICO_RBAC_URL:=https://docs.projectcalico.org/$CALICO_VER/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml}
: ${FLANNEL_URL:=https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml}
: ${USE_TRAEFIK_DAEMON_SET:='true'}
: ${USE_TRAEFIK_RBAC:='true'}
: ${VOYAGER_PROVIDER:='baremetal'}
: ${VOYAGER_BY_HELM:= "false"}
: ${VOYAGER_ADMISSIONWEBHOOK:='--set apiserver.enableAdmissionWebhook=true'}
: ${LINKERD_URL:='https://raw.githubusercontent.com/linkerd/linkerd-examples/master/k8s-daemonset/k8s/linkerd-ingress-controller.yml'}
: ${TAB_1:='  '}
: ${TAB_2:='    '}
: ${TAB_3:='      '}
: ${TAB_4:='        '}

set -e

net_set () {
  # Set networking defaults
  if [[ -e "$KUBASH_CLUSTER_DIR/net_set" ]]; then
    K8S_NET=$(cat $KUBASH_CLUSTER_DIR/net_set)
  fi
  if [[ "$K8S_NET" == "calico" ]]; then
    my_KUBE_CIDR="192.168.0.0/16"
  elif [[ "$K8S_NET" == "flannel" ]]; then
    my_KUBE_CIDR="10.244.0.0/16"
  else
    horizontal_rule
    echo 'unknown pod network'
    exit 1
  fi
}

net_set

export KUBECONFIG=$KUBASH_CLUSTER_CONFIG
# Rasion d etre
RAISON=false

# global vars
ANSWER_YES=no
print_help=no

user_csv_columns="user_email user_role"
uniq_hosts_list_columns="K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt"

set_csv_columns () {
  squawk 125 "prep the columns strings for csv input"
  if [ ! -z "$1" ]; then
    KUBASH_CSV_VER=$1
  else
    KUBASH_CSV_VER=$(cat $KUBASH_CSV_VER_FILE)
  fi
  if [ "$KUBASH_CSV_VER" = '2.0.0' ]; then
    csv_columns="K8S_node K8S_role K8S_cpuCount K8S_Memory K8S_sshPort K8S_network1 K8S_mac1 K8S_ip1 K8S_routingprefix1 K8S_subnetmask1 K8S_broadcast1 K8S_gateway1 K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt K8S_network2 K8S_mac2 K8S_ip2 K8S_routingprefix2 K8S_subnetmask2 K8S_broadcast2 K8S_gateway2 K8S_network3 K8S_mac3 K8S_ip3 K8S_routingprefix3 K8S_subnetmask3 K8S_broadcast3 K8S_gateway3"
  elif [ "$KUBASH_CSV_VER" = '1.0.0' ]; then
    csv_columns="K8S_node K8S_role K8S_cpuCount K8S_Memory K8S_sshPort K8S_network1 K8S_mac1 K8S_ip1 K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt K8S_network2 K8S_mac2 K8S_ip2 K8S_network3 K8S_mac3 K8S_ip3"
  else
    echo 'CSV columns cannot be set CSV Version not recognized'
    exit 1
  fi
}

squawk () {
  # This function simplifies error reporting and verbosity
  # call it by preceding your message with a verbosity level
  # e.g. `squawk 3 "This is a squawk"`
  # if the current verbosity level is greater than or equal to
  # the number given then this function will echo out your message
  # and pad it with # to let you now how verbose that message was
  squawk_lvl=$1
  shift
  squawk=$1
  shift
  squawk_opt=$@

  if [[ "$VERBOSITY" -ge "$squawk_lvl" ]] ; then
    if [[ "$squawk_lvl" -le 20 ]] ; then
      count_squawk=0
      while [[ "$count_squawk" -lt "$squawk_lvl" ]]; do
        echo -n "#"
        count_squawk=`expr $count_squawk + 1`
      done
      echo " $squawk"
    else
      echo -n '#{ '
      echo -n "$squawk_lvl"
      echo -n " }#############"
      count_squawk=0
      while [[ "$count_squawk" -lt "$squawk_lvl" ]]; do
        echo -n "#"
        count_squawk=`expr $count_squawk + 5`
      done
      echo -n '#{ '
      echo -n "$squawk_lvl"
      echo -n ' }### '
      echo " $squawk"
    fi
  fi
}

grab_kube_pki_ext_etcd_sub () {
  grab_sub_USER=$1
  grab_sub_HOST=$2
  grab_sub_PORT=$3
  # Make a list of required etcd certificate files for subsequent masters
  # break indentation
    command2run='cat << EOF > sub-pki-files.txt
/etc/kubernetes/pki/ca.crt
/etc/kubernetes/pki/ca.key
/etc/kubernetes/pki/sa.key
/etc/kubernetes/pki/sa.pub
/etc/kubernetes/pki/front-proxy-ca.crt
/etc/kubernetes/pki/front-proxy-ca.key
EOF'
  # unbreak indentation

  squawk 55 "ssh ${grab_sub_USER}@${grab_sub_HOST} $command2run"
  sudo_command ${grab_sub_PORT} ${grab_sub_USER} ${grab_sub_HOST} "$command2run"

  # create the archive
  command2run="tar -czf /tmp/sub-pki.tar.gz -T sub-pki-files.txt"
  sudo_command ${grab_sub_PORT} ${grab_sub_USER} ${grab_sub_HOST} "$command2run"
  squawk 55 "scp -P ${grab_sub_PORT} ${grab_sub_USER}@${grab_sub_HOST}/tmp/sub-pki.tar.gz ${KUBASH_CLUSTER_DIR}/sub-pki.tar.gz"
  scp -P ${grab_sub_PORT} ${grab_sub_USER}@${grab_sub_HOST}:/tmp/sub-pki.tar.gz ${KUBASH_CLUSTER_DIR}/sub-pki.tar.gz
  command2run="rm /tmp/sub-pki.tar.gz"
}

grab_kube_pki_stacked_method () {
  grab_USER=$1
  grab_HOST=$2
  grab_PORT=$3
  # Make a list of required etcd certificate files
  # break indentation
    command2run='cat << EOF > kube-pki-files.txt
/etc/kubernetes/pki/ca.crt
/etc/kubernetes/pki/ca.key
/etc/kubernetes/pki/sa.key
/etc/kubernetes/pki/sa.pub
/etc/kubernetes/pki/front-proxy-ca.crt
/etc/kubernetes/pki/front-proxy-ca.key
/etc/kubernetes/pki/etcd/ca.crt
/etc/kubernetes/pki/etcd/ca.key
/etc/kubernetes/admin.conf
EOF'
  # unbreak indentation
#/etc/kubernetes/controller-manager.conf
#/etc/kubernetes/scheduler.conf

  squawk 55 "ssh ${grab_USER}@${grab_HOST} $command2run"
  sudo_command ${grab_PORT} ${grab_USER} ${grab_HOST} "$command2run"

  # create the archive
  command2run="tar -czf /tmp/kube-pki.tar.gz -T kube-pki-files.txt"
  sudo_command ${grab_PORT} ${grab_USER} ${grab_HOST} "$command2run"
  squawk 55 "scp -P ${grab_PORT} ${grab_USER}@${grab_HOST}/tmp/kube-pki.tar.gz ${KUBASH_CLUSTER_DIR}/kube-pki.tar.gz"
  scp -P ${grab_PORT} ${grab_USER}@${grab_HOST}:/tmp/kube-pki.tar.gz ${KUBASH_CLUSTER_DIR}/kube-pki.tar.gz
  command2run="rm /tmp/kube-pki.tar.gz"
  #sudo_command ${grab_PORT} ${grab_USER} ${grab_HOST} "$command2run"
}

push_kube_pki_stacked_method () {
  push_USER=$1
  push_HOST=$2
  push_PORT=$3
  squawk 9 "rsync $KUBASH_RSYNC_OPTS ssh -p $push_PORT ${KUBASH_CLUSTER_DIR}/kube-pki.tar.gz $push_USER@$push_HOST:/tmp/"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $push_PORT" ${KUBASH_CLUSTER_DIR}/kube-pki.tar.gz $push_USER@$push_HOST:/tmp/
  #command2run='mkdir -p /etc/kubernetes/pki && tar -xzvf /tmp/kube-pki.tar.gz -C /etc/kubernetes/pki --strip-components=3'
  command2run='mkdir -p /etc/kubernetes/pki && cd / && tar -xzvf /tmp/kube-pki.tar.gz'
  sudo_command ${push_PORT} ${push_USER} ${push_HOST} "$command2run"
  command2run='rm /tmp/kube-pki.tar.gz'
  #sudo_command ${push_PORT} ${push_USER} ${push_HOST} "$command2run"
}

push_kube_pki_ext_etcd_sub () {
  push_sub_USER=$1
  push_sub_HOST=$2
  push_sub_PORT=$3
  squawk 9 "rsync $KUBASH_RSYNC_OPTS ssh -p $push_sub_PORT ${KUBASH_CLUSTER_DIR}/sub-pki.tar.gz $push_sub_USER@$push_sub_HOST:/tmp/"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $push_sub_PORT" ${KUBASH_CLUSTER_DIR}/sub-pki.tar.gz $push_sub_USER@$push_sub_HOST:/tmp/
  command2run='mkdir -p /etc/kubernetes/pki && cd / && tar -xzvf /tmp/sub-pki.tar.gz'
  sudo_command ${push_sub_PORT} ${push_sub_USER} ${push_sub_HOST} "$command2run"
  command2run='rm /tmp/sub-pki.tar.gz'
  #sudo_command ${push_sub_PORT} ${push_sub_USER} ${push_sub_HOST} "$command2run"
}

grab_pki_ext_etcd_method () {
  grab_pki_ext_etcdUSER=$1
  grab_pki_ext_etcdHOST=$2
  grab_pki_ext_etcdPORT=$3
  # Make a list of required etcd certificate files
  # break indentation
    command2run='cat << EOF > etcd-pki-files.txt
/etc/kubernetes/pki/etcd/ca.crt
/etc/kubernetes/pki/apiserver-etcd-client.crt
/etc/kubernetes/pki/apiserver-etcd-client.key
EOF'
  # unbreak indentation
  squawk 55 "ssh ${grab_pki_ext_etcdUSER}@${grab_pki_ext_etcdHOST} $command2run"
  sudo_command ${grab_pki_ext_etcdPORT} ${grab_pki_ext_etcdUSER} ${grab_pki_ext_etcdHOST} "$command2run"

  # create the archive
  command2run="tar -czf /tmp/etcd-pki.tar.gz -T etcd-pki-files.txt"
  sudo_command ${grab_pki_ext_etcdPORT} ${grab_pki_ext_etcdUSER} ${grab_pki_ext_etcdHOST} "$command2run"
  squawk 55 "scp -P ${grab_pki_ext_etcdPORT} ${grab_pki_ext_etcdUSER}@${grab_pki_ext_etcdHOST}/tmp/etcd-pki.tar.gz ${KUBASH_CLUSTER_DIR}/etcd-pki.tar.gz"
  scp -P ${grab_pki_ext_etcdPORT} ${grab_pki_ext_etcdUSER}@${grab_pki_ext_etcdHOST}:/tmp/etcd-pki.tar.gz ${KUBASH_CLUSTER_DIR}/etcd-pki.tar.gz
  command2run="rm /tmp/etcd-pki.tar.gz"
  sudo_command ${grab_pki_ext_etcdPORT} ${grab_pki_ext_etcdUSER} ${grab_pki_ext_etcdHOST} "$command2run"
}

push_pki_ext_etcd_method () {
  push_pki_ext_etcd_USER=$1
  push_pki_ext_etcd_HOST=$2
  push_pki_ext_etcd_PORT=$3
  squawk 9 "rsync $KUBASH_RSYNC_OPTS ssh -p $push_pki_ext_etcd_PORT ${KUBASH_CLUSTER_DIR}/etcd-pki.tar.gz $push_pki_ext_etcd_USER@$push_pki_ext_etcd_HOST:/tmp/"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $push_pki_ext_etcd_PORT" ${KUBASH_CLUSTER_DIR}/etcd-pki.tar.gz $push_pki_ext_etcd_USER@$push_pki_ext_etcd_HOST:/tmp/
  #command2run='mkdir -p /etc/kubernetes/pki && tar -xzvf /tmp/etcd-pki.tar.gz -C /etc/kubernetes/pki --strip-components=3'
  command2run='mkdir -p /etc/kubernetes/pki && cd / && tar -xzvf /tmp/etcd-pki.tar.gz'
  sudo_command ${push_pki_ext_etcd_PORT} ${push_pki_ext_etcd_USER} ${push_pki_ext_etcd_HOST} "$command2run"
  command2run='rm /tmp/etcd-pki.tar.gz'
  sudo_command ${push_pki_ext_etcd_PORT} ${push_pki_ext_etcd_USER} ${push_pki_ext_etcd_HOST} "$command2run"
}

determine_api_version () {
  if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
    squawk 20 'Major Version 1'
    if [[ $KUBE_MINOR_VER -lt 9 ]]; then
      echo "$KUBE_MINOR_VER is too old may not ever be supported"
      exit 1
    elif [[ $KUBE_MINOR_VER -eq 11 ]]; then
      squawk 75 kubeadm_apiVersion="kubeadm.k8s.io/v1alpha2"
      export kubeadm_apiVersion="kubeadm.k8s.io/v1alpha2"
      kubeadm_cfg_kind=MasterConfiguration
    elif [[ $KUBE_MINOR_VER -eq 12 ]]; then
      squawk 75 kubeadm_apiVersion="kubeadm.k8s.io/v1alpha3"
      export kubeadm_apiVersion="kubeadm.k8s.io/v1alpha3"
      kubeadm_cfg_kind=ClusterConfiguration
    else
      echo "$KUBE_MINOR_VER not supported yet"
      exit 1
    fi
  elif [[ $MAJOR_VER -eq 0 ]]; then
    squawk 1 'Major Version 0 unsupported'
    exit 1
  else
    squawk 1 'Major Version Unknown'
    exit 1
  fi
}

etcd_kubernetes_ext_etcd_method () {
  etcd_test_tmp=$(mktemp -d)
  INIT_USER=root
  #my_KUBE_CIDR="10.244.0.0/16"
  set_csv_columns
  etc_count_zero=0
  master_count_zero=0
  node_count_zero=0
  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' || "$K8S_role" == 'primary_etcd' ]]; then
        ETCDHOSTS[$etc_count_zero]=$K8S_ip1
        ETCDNAMES[$etc_count_zero]=$K8S_node
        ETCDPORTS[$etc_count_zero]=$K8S_sshPort
        MASTERHOSTS[$master_count_zero]=$K8S_ip1
        MASTERNAMES[$master_count_zero]=$K8S_node
        MASTERPORTS[$master_count_zero]=$K8S_sshPort
        ((++etc_count_zero))
        ((++master_count_zero))
      elif [[ "$K8S_role" == 'node' ]]; then
        NODEHOSTS[$node_count_zero]=$K8S_ip1
        NODENAMES[$node_count_zero]=$K8S_node
        NODEPORTS[$node_count_zero]=$K8S_sshPort
        ((++node_count_zero))
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        ETCDHOSTS[$etc_count_zero]=$K8S_ip1
        ETCDNAMES[$etc_count_zero]=$K8S_node
        ETCDPORTS[$etc_count_zero]=$K8S_sshPort
        ((++etc_count_zero))
      elif [[ "$K8S_role" == 'node' ]]; then
        NODEHOSTS[$node_count_zero]=$K8S_ip1
        NODENAMES[$node_count_zero]=$K8S_node
        NODEPORTS[$node_count_zero]=$K8S_sshPort
        ((++node_count_zero))
      elif [[ "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        MASTERHOSTS[$master_count_zero]=$K8S_ip1
        MASTERNAMES[$master_count_zero]=$K8S_node
        MASTERPORTS[$master_count_zero]=$K8S_sshPort
        ((++master_count_zero))
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"
  echo $ETCDHOSTS
  sleep 33
  get_major_minor_kube_version $K8S_user ${MASTERHOSTS[0]} ${MASTERNAMES[0]} ${MASTERPORTS[0]}
  determine_api_version

  echo -n "            initial-cluster: " > $etcd_test_tmp/initial-cluster.head
  count_etcd=0
  countetcdnodes=0
  while IFS="," read -r $csv_columns
  do
    echo "- \"${K8S_ip1}\"" >> $etcd_test_tmp/apiservercertsans.line
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        if [[ $countetcdnodes -gt 0 ]]; then
          printf ',' >> $etcd_test_tmp/initial-cluster.line
        fi
        if [[ "$ETCD_TLS" == 'true' ]]; then
          printf "${K8S_node}=https://${K8S_ip1}:2380" >> $etcd_test_tmp/initial-cluster.line
          echo "      - https://${K8S_ip1}:2379" >> $etcd_test_tmp/endpoints.line
        else
          printf "${K8S_node}=https://${K8S_ip1}:2380" >> $etcd_test_tmp/initial-cluster.line
          echo "      - https://${K8S_ip1}:2379" >> $etcd_test_tmp/endpoints.line
          #printf "${K8S_node}=http://${K8S_ip1}:2380" >> $etcd_test_tmp/initial-cluster.line
          #echo "      - http://${K8S_ip1}:2379" >> $etcd_test_tmp/endpoints.line
        fi
        ((++countetcdnodes))
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        if [[ $countetcdnodes -gt 0 ]]; then
          printf ',' >> $etcd_test_tmp/initial-cluster.line
        fi
        if [[ "$ETCD_TLS" == 'true' ]]; then
          printf "${K8S_node}=https://${K8S_ip1}:2380" >> $etcd_test_tmp/initial-cluster.line
          echo "      - https://${K8S_ip1}:2379" >> $etcd_test_tmp/endpoints.line
        else
          printf "${K8S_node}=https://${K8S_ip1}:2380" >> $etcd_test_tmp/initial-cluster.line
          echo "      - https://${K8S_ip1}:2379" >> $etcd_test_tmp/endpoints.line
          #printf "${K8S_node}=http://${K8S_ip1}:2380" >> $etcd_test_tmp/initial-cluster.line
          #echo "      - http://${K8S_ip1}:2379" >> $etcd_test_tmp/endpoints.line
        fi
        ((++countetcdnodes))
      fi
    fi
    ((++count_etcd))
  done <<< "$kubash_hosts_csv_slurped"
  if [[ "$ETCD_TLS" == 'true' ]]; then
    echo '      caFile: /etc/kubernetes/pki/etcd/ca.crt
      certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
      keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key' \
    >> $etcd_test_tmp/endpoints.line
  else
    echo '      caFile: /etc/kubernetes/pki/etcd/ca.crt
      certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
      keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key' \
    >> $etcd_test_tmp/endpoints.line
  fi
  printf " \n" >> $etcd_test_tmp/initial-cluster.line
  initial_cluster_line=$(cat $etcd_test_tmp/initial-cluster.head $etcd_test_tmp/initial-cluster.line)
  api_server_cert_sans_line=$(cat $etcd_test_tmp/apiservercertsans.line)
  endpoints_line=$(cat $etcd_test_tmp/endpoints.line)
  rm $etcd_test_tmp/initial-cluster.head $etcd_test_tmp/initial-cluster.line $etcd_test_tmp/apiservercertsans.line $etcd_test_tmp/endpoints.line

  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    # Create temp directories to store files that will end up on other hosts.
    squawk 55 "mkdir -p $etcd_test_tmp/${HOST}/"
    mkdir -p $etcd_test_tmp/${HOST}/

    # break indentation
    command2run='cat << EOF > /etc/systemd/system/kubelet.service.d/20-etcd-service-manager.conf
[Service]
ExecStart=
ExecStart=/usr/bin/kubelet --address=127.0.0.1 --pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true
Restart=always
EOF'
    # unbreak indentation

    squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    ssh ${INIT_USER}@${HOST} "$command2run"

    # break indentation
    #command2run='cat << EOF > /var/lib/kubelet/config.yaml
  #kind: KubeletConfiguration
  #apiVersion: kubelet.config.k8s.io/v1beta1
  #address: 127.0.0.1
  #staticpodpath: /etc/kubernetes/manifests
  #EOF'
    # unbreak indentation
    #squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    #ssh ${INIT_USER}@${HOST} "$command2run"
  done

  for i in "${!MASTERHOSTS[@]}"; do
    HOST=${MASTERHOSTS[$i]}
    squawk 55 "mkdir -p $etcd_test_tmp/${HOST}/"
    mkdir -p $etcd_test_tmp/${HOST}/
    # break indentation
    #command2run='cat << EOF > /etc/systemd/system/kubelet.service.d/20-etcd-service-manager.conf
#[Service]
#ExecStart=
#ExecStart=/usr/bin/kubelet --address=127.0.0.1 --pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true
#Restart=always
#EOF'
    ## unbreak indentation
    #squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    #ssh ${INIT_USER}@${HOST} "$command2run"
  done


  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    NAME=${ETCDNAMES[$i]}
    cat << EOF > $etcd_test_tmp/${HOST}/kubeadmcfg.yaml
apiVersion: "$kubeadm_apiVersion"
kind: $kubeadm_cfg_kind
etcd:
    local:
        serverCertSANs:
        - "${HOST}"
        peerCertSANs:
        - "${HOST}"
        extraArgs:
$initial_cluster_line
            initial-cluster-state: new
            name: ${NAME}
EOF
  if [[ "$ETCD_TLS" == 'true' ]]; then
    echo "            listen-peer-urls: https://${HOST}:2380
            listen-client-urls: https://${HOST}:2379
            advertise-client-urls: https://${HOST}:2379
            initial-advertise-peer-urls: https://${HOST}:2380" \
     >> $etcd_test_tmp/${HOST}/kubeadmcfg.yaml
  elif [[ "$ETCD_TLS" == 'calamazoo' ]]; then
    # neutered
    echo "            listen-peer-urls: http://${HOST}:2380
            listen-client-urls: http://${HOST}:2379
            advertise-client-urls: http://${HOST}:2379
            initial-advertise-peer-urls: http://${HOST}:2380" \
     >> $etcd_test_tmp/${HOST}/kubeadmcfg.yaml
  else
    echo "            listen-peer-urls: https://${HOST}:2380
            listen-client-urls: https://${HOST}:2379
            advertise-client-urls: https://${HOST}:2379
            initial-advertise-peer-urls: https://${HOST}:2380" \
     >> $etcd_test_tmp/${HOST}/kubeadmcfg.yaml
  fi
    command2run='systemctl daemon-reload'
    squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    ssh ${INIT_USER}@${HOST} "$command2run"
    command2run='systemctl restart kubelet'
    squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    ssh ${INIT_USER}@${HOST} "$command2run"
  done
  for i in "${!MASTERHOSTS[@]}"; do
    HOST=${MASTERHOSTS[$i]}
    NAME=${MASTERNAMES[$i]}
    if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
      if [[ $KUBE_MINOR_VER -gt 11 ]]; then
       if [[ $SEMAPHORE_FLAG_KILL = 'not_gonna_be_it' ]]; then
        cat << EOF > $etcd_test_tmp/${HOST}/kubeadmcfg.yaml
apiVersion: $kubeadm_apiVersion
kind: InitConfiguration
apiEndpoint:
  advertiseAddress: ${HOST}
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: ${NAME}
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
EOF
      fi
     fi
   fi
    cat << EOF >> $etcd_test_tmp/${HOST}/kubeadmcfg.yaml
apiVersion: $kubeadm_apiVersion
kind: $kubeadm_cfg_kind
apiServerCertSANs:
- "127.0.0.1"
$api_server_cert_sans_line
controlPlaneEndpoint: "${MASTERHOSTS[0]}:6443"
etcd:
  external:
      endpoints:
$endpoints_line
networking:
  podSubnet: $my_KUBE_CIDR
EOF
    command2run='systemctl daemon-reload'
    squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    ssh ${INIT_USER}@${HOST} "$command2run"
    #command2run='systemctl restart kubelet'
    #squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    #ssh ${INIT_USER}@${HOST} "$command2run"
  done

  command2run='kubeadm alpha phase certs etcd-ca'
  squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
  ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"

  squawk 5 "copy pki directory to host 0"
  command2run='tar zcf - pki'
  PREV_PWD=$(pwd)
  cd $etcd_test_tmp/${ETCDHOSTS[0]}/
  squawk 56 "ssh ${INIT_USER}@${HOST} cd /etc/kubernetes;$command2run|tar pzxvf -"
  ssh ${INIT_USER}@${ETCDHOSTS[0]} "cd /etc/kubernetes;$command2run"|tar pzxvf -
  cd $PREV_PWD

  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    PREV_PWD=$(pwd)
    cd $etcd_test_tmp/
    squawk 55 "tar zcf - ${HOST} | ssh ${INIT_USER}@${ETCDHOSTS[0]} cd /tmp; tar pzxvf -"
    tar zcf - ${HOST} | ssh ${INIT_USER}@${ETCDHOSTS[0]} "cd /tmp; tar pzxvf -"
    cd $PREV_PWD
  done

  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    command2run="kubeadm alpha phase certs etcd-server --config=/tmp/${HOST}/kubeadmcfg.yaml"
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
    command2run="kubeadm alpha phase certs etcd-peer --config=/tmp/${HOST}/kubeadmcfg.yaml"
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
    command2run="kubeadm alpha phase certs etcd-healthcheck-client --config=/tmp/${HOST}/kubeadmcfg.yaml"
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
    command2run="kubeadm alpha phase certs apiserver-etcd-client --config=/tmp/${HOST}/kubeadmcfg.yaml"
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
    command2run="rsync -a /etc/kubernetes/pki /tmp/${HOST}/"
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
    squawk 5 "cleanup non-reusable certificates"
    command2run="find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete"
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
    squawk 5 "clean up certs that should not be copied off this host"
    command2run="find /tmp/${HOST} -name ca.key -type f -delete"
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} $command2run"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
    #if [[ $i -eq 0 ]]; then
      #grab_pki_ext_etcd_method $K8S_user ${ETCDHOSTS[0]} ${ETCDPORTS[0]}
    #fi
  done

  squawk 5 "gather the pki and configs"
  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    PREV_PWD=$(pwd)
    cd $etcd_test_tmp/
    squawk 55 "ssh ${INIT_USER}@${ETCDHOSTS[0]} cd /tmp;tar zcf - ${HOST} | tar pzxvf -"
    ssh ${INIT_USER}@${ETCDHOSTS[0]} "cd /tmp;tar zcf - ${HOST}" | tar pzxvf -
    cd $PREV_PWD
  done
  squawk 5 "distribute the pki and configs to etcd hosts"
  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    PREV_PWD=$(pwd)
    cd $etcd_test_tmp/${HOST}
    squawk 55 "tar zcf - pki | ssh ${INIT_USER}@${HOST} cd /etc/kubernetes; tar pzxvf -"
    tar zcf - pki | ssh ${INIT_USER}@${HOST} "cd /etc/kubernetes; tar pzxvf -"
    squawk 55 "tar zcf - kubeadmcfg.yaml | ssh ${INIT_USER}@${HOST} cd /etc/kubernetes; tar pzxvf -"
    tar zcf - kubeadmcfg.yaml | ssh ${INIT_USER}@${HOST} "cd /etc/kubernetes; tar pzxvf -"
    cd $PREV_PWD
  done

  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    squawk 55 "ssh ${INIT_USER}@${HOST} sudo chown -R root:root /etc/kubernetes/pki"
    ssh ${INIT_USER}@${HOST} "sudo chown -R root:root /etc/kubernetes/pki"
    squawk 55 "ssh ${INIT_USER}@${HOST} kubeadm alpha phase etcd local --config=/etc/kubernetes/kubeadmcfg.yaml"
    ssh ${INIT_USER}@${HOST} "kubeadm alpha phase etcd local --config=/etc/kubernetes/kubeadmcfg.yaml"
  done
  for i in "${!ETCDHOSTS[@]}"; do
    HOST=${ETCDHOSTS[$i]}
    command2run='ls -alh /root'
    squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    ssh ${INIT_USER}@${HOST} "$command2run"
    command2run='ls -Ralh /etc/kubernetes/pki'
    squawk 55 "ssh ${INIT_USER}@${HOST} $command2run"
    ssh ${INIT_USER}@${HOST} "$command2run"
  done

  command2run="kubeadm config images pull"
  squawk 55 "$command2run"
  #ssh ${INIT_USER}@${ETCDHOSTS[0]} "$command2run"
  #ssh ${INIT_USER}@${ETCDHOSTS[1]} "$command2run"
  #ssh ${INIT_USER}@${ETCDHOSTS[2]} "$command2run"
  #sleep 33
  sleep 11

  command2run="docker run --rm  \
    --net host \
    -v /etc/kubernetes:/etc/kubernetes quay.io/coreos/etcd:v3.2.18 etcdctl \
    --cert-file /etc/kubernetes/pki/etcd/peer.crt \
    --key-file /etc/kubernetes/pki/etcd/peer.key \
    --ca-file /etc/kubernetes/pki/etcd/ca.crt \
    --endpoints https://${ETCDHOSTS[0]}:2379 cluster-health"

  squawk 55 'To test etcd run this commmand'
  squawk 55 "$command2run"
  #squawk 55 "ssh -p ${ETCDPORTS[0]} ${K8S_User}@${ETCDHOSTS[0]} $command2run"
  #ssh -p ${ETCDPORTS[0]} ${K8S_User}@${ETCDHOSTS[0]} "$command2run"
  squawk 55 "sudo_command ${ETCDPORTS[0]} $K8S_user ${ETCDHOSTS[0]} $command2run"
  sudo_command ${ETCDPORTS[0]} $K8S_user ${ETCDHOSTS[0]} "$command2run"
  grab_pki_ext_etcd_method $K8S_user ${ETCDHOSTS[0]} ${ETCDPORTS[0]}
  #grab_kube_pki_stacked_method $K8S_user ${ETCDHOSTS[0]} ${ETCDPORTS[0]}

  # distribute the pki and configs
  #for i in "${!MASTERHOSTS[@]}"; do
    #squawk 55 "cp -a $etcd_test_tmp/${ETCDHOSTS[0]}/pki $etcd_test_tmp/${MASTERHOSTS[$i]}/"
    #cp -a $etcd_test_tmp/${ETCDHOSTS[0]}/pki $etcd_test_tmp/${MASTERHOSTS[$i]}/
  #done
  for i in "${!MASTERHOSTS[@]}"; do
    HOST=${MASTERHOSTS[$i]}
    PREV_PWD=$(pwd)
    squawk 55 "push_pki_ext_etcd_method  $K8S_user ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}"
    push_pki_ext_etcd_method  $K8S_user ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}
    cd $etcd_test_tmp/${HOST}
    #squawk 55 "tar zcf - pki | ssh ${INIT_USER}@${HOST} cd /etc/kubernetes; tar pzxvf -"
    #tar zcf - pki | ssh ${INIT_USER}@${HOST} "cd /etc/kubernetes; tar pzxvf -"
    squawk 55 "tar zcf - kubeadmcfg.yaml | ssh ${INIT_USER}@${HOST} cd /etc/kubernetes; tar pzxvf -"
    tar zcf - kubeadmcfg.yaml | ssh ${INIT_USER}@${HOST} "cd /etc/kubernetes; tar pzxvf -"
    cd $PREV_PWD
  done
  for i in "${!MASTERHOSTS[@]}"; do
    HOST=${MASTERHOSTS[$i]}
    #command2run='systemctl daemon-reload'
    #echo "ssh ${INIT_USER}@${HOST} $command2run"
  #  ssh ${INIT_USER}@${HOST} "$command2run"
    #command2run='systemctl stop kubelet'
    #echo "ssh ${INIT_USER}@${HOST} $command2run"
  #  ssh ${INIT_USER}@${HOST} "$command2run"
  done

  command2run="kubeadm init --dry-run --ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-etcd.yaml,ExternalEtcdVersion --config /etc/kubernetes/kubeadmcfg.yaml"
  echo "$command2run"
  ssh ${INIT_USER}@${MASTERHOSTS[0]} "$command2run"
  #sleep 11
  #command2run="kubeadm init  --ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-etcd.yaml,ExternalEtcdVersion --config /etc/kubernetes/kubeadmcfg.yaml"
  #master_grab_kube_config ${MASTERNAMES[0]} ${MASTERHOSTS[0]} $K8S_user ${MASTERPORTS[0]}
  #sudo_command ${MASTERPORTS[0]} $K8S_user ${MASTERHOSTS[0]} "$command2run"
  #command2run="kubeadm init --config /etc/kubernetes/kubeadmcfg.yaml"
  for i in "${!MASTERHOSTS[@]}"; do
    HOST=${MASTERHOSTS[$i]}
    NAME=${MASTERNAMES[$i]}
    if [[ -e "$KUBASH_CLUSTER_DIR/join.sh" ]]; then
      rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[$i]}" $KUBASH_CLUSTER_DIR/join.sh $INIT_USER@$HOST:/tmp/
      push_kube_pki_ext_etcd_sub ${INIT_USER} ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}
      #command2run="ls -Rl /etc/kubernetes"
      #sudo_command ${MASTERPORTS[$i]} ${INIT_USER} ${MASTERHOSTS[$i]} "$command2run"
      #command2run="rm -fv /etc/kubernetes/kubelet.conf"
      #sudo_command ${MASTERPORTS[$i]} ${INIT_USER} ${MASTERHOSTS[$i]} "$command2run"
      my_KUBE_INIT="bash /tmp/join.sh"
      squawk 5 "kube init --> $my_KUBE_INIT"
      ssh -n -p ${MASTERPORTS[$i]} root@${HOST} "$my_KUBE_INIT" 2>&1 | tee $etcd_test_tmp/${HOST}-rawresults.k8s
  #    w8_node $my_node_name
    else
      #command2run="kubeadm init --ignore-preflight-errors=FileAvailable--etc-kubernetes-manifests-etcd.yaml,ExternalEtcdVersion --config /etc/kubernetes/kubeadmcfg.yaml"
      #echo "$command2run"
      #ssh ${INIT_USER}@${MASTERHOSTS[0]} "$command2run"
      #sudo_command ${MASTERPORTS[0]} $K8S_user ${MASTERHOSTS[0]} "$command2run"


      #my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/etc/kubernetes/kubeadmcfg.yaml"
      my_KUBE_INIT="kubeadm init --config=/etc/kubernetes/kubeadmcfg.yaml"
      squawk 5 "master kube init --> $my_KUBE_INIT"
      my_grep='kubeadm join .* --token'
      #run_join=$(ssh -n ${INIT_USER}@${HOST} "$my_KUBE_INIT" | tee $etcd_test_tmp/rawresults.k8s | grep -- "$my_grep")
      ssh -n -p ${MASTERPORTS[$i]} root@${HOST} "$my_KUBE_INIT" 2>&1 | tee $etcd_test_tmp/${HOST}-rawresults.k8s
      #cat $etcd_test_tmp/${HOST}-rawresults.k8s | grep -- "$my_grep"
      run_join=$(cat $etcd_test_tmp/${HOST}-rawresults.k8s | grep -P -- "$my_grep")
      join_token=$(cat $etcd_test_tmp/${HOST}-rawresults.k8s \
        | grep -P -- "$my_grep" \
        | sed 's/\(.*\)--token\ \(\S*\)\ --discovery-token-ca-cert-hash\ .*/\2/')
      if [[ -z "$run_join" ]]; then
        horizontal_rule
        echo 'kubeadm init failed!'
        exit 1
      else
        echo $run_join > $KUBASH_CLUSTER_DIR/join.sh
        sed -i 's/$/ --experimental-control-plane/' $KUBASH_CLUSTER_DIR/join.sh
        echo $join_token > $KUBASH_CLUSTER_DIR/join_token
        master_grab_kube_config ${NAME} ${HOST} ${INIT_USER} ${MASTERPORTS[$i]}
        grab_kube_pki_ext_etcd_sub ${INIT_USER} ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}
      fi
    fi
  done
  while IFS="," read -r $csv_columns
  do
    squawk 85 "ROLE $K8S_role $K8S_user $K8S_ip1 $K8S_sshPort"
    if [[ "$K8S_role" == 'node' ]]; then
      squawk 65 "push kube pki ext etcd sub $K8S_user $K8S_ip1 $K8S_sshPort"
      #push_pki_ext_etcd_method   $K8S_user $K8S_ip1 $K8S_sshPort
      push_kube_pki_ext_etcd_sub $K8S_user $K8S_ip1 $K8S_sshPort
    fi
  done <<< "$kubash_hosts_csv_slurped"
  rm -Rf $etcd_test_tmp
}

etcd_kubernetes_docs_stacked_method () {
  sleep 4
  number_limiter=$1
  etcd_stacked_tmp=$(mktemp -d)
  STACKED_USER=root
  #my_KUBE_CIDR="10.244.0.0/16"
  set_csv_columns
  etc_count_zero=0
  master_count_zero=0
  node_count_zero=0
  #rm -f $KUBASH_CLUSTER_DIR/join.sh
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' || "$K8S_role" == 'primary_etcd' ]]; then
      ETCDHOSTS[$etc_count_zero]=$K8S_ip1
      ETCDNAMES[$etc_count_zero]=$K8S_node
      ETCDPORTS[$etc_count_zero]=$K8S_sshPort
      MASTERHOSTS[$master_count_zero]=$K8S_ip1
      MASTERNAMES[$master_count_zero]=$K8S_node
      MASTERPORTS[$master_count_zero]=$K8S_sshPort
      ((++etc_count_zero))
      ((++master_count_zero))
    elif [[ "$K8S_role" == 'node' ]]; then
      NODEHOSTS[$node_count_zero]=$K8S_ip1
      NODENAMES[$node_count_zero]=$K8S_node
      NODEPORTS[$node_count_zero]=$K8S_sshPort
      ((++node_count_zero))
    fi
  done <<< "$kubash_hosts_csv_slurped"
  echo $ETCDHOSTS
  sleep 33
  get_major_minor_kube_version $K8S_user ${MASTERHOSTS[0]} ${MASTERNAMES[0]} ${MASTERPORTS[0]}
  determine_api_version

  echo -n '            initial-cluster: "' > $etcd_stacked_tmp/initial-cluster.head
  if [[ "$ETCD_TLS" == 'true' ]]; then
    echo -n '            listen-client-urls: "https://127.0.0.1:2379,' > $etcd_stacked_tmp/listen-client_urls.head
  else
    #echo -n '            listen-client-urls: "http://127.0.0.1:2379,' > $etcd_stacked_tmp/listen-client_urls.head
    echo -n '            listen-client-urls: "https://127.0.0.1:2379,' > $etcd_stacked_tmp/listen-client_urls.head
  fi
  count_etcd=0
  countetcdnodes=0
  while IFS="," read -r $csv_columns
  do
    echo "- \"${K8S_ip1}\"" >> $etcd_stacked_tmp/apiservercertsans.line
    if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' || "$K8S_role" == 'primary_etcd' ]]; then
      if [[ $countetcdnodes -gt 0 ]]; then
        printf ',' >> $etcd_stacked_tmp/initial-cluster.line
        printf ',' >> $etcd_stacked_tmp/listen-client_urls.line
      fi
      if [[ "$ETCD_TLS" == 'true' ]]; then
        echo "      - https://${K8S_ip1}:2379" >> $etcd_stacked_tmp/endpoints.line
        printf "${K8S_node}=https://${K8S_ip1}:2380" >>  $etcd_stacked_tmp/initial-cluster.line
        printf "https://${K8S_ip1}:2379" > $etcd_stacked_tmp/${countetcdnodes}-listen-client_urls.line
      else
        #echo "      - http://${K8S_ip1}:2379" >> $etcd_stacked_tmp/endpoints.line
        #printf "${K8S_node}=http://${K8S_ip1}:2380" >>  $etcd_stacked_tmp/initial-cluster.line
        #printf "http://${K8S_ip1}:2379" > $etcd_stacked_tmp/${countetcdnodes}-listen-client_urls.line
        echo "      - https://${K8S_ip1}:2379" >> $etcd_stacked_tmp/endpoints.line
        printf "${K8S_node}=https://${K8S_ip1}:2380" >>  $etcd_stacked_tmp/initial-cluster.line
        printf "https://${K8S_ip1}:2379" > $etcd_stacked_tmp/${countetcdnodes}-listen-client_urls.line
      fi
      cp $etcd_stacked_tmp/initial-cluster.line $etcd_stacked_tmp/${countetcdnodes}-initial-cluster.line
      printf '"' >> $etcd_stacked_tmp/${countetcdnodes}-initial-cluster.line
      printf " \n" >> $etcd_stacked_tmp/${countetcdnodes}-initial-cluster.line
      #printf "https://${K8S_ip1}:2379" >> $etcd_stacked_tmp/listen-client_urls.line
      #cp $etcd_stacked_tmp/listen-client_urls.line $etcd_stacked_tmp/${countetcdnodes}-listen-client_urls.line
      printf '"' >> $etcd_stacked_tmp/${countetcdnodes}-listen-client_urls.line
      printf " \n" >> $etcd_stacked_tmp/${countetcdnodes}-listen-client_urls.line
      ((++countetcdnodes))
    fi
    ((++count_etcd))
  done <<< "$kubash_hosts_csv_slurped"
  printf '"' >> $etcd_stacked_tmp/initial-cluster.line
  printf '"' >> $etcd_stacked_tmp/listen-client_urls.line
  printf " \n" >> $etcd_stacked_tmp/initial-cluster.line
  printf " \n" >> $etcd_stacked_tmp/listen-client_urls.line

  initial_cluster_line=$(cat $etcd_stacked_tmp/initial-cluster.head $etcd_stacked_tmp/initial-cluster.line)
  api_server_cert_sans_line=$(cat $etcd_stacked_tmp/apiservercertsans.line)
  endpoints_line=$(cat $etcd_stacked_tmp/endpoints.line)
  #rm $etcd_stacked_tmp/initial-cluster.head $etcd_stacked_tmp/initial-cluster.line $etcd_stacked_tmp/apiservercertsans.line $etcd_stacked_tmp/endpoints.line


  for i in "${!MASTERHOSTS[@]}"; do
    initial_cluster_line=$(cat $etcd_stacked_tmp/initial-cluster.head $etcd_stacked_tmp/${i}-initial-cluster.line)
    listen_client_urls_line=$(cat $etcd_stacked_tmp/listen-client_urls.head $etcd_stacked_tmp/${i}-listen-client_urls.line)
    api_server_cert_sans_line=$(cat $etcd_stacked_tmp/apiservercertsans.line)
    endpoints_line=$(cat $etcd_stacked_tmp/endpoints.line)
    HOST=${MASTERHOSTS[$i]}
    NAME=${MASTERNAMES[$i]}
    mkdir -p $etcd_stacked_tmp/${HOST}
    if [ "$i" -eq '0' ]; then
      INITIAL_CLUSTER_STATE=new
    else
      INITIAL_CLUSTER_STATE=existing
    fi
    cat << EOF > $etcd_stacked_tmp/${HOST}/kubeadmcfg.yaml
apiVersion: $kubeadm_apiVersion
kind: $kubeadm_cfg_kind
apiServerCertSANs:
- "127.0.0.1"
$api_server_cert_sans_line
controlPlaneEndpoint: "${MASTERHOSTS[0]}:6443"
etcd:
    local:
        serverCertSANs:
        - "${HOST}"
        - "${NAME}"
        peerCertSANs:
        - "${HOST}"
        - "${NAME}"
        extraArgs:
$listen_client_urls_line
            advertise-client-urls: "https://${HOST}:2379"
            listen-peer-urls: "https://${HOST}:2380"
            initial-advertise-peer-urls: "https://${HOST}:2380"
$initial_cluster_line
            initial-cluster-state: $INITIAL_CLUSTER_STATE
networking:
  podSubnet: $my_KUBE_CIDR
EOF
    squawk 55 "push_pki_ext_etcd_method  $K8S_SU_STACKED_USER ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}"
    rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[$i]}" $etcd_stacked_tmp/${HOST}/kubeadmcfg.yaml $STACKED_USER@$HOST:/tmp/
    command2run='mv /tmp/kubeadmcfg.yaml /etc/kubernetes/'
    sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"

    if [[ -e "$KUBASH_CLUSTER_DIR/join.sh" ]]; then
      rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[$i]}" $KUBASH_DIR/templates/kube_stacked_init.sh $STACKED_USER@$HOST:/tmp/
      #rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[0]}" root@${MASTERHOSTS[0]}:/etc/kubernetes/admin.conf $STACKED_USER@$HOST:/etc/kubernetes/admin.conf
      #rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[0]}" root@${MASTERHOSTS[0]}:/etc/kubernetes/admin.conf $STACKED_USER@$HOST:/tmp/admin.conf
      #rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[0]}" \
        #root@${MASTERHOSTS[0]}:/etc/kubernetes/admin.conf \
        #$etcd_stacked_tmp/${HOST}/
      #rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[$i]}" \
        #$etcd_stacked_tmp/${HOST}/admin.conf \
        #root@$HOST:/etc/kubernetes/admin.conf
      #rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[0]}" \
        #root@${MASTERHOSTS[0]}:/etc/kubernetes \
        #$etcd_stacked_tmp/${HOST}/
      #rsync $KUBASH_RSYNC_OPTS "ssh -p ${MASTERPORTS[$i]}" \
        #$etcd_stacked_tmp/${HOST}/kubernetes \
        #root@$HOST:/etc/
      squawk 55 "push_kube_pki_stacked_method  $K8S_user ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}"
      push_kube_pki_stacked_method ${STACKED_USER} ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}
      command2run="ls -Rl /etc/kubernetes"
      sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"
      #command2run="rm -v /etc/kubernetes/controller-manager.conf /etc/kubernetes/kubelet.conf"
      #command2run="rm -fv /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf /etc/kubernetes/kubelet.conf"
      command2run="rm -fv /etc/kubernetes/kubelet.conf"
      sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"
      escaped_master=$( echo ${MASTERHOSTS[0]} |sed 's/\./\\./g')
      sedder="s/$escaped_master/$HOST/g"
      #command2run="rm -v /etc/kubernetes/admin.conf"
      #sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"
      #command2run="sed -i "$sedder" /etc/kubernetes/admin.conf"
      #sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"
      #command2run="sed -i "$sedder" /etc/kubernetes/scheduler.conf"
      #sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"
      #command2run="sed -i "$sedder" /etc/kubernetes/controller-manager.conf"
      #sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"
      command2run='mv /tmp/kube_stacked_init.sh /etc/kubernetes/'
      sudo_command ${MASTERPORTS[$i]} ${STACKED_USER} ${MASTERHOSTS[$i]} "$command2run"
      #my_KUBE_INIT=$(cat $KUBASH_CLUSTER_DIR/join.sh)
      my_KUBE_INIT="bash /etc/kubernetes/kube_stacked_init.sh ${MASTERHOSTS[0]} ${MASTERNAMES[0]} ${MASTERHOSTS[$i]} ${MASTERNAMES[$i]}"
      squawk 5 "kube init --> $my_KUBE_INIT"
      ssh -n -p ${MASTERPORTS[$i]} root@${HOST} "$my_KUBE_INIT" 2>&1 | tee $etcd_stacked_tmp/${HOST}-rawresults.k8s
      w8_node $my_node_name
      #rolero $my_node_name master
    else
      #my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/etc/kubernetes/kubeadmcfg.yaml"
      my_KUBE_INIT="kubeadm init --config=/etc/kubernetes/kubeadmcfg.yaml"
      squawk 5 "master kube init --> $my_KUBE_INIT"
      my_grep='kubeadm join .* --token'
      #run_join=$(ssh -n ${STACKED_USER}@${HOST} "$my_KUBE_INIT" | tee $etcd_stacked_tmp/rawresults.k8s | grep -- "$my_grep")
      ssh -n -p ${MASTERPORTS[$i]} root@${HOST} "$my_KUBE_INIT" 2>&1 | tee $etcd_stacked_tmp/${HOST}-rawresults.k8s
      #cat $etcd_stacked_tmp/${HOST}-rawresults.k8s | grep -- "$my_grep"
      run_join=$(cat $etcd_stacked_tmp/${HOST}-rawresults.k8s | grep -P -- "$my_grep")
      join_token=$(cat $etcd_stacked_tmp/${HOST}-rawresults.k8s \
        | grep -P -- "$my_grep" \
        | sed 's/\(.*\)--token\ \(\S*\)\ --discovery-token-ca-cert-hash\ .*/\2/')
      if [[ -z "$run_join" ]]; then
        horizontal_rule
        echo 'kubeadm init failed!'
        exit 1
      else
        echo $run_join > $KUBASH_CLUSTER_DIR/join.sh
        echo $join_token > $KUBASH_CLUSTER_DIR/join_token
        master_grab_kube_config ${NAME} ${HOST} ${STACKED_USER} ${MASTERPORTS[$i]}
        grab_kube_pki_stacked_method ${STACKED_USER} ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}
      fi
    fi
  done
  squawk 55 'key nodes'
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 85 "ROLE $K8S_role $K8S_user $K8S_ip1 $K8S_sshPort"
    if [[ "$K8S_role" == 'node' ]]; then
      squawk 65 "NEUTERED push kube pki ext etcd sub $K8S_user $K8S_ip1 $K8S_sshPort"
      #squawk 65 "push kube pki ext etcd sub $K8S_user $K8S_ip1 $K8S_sshPort"
      #push_kube_pki_stacked_method ${STACKED_USER} ${MASTERHOSTS[$i]} ${MASTERPORTS[$i]}
      #push_kube_pki_ext_etcd_sub $K8S_user $K8S_ip1 $K8S_sshPort
    fi
  done <<< "$kubash_hosts_csv_slurped"
  rm -Rf $etcd_stacked_tmp

}

horizontal_rule () {
  printf '%*s\n' "${COLUMNS:-$(tput cols)}" '' | tr ' ' -
}

usage () {
  horizontal_rule
  # Print usage
  echo 'kubash, by Josh Cox 2018.01.31
usage: kubash COMMAND
This script automates the setup and maintenance of a kubernetes cluster
e.g.

kubash init
'
  horizontal_rule
echo '
commands:
  build         - build a base image
  provision     - provision individual nodes
  init          - initialize the cluster
  reset         - reset the cluster with `kubeadm reset` on all hosts
  decommission  - tear down the cluster and decommission nodes
  show          - show the analyzed input of the hosts file
  ping          - Perform ansible ping to all hosts
  auto          - Full auto will provision and initialize all hosts
  masters       - Perform initialization of masters
  nodes         - Perform initialization of nodes
  dotfiles      - Perform dotfiles auto configuration
  grab          - Grab the .kube/config from the master
  hosts         - Write ansible hosts file
  copy          - copy the built images to the provisioning hosts
  kubash *     - any unrecognized commands will attempt to be passed to kubectl
'
  horizontal_rule
echo '
options:
 -h --help      - Print usage
 -c --csv FILE  - Set the csv file to be parsed
 --parallel X   - set the number of parallel jobs for tasks that support it
 -v --verbose   - Increase the verbosity (can set multiple times to incrementally increase e.g. `-vvvv`
 --verbosity X  - or you can set the verbosity directly
 --debug        - adds the debug flag
 -n             - use a particular cluster by name
'
}

interactive_usage () {
horizontal_rule
echo -n 'commands:
  help          - show this help
  kh|khelp      - show the kubectl help
  build         - build a base image
  provision     - provision individual nodes
  init          - initialize the cluster
  reset         - reset the cluster with `kubeadm reset` on all hosts
  decommission  - tear down the cluster and decommission nodes
  show          - show the analyzed input of the hosts file
  ping          - Perform ansible ping to all hosts
  auto          - Full auto will provision and initialize all hosts
  masters       - Perform initialization of masters
  nodes         - Perform initialization of nodes
  dotfiles      - Perform dotfiles auto configuration
  grab          - Grab the .kube/config from the master
  hosts         - Write ansible hosts file
  copy          - copy the built images to the provisioning hosts
  k *           - k commands will attempt to be passed to kubectl
  h *           - h commands will attempt to be passed to helm
  i.e.
  get pods
  get nodes
  etc'
}

kubectl_interactive_usage () {
horizontal_rule
echo -n 'kubectl shorthand commands:
  # Show all the nodes and their status
  kgn="kubectl get nodes"
  # Drop into an interactive terminal on a container
  keti="kubectl exec -ti"
  # Pod management.
  kgp="kubectl get pods| grep -v '^pvc-' "
  kgpa="kubectl get pods --all-namespaces| grep -v '^pvc-' "
  kgpvc="kubectl get pods | grep '^pvc-' "
  klp="kubectl logs pods"
  kep="kubectl edit pods"
  kdp="kubectl describe pods"
  kdelp="kubectl delete pods"
  # Service management.
  kgs="kubectl get svc"
  kes="kubectl edit svc"
  kds="kubectl describe svc"
  kdels="kubectl delete svc"
  # Secret management
  kgsec="kubectl get secret"
  kdsec="kubectl describe secret"
  kdelsec="kubectl delete secret"
  # Deployment management.
  kgd="kubectl get deployment"
  ked="kubectl edit deployment"
  kdd="kubectl describe deployment"
  kdeld="kubectl delete deployment"
  ksd="kubectl scale deployment"
  krsd="kubectl rollout status deployment"
  # voyager management.
  kei="kubectl edit ingress.voyager.appscode.com "
  # Rollout management.
  kgrs="kubectl get rs"
  krh="kubectl rollout history"
  kru="kubectl rollout undo"'
}

node_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash node_join
build - build a base image

This command joins a node to the cluster
e.g.

kubash node_join

options:

 -h --help - Print usage
 --node-join-name - set node name
 --node-join-user - set node user
 --node-join-ip   - set node ip
 --node-join-port - set node port
 --node-join-role - set node role
 -n --clustername - use a particular cluster by name
'
}

build_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash build
build - build a base image

This script automates the setup and maintenance of a kubernetes cluster
e.g.

kubash build

options:

 -h --help - Print usage
 --builder - choose builder (packer,coreos)
 --target-os - choose target-os (debian,ubuntu,centos,fedora,coreos)
 --target-build - choose target-build
'
}

init_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash init

This initializes the cluster

options:

 -h --help - Print usage
 --initializer - Choose the initialization method (kubeadm,kubespray,openshift)
 -n --clustername - use a particular cluster by name
'
}

provision_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash provision
provision - provision a base image

This provisions the base VMs

options:

 -h --help - Print usage
 -n --clustername - use a particular cluster by name
'
}

decom_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash decom
decommission - decommission a cluster and destroy all VMs

This script automates the setup and maintenance of a kubernetes cluster
e.g.

kubash decommission

options:

 -h --help - Print usage
 -n --clustername - use a particular cluster by name
'
}

# Check if a command exists
check_cmd () {
  if ! test_cmd_loc="$(type -p "$1")" || [[ -z "$test_cmd_loc" ]]; then
    horizontal_rule
    echo "$1 was not found in your path!"
    echo "To proceed please install $1 to your path and try again!"
    exit 1
  fi
}

# Check if a file exists and is writable
check_file () {
  if [[ -w "$1" ]]; then
    horizontal_rule
    echo "$1 was not writable!"
    exit 1
  fi
}

check_cmd mktemp
TMP=$(mktemp -d --suffix='.kubash.tmp' 2>/dev/null || mktemp -d -t '.kubash.tmp')

chkdir () {
  if [[ ! -w "$1" ]] ; then
    sudo mkdir -p $1
    sudo chown $USER $1
  fi
  if [[ ! -w "$1" ]] ; then
    echo "Cannot write to $1, please check your permissions"
    exit 2
  fi
}

killtmp () {
  cd
  rm -Rf $TMP
}

trap killtmp EXIT
# these vars are used by the following functions
LINE_TO_ADD=''
TARGET_FILE_FOR_ADD=$HOME/.profile

check_if_line_exists()
{
  squawk 7 " Checking for '$LINE_TO_ADD'  in $TARGET_FILE_FOR_ADD"
  grep -qsFx "$LINE_TO_ADD" $TARGET_FILE_FOR_ADD
}

add_line_to()
{
  squawk 5 " Adding '$LINE_TO_ADD'  to $TARGET_FILE_FOR_ADD"
  TARGET_FILE=$TARGET_FILE_FOR_ADD
    [[ -w "$TARGET_FILE" ]] || TARGET_FILE=$TARGET_FILE_FOR_ADD
    printf "%s\n" "$LINE_TO_ADD" >> "$TARGET_FILE"
}

genmac () {
  # Generate a mac address
  hexchars="0123456789ABCDEF"
  : ${DEFAULT_MAC_ADDRESS_BLOCK:=52:54:00}

  if [[ ! -z "$1" ]]; then
    DEFAULT_MAC_ADDRESS_BLOCK=$1
  fi

  end=$( for i in {1..6} ; do echo -n ${hexchars:$(( $RANDOM % 16 )):1} ; done | sed -e 's/\(..\)/:\1/g' )

  echo "$DEFAULT_MAC_ADDRESS_BLOCK$end" >&3
}

rolero () {
  squawk 2 "rolero $@"
  node_name=$1
  NODE_ROLE=$2

  result=$(kubectl --kubeconfig=$KUBECONFIG label --overwrite node $node_name node-role.kubernetes.io/$NODE_ROLE=)
  squawk 4 "Result = $result"
}

hosts_csv_slurp () {
  squawk 19 "slurp hosts.csv"
  # Get rid of commented lines, and sort on the second and third mac address fields
  # This ensures hosts with more net interfaces are set after hosts with less interfaces
  kubash_hosts_csv_slurped="$(grep -v '^#' $KUBASH_HOSTS_CSV|sort -t , -k 19,19n  -k 16,16n)"
}

provision_csv_slurp () {
  squawk 19 "slurp provision.csv"
  # Get rid of commented lines, and sort on the second and third mac address fields
  # This ensures hosts with more net interfaces are set after hosts with less interfaces
  kubash_provision_csv_slurped="$(grep -v '^#' $KUBASH_PROVISION_CSV|sort -t , -k 19,19n  -k 16,16n)"
}

kvm-decommer () {
  squawk 5 "kvm-decommer-remote $@"
  REBASED_NODE=$1
  THRU_USER=$2
  THRU_HOST=$3
  THRU_PORT=$4
  NODE_PATH=$5
  qemunodeimg="$NODE_PATH/$KUBASH_CLUSTER_NAME-k8s-$REBASED_NODE.qcow2"

  command2run="virsh destroy $REBASED_NODE"
  squawk 8 "$command2run"
  sudo_command $THRU_PORT $THRU_USER $THRU_HOST "$command2run"
  command2run="virsh undefine $REBASED_NODE"
  squawk 8 "$command2run"
  sudo_command $THRU_PORT $THRU_USER $THRU_HOST "$command2run"
  command2run="rm $qemunodeimg"
  squawk 8 "$command2run"
  sudo_command $THRU_PORT $THRU_USER $THRU_HOST "$command2run"
}

remove_all_base_images_kvm () {
  # Now remove the cluster base images
  KUBASH_CSV_VER=$(cat $KUBASH_CSV_VER_FILE)
  if [ "$KUBASH_CSV_VER" = '2.0.0' ]; then
    uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f13,14,15,16,17,18|sort|uniq)"
  elif [ "$KUBASH_CSV_VER" = '1.0.0' ]; then
    uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f9,10,11,12,13,14|sort|uniq)"
  else
    echo 'CSV columns cannot be set CSV Version not recognized'
    exit 1
  fi
  squawk 8 "$uniq_hosts"
  copy_image_tmp_para=$(mktemp -d)
  while IFS="," read -r $uniq_hosts_list_columns
  do
    command2run="rm $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
    sudo_command $K8S_provisionerPort $K8S_provisionerUser $K8S_provisionerHost "$command2run"
  done <<< "$uniq_hosts"
}

decom_kvm () {
  squawk 1 "decom_kvm starting"
  if [[ -z "$kubash_provision_csv_slurped" ]]; then
    provision_csv_slurp
  fi
  squawk 19 "slurpy -----> $(echo $kubash_provision_csv_slurped)"
  # Write all hosts to inventory for id
  squawk 15 "decom_kvm loop starting"
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 19 "Loop $K8S_node $K8S_user $K8S_ip1 $K8S_provisionerPort $K8S_role $K8S_provisionerUser $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort"
    set +e
    kvm-decommer $K8S_node $K8S_provisionerUser $K8S_provisionerHost $K8S_provisionerPort $K8S_provisionerBasePath
    set -e
  done <<< "$kubash_provision_csv_slurped"
  squawk 16 'Looped through all hosts to be decommissioned'
  remove_all_base_images_kvm
}

vbox-provisioner () {
  squawk 1 "vbox-provisioner $@"

  K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_network1=$5
  K8S_sshPort=${10}
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}

  squawk 7 "K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_sshPort=${10}
  K8S_network1=$5
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}
  "

  echo 'Vbox provisioner not implemented yet'
  exit 1
}

gke_yaml2cluster () {
  yaml2cluster_tmp=$(mktemp -d)
  echo yaml2cluster
  if [[ -z "$1" ]]; then
    echo 'gke_yaml2cluster requires an argument'
    exit 1
  fi
  this_yaml=$1
  this_json=$yaml2cluster_tmp/this.json
  yaml2json $this_yaml > $this_json
  gke_json2cluster $this_json
  rm $this_json
  rm -Rf $yaml2cluster_tmp
}

gke_json2cluster () {
  json2cluster_tmp=$(mktemp -d)
  if [[ -z "$1" ]]; then
    echo 'json2cluster requires an argument'
    exit 1
  fi
  this_json=$1

  # csv_version
  # should be a string not an int!
  jq -r '.csv_version | "\(.)" ' \
    $this_json > $json2cluster_tmp/csv_version
  # kubernetes_version
  # should be a string not an int!
  jq -r '.kubernetes_version | "\(.)" ' \
    $this_json > $json2cluster_tmp/kubernetes_version
  jq -r '.project | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_project=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.cluster_name | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_cluster_name=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.zone | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_zone=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.username | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_username=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.cluster_version | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_cluster_version=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.machine_type | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_machine_type=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.image_type | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_image_type=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.disk_size | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_disk_size=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.scopes | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_scopes=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.num_nodes | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_num_nodes=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.network | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_network=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.subnetwork | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_subnetwork=$(cat $json2cluster_tmp/this_tmp)
  jq -r '.additional_opts | "\(.)" ' \
    $this_json > $json2cluster_tmp/this_tmp
  gke_additional_opts=$(cat $json2cluster_tmp/this_tmp)

  echo 'Provisioning on GKE with these attributes'

  echo "gke_project=$gke_project
gke_cluster_name=$gke_cluster_name
gke_zone=$gke_zone
gke_username=$gke_username
gke_cluster_version=$gke_cluster_version
gke_machine_type=$gke_machine_type
gke_image_type=$gke_image_type
gke_disk_size=$gke_disk_size
gke_scopes=$gke_scopes
gke_num_nodes=$gke_num_nodes
gke_network=$gke_network
gke_subnetwork=$gke_subnetwork
gke_additional_opts=$gke_additional_opts
"

  echo -n 'Ctrl-C now to stop if this is not what you intend!'
  echo -n '!'; sleep 1; echo -n '!'; sleep 1; echo -n '!'; sleep 1; echo '!'; sleep 1;
  sleep 2

  gke_gcloud_provision $gke_project $gke_cluster_name $gke_zone $gke_username $gke_cluster_version $gke_machine_type $gke_image_type $gke_disk_size $gke_scopes $gke_num_nodes $gke_network $gke_subnetwork "$gke_additional_opts"
}

gke_gcloud_provision () {
  gke_project=$1
  gke_cluster_name=$2
  gke_zone=$3
  gke_username=$4
  gke_cluster_version=$5
  gke_machine_type=$6
  gke_image_type=$7
  gke_disk_size=$8
  gke_scopes=$9
  gke_num_nodes=${10}
  gke_network=${11}
  gke_subnetwork=${12}
  gke_additional_opts=${13}

  echo "gcloud beta container \
  --project '$gke_project' \
  clusters create '$gke_cluster_name' \
  --zone '$gke_zone' \
  --username '$gke_username' \
  --cluster-version '$gke_cluster_version' \
  --machine-type '$gke_machine_type' \
  --image-type '$gke_image_type' \
  --disk-size '$gke_disk_size' \
  --scopes $gke_scopes \
  --num-nodes '$gke_num_nodes' \
  --network '$gke_network' \
  --subnetwork '$gke_subnetwork' \
  $gke_additional_opts"

  gcloud beta container \
    --project "$gke_project" \
    clusters create "$gke_cluster_name" \
    --zone "$gke_zone" \
    --username "$gke_username" \
    --cluster-version "$gke_cluster_version" \
    --machine-type "$gke_machine_type" \
    --image-type "$gke_image_type" \
    --disk-size "$gke_disk_size" \
    --scopes $gke_scopes \
    --num-nodes "$gke_num_nodes" \
    --network "$gke_network" \
    --subnetwork "$gke_subnetwork" \
    $gke_additional_opts

  sleep 3

  KUBECONFIG=$KUBECONFIG \
  gcloud container \
    clusters \
    --zone $gke_zone \
    get-credentials $gke_cluster_name

  KUBECONFIG=$KUBECONFIG \
  kubectl create clusterrolebinding cluster-admin-binding \
    --clusterrole cluster-admin \
    --user $(gcloud config get-value account)
}

gke-provisioner () {
  squawk 1 "gke-provisioner $@"

  if [[ -z "$1" ]]; then
    echo 'gke-provisioner requires an argument'
    exit 1
  fi

  if [[ "${1: -5}" == '.yaml' ]]; then
    squawk 1 "gke_yaml2cluster $1"
    gke_yaml2cluster $1
  elif [ "${1: -4}" = ".yml" ]; then
    squawk 1 "gke_yaml2cluster $1"
    gke_yaml2cluster $1
  elif [ "${1: -5}" = ".json" ]; then
    squawk 1 "gke_json2cluster $1"
    gke_json2cluster $1
  fi
}

qemu-provisioner () {
  squawk 1 "qemu-provisioner $@"

  K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_network1=$5
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}
  if [[ "$K8S_mac1" == 'null' ]]; then
    K8S_mac1=$(VERBOSITY=0 kubash --verbosity=1 genmac)
  fi
  if [[ "$K8S_network2" != 'null' ]]; then
    if [[ "$K8S_mac2" == 'null' ]]; then
      K8S_mac2=$(VERBOSITY=0 kubash --verbosity=1 genmac)
    fi
    SECOND_NIC="--network=$K8S_network2,mac=$K8S_mac2,model=virtio"
  fi
  if [[ "$K8S_network3" != 'null' ]]; then
    if [[ "$K8S_mac3" == 'null' ]]; then
      K8S_mac3=$(VERBOSITY=0 kubash --verbosity=1 genmac)
    fi
    THIRD_NIC="--network=$K8S_network3,mac=$K8S_mac3,model=virtio"
  fi

  squawk 7 "K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_network1=$5
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}
  "

  # Create VM for node
  qemunodeimg="$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$K8S_node.qcow2"
  qemucmd2run="$PSEUDO qemu-img create -f qcow2 -b $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG $qemunodeimg"

  if [[ "$K8S_os" == "coreos" ]]; then
    squawk 5 "Keyer"
    KEYTMP=$(mktemp -d)
    touch $KEYTMP/keys
    if [ ! -z  "$KEYS_URL" ]; then
      curl --silent -L "$KEYS_URL"  >> $KEYTMP/keys 
    else
      echo 'no KEYS_URL given'
    fi
    if [ ! -z  "$KEYS_TO_ADD" ]; then
      echo "$KEYS_TO_ADD" >>  $KEYTMP/keys
    else
      echo 'no KEYS_TO_ADD given'
    fi
    squawk 18 "Keys $(cat $KEYTMP/keys)"
    echo '    ssh_authorized_keys:'>  $KEYTMP/keys.json
    cat  $KEYTMP/keys|sed 's/^/    - /' >> $KEYTMP/keys.json
    SSH_AUTHORIZED_KEYS=$(cat $KEYTMP/keys.json)
    squawk 19 "Keys.json $SSH_AUTHORIZED_KEYS"
    rm -Rf $KEYTMP
    chkdir $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node
    if [[ "$K8S_ip2" == 'null' && "$K8S_ip2" == 'null' ]]; then
      SSH_AUTHORIZED_KEYS=$SSH_AUTHORIZED_KEYS \
      K8S_SU_USER=$K8S_SU_USER \
      K8S_node=$K8S_node \
      envsubst < $KUBASH_DIR/templates/user_data \
      > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data
    elif [[ "$K8S_ip2" -ne 'null' && "$K8S_ip3" == 'null' ]]; then
      K8S_mac2=$K8S_mac2 \
      K8S_ip2=$K8S_ip2 \
      SSH_AUTHORIZED_KEYS=$SSH_AUTHORIZED_KEYS \
      K8S_SU_USER=$K8S_SU_USER \
      K8S_node=$K8S_node \
      envsubst < $KUBASH_DIR/templates/user_data_two_interface \
      > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data
    else
      K8S_mac2=$K8S_mac2 \
      K8S_ip2=$K8S_ip2 \
      K8S_network3=$K8S_network3 \
      K8S_mac3=$K8S_mac3 \
      K8S_ip3=$K8S_ip3 \
      SSH_AUTHORIZED_KEYS=$SSH_AUTHORIZED_KEYS \
      K8S_SU_USER=$K8S_SU_USER \
      K8S_node=$K8S_node \
      envsubst < $KUBASH_DIR/templates/user_data_three_interface \
      > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data
    fi
    ct < $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data \
       > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data.ign

    virshcmd2run="$PSEUDO virt-install --connect qemu:///system \
  --import \
    --autostart \
    --name $K8S_node \
    --ram $K8S_Memory \
    --vcpus $K8S_cpuCount \
    --os-type=linux \
    --noautoconsole \
    --accelerate \
    --hvm \
    --os-variant=virtio26 \
    --disk path=$qemunodeimg,format=qcow2,bus=virtio \
    --network=$K8S_network1,mac=$K8S_mac1,model=virtio \
    $SECOND_NIC \
    $THIRD_NIC \
  --print-xml
  " >&3 2>&3
  else
    virshcmd2run="$PSEUDO virt-install --connect qemu:///system \
  --import \
    --autostart \
    --name $K8S_node \
    --ram $K8S_Memory \
    --vcpus $K8S_cpuCount \
    --os-type=linux \
    --noautoconsole \
    --accelerate \
    --hvm \
    --os-variant=virtio26 \
    --disk path=$qemunodeimg,format=qcow2,bus=virtio \
    --network=$K8S_network1,mac=$K8S_mac1,model=virtio \
    $SECOND_NIC \
    $THIRD_NIC"
  fi

  if [[ "$K8S_provisionerHost" = "localhost" ]]; then
    squawk 5 "$qemucmd2run"
    $qemucmd2run
    if [[ "$K8S_os" == "coreos" ]]; then
      squawk 5 "create domain.xml $virshcmd2run"
      $virshcmd2run > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i 's|type=\"kvm\"|type=\"kvm\" xmlns:qemu=\"http://libvirt.org/schemas/domain/qemu/1.0\"|' $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i "/<\/devices>/a <qemu:commandline>\n  <qemu:arg value='-fw_cfg'/>\n  <qemu:arg value='name=opt/com.coreos/config,file=$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME/$K8S_node/user_data.ign'/>\n</qemu:commandline>" $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      squawk 5 "sync the cluster directory"

      squawk 9 "rsync -az $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME $K8S_provisionerBasePath/"
      rsync -az $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME $K8S_provisionerBasePath/

      $PSEUDO virsh define $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      $PSEUDO virsh start $K8S_node
    else
      squawk 5 "$PSEUDO $virshcmd2run"
      $PSEUDO $virshcmd2run
    fi
  else
    squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $qemucmd2run"
    ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$qemucmd2run"

    if [[ "$K8S_os" == "coreos" ]]; then
      squawk 5 "create the domain.xml"
      squawk 1 "touch $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml"
      touch $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run" > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i 's|type=\"kvm\"|type=\"kvm\" xmlns:qemu=\"http://libvirt.org/schemas/domain/qemu/1.0\"|' $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i "/<\/devices>/a <qemu:commandline>\n  <qemu:arg value='-fw_cfg'/>\n  <qemu:arg value='name=opt/com.coreos/config,file=$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME/$K8S_node/user_data.ign'/>\n</qemu:commandline>" $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml

      squawk 5 "sync the cluster directory"
      squawk 9 "rsync $KUBASH_RSYNC_OPTS 'ssh -p$K8S_provisionerPort' $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME $K8S_provisionerUser@$K8S_provisionerHost:~/"
      rsync $KUBASH_RSYNC_OPTS "ssh -p$K8S_provisionerPort" $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME $K8S_provisionerUser@$K8S_provisionerHost:$K8S_provisionerBasePath/

      virshcmd2run="$PSEUDO virsh define $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml"
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $virshcmd2run"
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run"

      virshcmd2run="$PSEUDO virsh start $K8S_node"
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $virshcmd2run"
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run"
    else
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $virshcmd2run"
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run"
    fi
  fi
}

provisioner () {
  squawk 1 " provisioner"
  slurpy="$(grep -v '^#' $KUBASH_PROVISION_CSV)"
  squawk 8 "$slurpy"
  apparmor_fixed='false'
  if [[ -e "$KUBASH_HOSTS_CSV" ]]; then
    horizontal_rule
    rm $KUBASH_HOSTS_CSV
  fi
  touch $KUBASH_HOSTS_CSV
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
      if [[ "$apparmor_fixed" == 'false' && "$K8S_os" == "coreos" ]]; then
        #apparmor_fix_all_provisioning_hosts
        apparmor_fixed='true'
      fi
      if [[ "$K8S_virt" = "qemu" ]]; then
        squawk 9 "qemu-provisioner $K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3"
        qemu-provisioner $K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3
      elif [[ "$K8S_virt" = "vbox" ]]; then
        vbox-provisioner $K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3
      else
  echo "virtualization technology '$K8S_virt' not recognized"
      fi
      squawk 4 "provisioned"
  done <<< "$slurpy"
}

configure_secondary_network_interfaces () {
  squawk 1 "configure_secondary_network_interfaces"
  slurpy="$(grep -v '^#' $KUBASH_HOSTS_CSV)"
  squawk 8 "$slurpy"
  configure_static_network_addresses_tmp=$(mktemp -d)
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 7 "Os is $K8S_os"
    if [[ $K8S_os =~ debian* || $K8S_os =~ ubuntu* ]]; then
      if [ "$K8S_network2" = 'null' ]; then
        squawk 7 "K8S_network2 is null"
      else
        squawk 7 "K8S_network2 is $K8S_network2"
        export this_interface=eth1
        if [ "$K8S_ip2" = 'dhcp' ]; then
          squawk 7 "network2 is DHCP"
          envsubst < $KUBASH_DIR/templates/debian-dhcp.interface \
          > $configure_static_network_addresses_tmp/kubash_interface
          rsync $KUBASH_RSYNC_OPTS "ssh -p $K8S_sshPort" \
            $configure_static_network_addresses_tmp/kubash_interface \
            $K8S_SU_USER@$K8S_ip1:/tmp/kubash_interface-$this_interface.cfg
          command2run="mv -v /tmp/kubash_interface-$this_interface.cfg /etc/network/interfaces.d/kubash_interface-$this_interface.cfg"
          sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
        else
          squawk 7 "network2 is static setting"
          #sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
          if [ ! "$K8S_ip2" = 'null' ]; then
            export this_ip="address $K8S_ip2"
          fi
          if [ ! "$K8S_subnetmask2" = 'null' ]; then
            export this_netmask="netmask $K8S_subnetmask2"
          fi
          if [ ! "$K8S_routingprefix2" = 'null' ]; then
            export this_network="network $K8S_routingprefix2"
          fi
          if [ ! "$K8S_broadcast2" = 'null' ]; then
            export this_broadcast="broadcast $K8S_broadcast2"
          fi
          if [ ! "$K8S_gateway2" = 'null' ]; then
            export this_gateway="gateway $K8S_gateway2"
          fi
          envsubst < $KUBASH_DIR/templates/debian-static.interface \
          > $configure_static_network_addresses_tmp/kubash_interface
          rsync $KUBASH_RSYNC_OPTS "ssh -p $K8S_sshPort" \
            $configure_static_network_addresses_tmp/kubash_interface \
            $K8S_SU_USER@$K8S_ip1:/tmp/kubash_interface-$this_interface.cfg
          command2run="mv -v /tmp/kubash_interface-$this_interface.cfg /etc/network/interfaces.d/kubash_interface-$this_interface.cfg"
          sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
        fi
        command2run="ifup $this_interface"
        sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
      fi
      if [ "$K8S_network3" = 'null' ]; then
        squawk 7 "K8S_network3 is null"
      else
        squawk 7 "K8S_network3 is $K8S_network3"
        export this_interface=eth2
        if [ "$K8S_ip3" = 'dhcp' ]; then
          envsubst < $KUBASH_DIR/templates/debian-dhcp.interface \
          > $configure_static_network_addresses_tmp/kubash_interface
          rsync $KUBASH_RSYNC_OPTS "ssh -p $K8S_sshPort" \
            $configure_static_network_addresses_tmp/kubash_interface \
            $K8S_SU_USER@$K8S_ip1:/tmp/kubash_interface-$this_interface.cfg
          command2run="mv -v /tmp/kubash_interface-$this_interface.cfg /etc/network/interfaces.d/kubash_interface-$this_interface.cfg"
          sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
        else
          #sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
          if [ ! "$K8S_ip3" = 'null' ]; then
            export this_ip="address $K8S_ip3"
          fi
          if [ ! "$K8S_subnetmask3" = 'null' ]; then
            export this_netmask="netmask $K8S_subnetmask3"
          fi
          if [ ! "$K8S_routingprefix3" = 'null' ]; then
            export this_network="network $K8S_routingprefix3"
          fi
          if [ ! "$K8S_broadcast3" = 'null' ]; then
            export this_broadcast="broadcast $K8S_broadcast3"
          fi
          if [ ! "$K8S_gateway3" = 'null' ]; then
            export this_gateway="gateway $K8S_gateway3"
          fi
          envsubst < $KUBASH_DIR/templates/debian-static.interface \
          > $configure_static_network_addresses_tmp/kubash_interface
          rsync $KUBASH_RSYNC_OPTS "ssh -p $K8S_sshPort" \
            $configure_static_network_addresses_tmp/kubash_interface \
            $K8S_SU_USER@$K8S_ip1:/tmp/kubash_interface-$this_interface.cfg
          command2run="mv -v /tmp/kubash_interface-$this_interface.cfg /etc/network/interfaces.d/kubash_interface-$this_interface.cfg"
          sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
        fi
        command2run="ifup $this_interface"
        sudo_command $K8S_sshPort $K8S_SU_USER $K8S_ip1 "$command2run"
      fi
    else
      squawk 1 "OS not supported by network configurator"
    fi
  done <<< "$slurpy"
  touch $configure_static_network_addresses_tmp/kubash_interface
  rm $configure_static_network_addresses_tmp/kubash_interface
  rmdir $configure_static_network_addresses_tmp
  squawk 19 'secondary network interfaces configured'
}

refresh_network_addresses () {
  squawk 1 "refresh_network_addresses"
  slurpy="$(grep -v '^#' $KUBASH_PROVISION_CSV)"
  squawk 8 "$slurpy"
  rm $KUBASH_HOSTS_CSV
  touch $KUBASH_HOSTS_CSV
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
      net_type=$(echo $K8S_network1|cut -f1 -d=)
      if [[ "$net_type" == "network" ]]; then
        K8S_networkDiscovery=virsh
      else
        K8S_networkDiscovery=arp
      fi
      if [[ "$K8S_networkDiscovery" == "virsh" ]]; then
        if [[ "$K8S_provisionerHost" == "localhost" ]]; then
          countzero=0
          while [[ -z "$this_node_ip" ]]; do
            squawk 7 "checking for IP address"
            squawk 8 "$PSEUDO virsh domifaddr $K8S_node --full"
            this_node_ip=$($PSEUDO virsh domifaddr $K8S_node --full|grep ipv4|head -n1|awk '{print $4}'|cut -f1 -d/ 2>/dev/null)
            if [[ "$countzero" -gt 2 ]]; then
              sleep 2
              fi
            ((++countzero))
          done
        else
          countzero=0
          this_node_ip=''
          while [[ "$this_node_ip" == '' ]]; do
            squawk 7 "checking for IP address"
            squawk 8 "$PSEUDO virsh domifaddr $K8S_node --full"
            this_node_ip=$(ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$PSEUDO virsh domifaddr $K8S_node --full"|grep ipv4|tail -n1|awk '{print $4}'|cut -f1 -d/ 2>/dev/null)
            if [[ "$countzero" -gt 2 ]]; then
              sleep 2
            fi
            ((++countzero))
          done
        fi
      elif [[ "$K8S_networkDiscovery" == "arp" ]]; then
        countzero=0
        this_node_ip=$($PSEUDO arp -n|grep $K8S_mac1|awk '{print $1}'|tail -n 1)
        while [[ -z "$this_node_ip" ]]; do
        squawk 2 "sudo nmap -p 22 $BROADCAST_TO_NETWORK"
        NMAP_OUTPUT=$($PSEUDO nmap -p 22 $BROADCAST_TO_NETWORK)
        squawk 1 "arp -n|grep $K8S_mac1|awk '{print \$1}'"
        this_node_ip=$($PSEUDO arp -n|grep $K8S_mac1|awk '{print $1}'|tail -n 1)
        if [[ "$countzero" -gt 2 ]]; then
          sleep 8
        fi
        sleep 2
        ((++countzero))
        done
      fi
      squawk 5 "adding to $KUBASH_HOSTS_CSV"
      if [[ "$K8S_os" == 'coreos' ]]; then
        this_K8S_user=$K8S_SU_USER
      else
        this_K8S_user=$K8S_user
      fi
      countzero=0
      set +e
      this_ssh_status=254
      until [[ "$this_ssh_status" == '0' ]]
      do
        if [[ "$countzero" -gt 25 ]]; then
          echo "$K8S_node host not coming up investigate $this_node_ip"
          exit 1
        elif [[ "$countzero" -gt 2 ]]; then
          sleep 3
        fi
        squawk 19 "checking ssh $this_node_ip $countzero"
        ssh -o "UserKnownHostsFile /dev/null" -o "StrictHostKeyChecking no" -n -q $this_K8S_user@$this_node_ip exit
        this_ssh_status=$?
        ((++countzero))
      done
      set -e
      KUBASH_CSV_VER=$(cat $KUBASH_CSV_VER_FILE)
      if [ "$KUBASH_CSV_VER" = '2.0.0' ]; then
        squawk 6 "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_sshPort,$K8S_network1,$K8S_mac1,$this_node_ip,$K8S_routingprefix1,$K8S_subnetmask1,$K8S_broadcast1,$K8S_gateway1,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_routingprefix2,$K8S_subnetmask2,$K8S_broadcast2,$K8S_gateway2,$K8S_network3,$K8S_mac3,$K8S_ip3,$K8S_routingprefix3,$K8S_subnetmask3,$K8S_broadcast3,$K8S_gateway3"
        echo "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_sshPort,$K8S_network1,$K8S_mac1,$this_node_ip,$K8S_routingprefix1,$K8S_subnetmask1,$K8S_broadcast1,$K8S_gateway1,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_routingprefix2,$K8S_subnetmask2,$K8S_broadcast2,$K8S_gateway2,$K8S_network3,$K8S_mac3,$K8S_ip3,$K8S_routingprefix3,$K8S_subnetmask3,$K8S_broadcast3,$K8S_gateway3" \
          >> $KUBASH_HOSTS_CSV
      elif [ "$KUBASH_CSV_VER" = '1.0.0' ]; then
        squawk 6 "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_network1,$K8S_mac1,$this_node_ip,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_network3,$K8S_mac3,$K8S_ip3"
        echo "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_sshPort,$K8S_network1,$K8S_mac1,$this_node_ip,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_network3,$K8S_mac3,$K8S_ip3" \
          >> $KUBASH_HOSTS_CSV
      else
        echo 'CSV columns cannot be set CSV Version not recognized'
        exit 1
      fi
      this_node_ip=''
  done <<< "$slurpy"
  squawk 19 'network addresses refreshed'
}

copy_image_to_all_provisioning_hosts () {
  squawk 1 "copy_image_to_all_provisioning_hosts"

  KUBASH_CSV_VER=$(cat $KUBASH_CSV_VER_FILE)
  if [ "$KUBASH_CSV_VER" = '2.0.0' ]; then
    uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f13,14,15,16,17,18|sort|uniq)"
  elif [ "$KUBASH_CSV_VER" = '1.0.0' ]; then
    uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f9,10,11,12,13,14|sort|uniq)"
  else
    echo 'CSV columns cannot be set CSV Version not recognized'
    exit 1
  fi
  squawk 8 "$uniq_hosts"
  copy_image_tmp_para=$(mktemp -d)
  touch $copy_image_tmp_para/hopper
  while IFS="," read -r $uniq_hosts_list_columns
  do
    squawk 9 " $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt"
    if [[ "$KVM_builderHost" == 'localhost' ]]; then
      if [[ "$K8S_provisionerHost" == 'localhost' ]]; then
        copyimagecommand2run="$PSEUDO cp -al $KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      else
        copyimagecommand2run="rsync $KUBASH_RSYNC_OPTS \"ssh -p $K8S_provisionerPort\" $KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerUser@$K8S_provisionerHost:$K8S_provisionerBasePath/$K8S_os-$KVM_BASE_IMG;ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost \"cp -al $K8S_provisionerBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG\""
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      fi
    else
      if [[ "$K8S_provisionerHost" == "$KVM_builderHost" ]]; then
        copyimagecommand2run="$PSEUDO cp -al $KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      else
        copyimagecommand2run="ssh -n -p $KVM_builderPort $K8S_builderUser@$K8S_builderHost 'rsync $KUBASH_RSYNC_OPTS \"ssh -p $K8S_provsionerPort\" $KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerUser@$K8S_provisionerHost:$K8S_provisionerBasePath/$K8S_os-$KVM_BASE_IMG; ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost \"cp -al $K8S_provisionerBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG\"'"
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      fi
    fi
  done <<< "$uniq_hosts"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_image_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_image_tmp_para/hopper
  else
    bash $copy_image_tmp_para/hopper
  fi
  rm -Rf $copy_image_tmp_para
}

apparmor_fix_all_provisioning_hosts () {
  squawk 1 "apparmor_fix_all_provisioning_hosts"
  KUBASH_CSV_VER=$(cat $KUBASH_CSV_VER_FILE)
  if [ "$KUBASH_CSV_VER" = '2.0.0' ]; then
    uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f13,14,15,16,17,18|sort|uniq)"
  elif [ "$KUBASH_CSV_VER" = '1.0.0' ]; then
    uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f9,10,11,12,13,14|sort|uniq)"
  else
    echo 'CSV columns cannot be set CSV Version not recognized'
    exit 1
  fi
  squawk 8 "$uniq_hosts"
  apparmor_tmp_para=$(mktemp -d)
  touch $apparmor_tmp_para/hopper
  #CURLY="bash $(curl -Ls https://raw.githubusercontent.com/kubash/kubash/master/scripts/libvirtarmor)"
  CURLY="curl -Ls https://raw.githubusercontent.com/kubash/kubash/master/scripts/libvirtarmor|bash"
  #"K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt"
  while IFS="," read -r $uniq_hosts_list_columns
  do
    if [[ "$K8S_provisionerHost" = 'localhost' ]]; then
      echo "$CURLY" >> $apparmor_tmp_para/hopper
    else
      squawk 9 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost \"$CURLY\""
      echo "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost \"$CURLY\"" \
        >> $apparmor_tmp_para/hopper
    fi
  done <<< "$uniq_hosts"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $apparmor_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $apparmor_tmp_para/hopper
  else
    bash $apparmor_tmp_para/hopper
  fi
  rm -Rf $apparmor_tmp_para
}

do_nginx_ingress () {
  INGRESS_NAME=$1
  KUBECONFIG=$KUBECONFIG \
    helm install \
    stable/nginx-ingress \
    --name $INGRESS_NAME \
    --set rbac.create=true
}

demo () {
  do_postgres
  do_rabbitmq
  do_percona
  do_jupyter
  do_mongodb
  do_jenkins
  do_kafka
  do_redis
}

do_redis () {
  cd $KUBASH_DIR/submodules/openebs/k8s/demo/redis
  kubectl --kubeconfig=$KUBECONFIG apply -f \
   redis-statefulset.yml
}

do_postgres () {
  cd $KUBASH_DIR/submodules/openebs/k8s/demo/crunchy-postgres
  KUBECONFIG=$KUBECONFIG bash run.sh
}

do_rabbitmq () {
  cd $KUBASH_DIR/submodules/openebs/k8s/demo/rabbitmq
  KUBECONFIG=$KUBECONFIG bash run.sh
}

do_percona () {
  cd $KUBASH_DIR/submodules/openebs/k8s/demo/percona
  kubectl --kubeconfig=$KUBECONFIG apply -f \
   demo-percona-mysql-pvc.yaml
}

do_jupyter () {
  cd $KUBASH_DIR/submodules/openebs/k8s/demo/jupyter
  kubectl --kubeconfig=$KUBECONFIG apply -f \
   demo-jupyter-openebs.yaml
}

do_mongodb () {
  cd $KUBASH_DIR/submodules/openebs/k8s/demo/mongodb
  kubectl --kubeconfig=$KUBECONFIG apply -f \
   mongo-statefulset.yml
}

do_jenkins () {
  cd $KUBASH_DIR/submodules/openebs/k8s/demo/jenkins
  kubectl --kubeconfig=$KUBECONFIG apply -f \
   jenkins.yml
}

do_kafka () {
  squawk 1 " do_kafka"
  KUBECONFIG=$KUBECONFIG \
  helm \
    repo add incubator http://storage.googleapis.com/kubernetes-charts-incubator

  KUBECONFIG=$KUBECONFIG \
  helm install \
  --name my-kafka \
  incubator/kafka \
    --set persistence.storageClass=openebs-kafka
}

do_net () {
  squawk 1 " do_net"
  slurpy="$(grep -v '^#' $KUBASH_PROVISION_CSV)"
  if [[ $K8S_NET == "calico" ]]; then
    kubectl --kubeconfig=$KUBECONFIG apply -f $CALICO_RBAC_URL
    kubectl --kubeconfig=$KUBECONFIG apply -f $CALICO_URL
  elif [[ $K8S_NET == "flannel" ]]; then
    kubectl --kubeconfig=$KUBECONFIG apply -f $FLANNEL_URL
  elif [[ $K8S_NET == "weavenet" ]]; then
    VERSION="$(kubectl version | base64 | tr -d '\n')"
    kubectl --kubeconfig=$KUBECONFIG apply -f "https://cloud.weave.works/k8s/net?k8s-version=${VERSION}"
  fi
}

do_searchlight () {
  squawk 1 " do_searchlight"
  kubectl --kubeconfig=$KUBECONFIG apply -f \
    $KUBASH_DIR/templates/searchlight.yaml
}

taint_ingress () {
  squawk 1 " taint_ingress $@"
  count_ingress=0
  for ingress_node in "$@"
  do
    squawk 5 "kubectl --kubeconfig=$KUBECONFIG taint --overwrite node $ingress_node IngressOnly=true:NoSchedule"
    kubectl --kubeconfig=$KUBECONFIG taint --overwrite node $ingress_node IngressOnly=true:NoSchedule
    squawk 5 "kubectl --kubeconfig=$KUBECONFIG label --overwrite node $ingress_node ingress=true"
    kubectl --kubeconfig=$KUBECONFIG label --overwrite node $ingress_node ingress=true
    ((++count_ingress))
  done
  if [[ $count_ingress -eq 0 ]]; then
    echo 'No ingress nodes found!'
    exit 1
  fi
}

taint_all_ingress () {
  squawk 1 " taint_all_ingress $@"
  count_all_ingress=0
  nodes_to_taint=' '
  while IFS="," read -r $csv_columns
  do
    squawk 185 "ROLE $K8S_role $K8S_user $K8S_ip1 $K8S_sshPort"
    if [[ "$K8S_role" = "ingress" ]]; then
      squawk 5 "ROLE $K8S_role $K8S_user $K8S_ip1 $K8S_sshPort"
      squawk 121 "nodes_to_taint $K8S_node $nodes_to_taint"
      new_nodes_to_taint="$K8S_node $nodes_to_taint"
      nodes_to_taint="$new_nodes_to_taint"
      ((++count_all_ingress))
    fi
  done <<< "$kubash_hosts_csv_slurped"
  echo "count_all_ingress $count_all_ingress"
  if [[ $count_all_ingress -eq 0 ]]; then
    squawk 150 "slurpy -----> $(echo $kubash_hosts_csv_slurped)"
    echo 'No ingress nodes found!!!'
    exit 1
  else
    squawk 185 "ROLE $K8S_role $K8S_user $K8S_ip1 $K8S_sshPort"
    squawk 101 "taint these nodes_to_taint=$K8S_node $nodes_to_taint"
    taint_ingress $nodes_to_taint
  fi
}

do_dashboard () {
  squawk 1 " do_dashboard"
  kubectl --kubeconfig=$KUBECONFIG \
    apply -f \
    https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
}

do_voyager () {
  squawk 1 " do_voyager"
  #taint_all_ingress
  if [ "$VOYAGER_BY_HELM" = "true" ]; then
  KUBECONFIG=$KUBECONFIG \
  helm install stable/voyager --name voyager \
    --set cloudProvider=$VOYAGER_PROVIDER \
    --set apiserver.ca="$(onessl get kube-ca)" \
    $VOYAGER_ADMISSIONWEBHOOK
  else
    KUBECONFIG=$KUBECONFIG \
    curl -fsSL \
    https://raw.githubusercontent.com/appscode/voyager/6.0.0/hack/deploy/voyager.sh \
        | bash -s -- --provider=$VOYAGER_PROVIDER --rbac
  fi
}

do_linkerd () {
  squawk 1 " do_linkerd"
  kubectl --kubeconfig=$KUBECONFIG \
    create ns l5d-system
  kubectl --kubeconfig=$KUBECONFIG \
    -n l5d-system \
    apply -f \
    $LINKERD_URL
  squawk 1 "kubectl create ns l5d-system"
  squawk 1 "kubectl apply -f https://raw.githubusercontent.com/linkerd/linkerd-examples/master/k8s-daemonset/k8s/linkerd-ingress-controller.yml -n l5d-system"
  squawk 1 "visit this page: https://buoyant.io/2017/04/06/a-service-mesh-for-kubernetes-part-viii-linkerd-as-an-ingress-controller/"
}

do_traefik () {
  squawk 1 " do_traefik"
  if [[ $USE_TRAEFIK_RBAC == 'true' ]]; then
    kubectl --kubeconfig=$KUBECONFIG apply -f \
    $KUBASH_DIR/templates/traefik-rbac.yaml
  fi

  if [[ $USE_TRAEFIK_DAEMON_SET == 'true' ]]; then
    TRAEFIK_URL=$KUBASH_DIR/templates/traefik-ds.yaml
  else
    TRAEFIK_URL=$KUBASH_DIR/templates/traefik-deployment.yaml
  fi
  kubectl --kubeconfig=$KUBECONFIG apply -f \
    $TRAEFIK_URL
}

do_tiller () {
  w8_kubedns
  squawk 1 " do_tiller"
  #kubectl --kubeconfig=$KUBECONFIG create serviceaccount tiller --namespace kube-system
  kubectl --kubeconfig=$KUBECONFIG create -f $KUBASH_DIR/tiller/rbac-tiller-config.yaml
  sleep 5
  KUBECONFIG=$KUBECONFIG \
   helm init --service-account tiller
}

write_ansible_hosts () {
  write_ansible_kubespray_hosts
}

write_ansible_kubeadm2ha_hosts () {
  squawk 1 " Make a hosts file for kubeadm2ha ansible"
  # Make a fresh hosts file
  slurpy="$(grep -v '^#' $KUBASH_HOSTS_CSV)"
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    horizontal_rule
    rm $KUBASH_ANSIBLE_HOSTS
    touch $KUBASH_ANSIBLE_HOSTS
  else
    touch $KUBASH_ANSIBLE_HOSTS
  fi
  # Write all hosts to inventory for id
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    echo "$K8S_node ansible_ssh_host=$K8S_ip1 ansible_ssh_port=$K8S_sshPort ansible_user=$K8S_provisionerUser" >> $KUBASH_ANSIBLE_HOSTS
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[primary-master]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"
  echo '' >> $KUBASH_ANSIBLE_HOSTS
  echo '[secondary-masters]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"
  echo '' >> $KUBASH_ANSIBLE_HOSTS
  echo '[masters]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[etcd]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "etcd" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
      if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
        echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
      fi
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[minions]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[nodes]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[nginx]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "ingress" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[nfs-server]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "nfs-server" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  cat $KUBASH_DIR/templates/my-cluster.inventory.tail >> $KUBASH_ANSIBLE_HOSTS
}

write_ansible_openshift_hosts () {
  squawk 1 " Make a hosts file for openshift ansible"
  # Make a fresh hosts file
  slurpy="$(grep -v '^#' $KUBASH_HOSTS_CSV)"
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    horizontal_rule
    rm $KUBASH_ANSIBLE_HOSTS
    touch $KUBASH_ANSIBLE_HOSTS
  else
    touch $KUBASH_ANSIBLE_HOSTS
  fi
  # Write all hosts to inventory for id
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    echo "$K8S_node ansible_ssh_host=$K8S_ip1 ansible_ssh_port=$K8S_sshPort ansible_user=$K8S_provisionerUser" >> $KUBASH_ANSIBLE_HOSTS
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS
  echo '[OSEv3:children]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'masters' >> $KUBASH_ANSIBLE_HOSTS
  echo 'nodes' >> $KUBASH_ANSIBLE_HOSTS
  echo 'etcd' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[OSEv3:vars]
openshift_deployment_type=origin
deployment_type=origin
openshift_release=v3.7
openshift_release=v3.7
openshift_pkg_version=-3.7.0
debug_level=2
openshift_disable_check=disk_availability,memory_availability,docker_storage,docker_image_availability
openshift_master_default_subdomain=apps.cbqa.in
osm_default_node_selector="region=lab"' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[masters]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[etcd]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "etcd" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
      if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
        echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
      fi
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  openshift_labels="openshift_node_labels=\"{'region': '$OPENSHIFT_REGION', 'zone': '$OPENSHIFT_ZONE'}\" openshift_schedulable=true"
  echo '[nodes]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[ingress]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "ingress" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS
}

write_ansible_kubespray_hosts () {
  squawk 1 " Make a hosts file for ansible"
  # Make a fresh hosts file
  slurpy="$(grep -v '^#' $KUBASH_HOSTS_CSV)"
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    horizontal_rule
    rm $KUBASH_ANSIBLE_HOSTS
    touch $KUBASH_ANSIBLE_HOSTS
  else
    touch $KUBASH_ANSIBLE_HOSTS
  fi
  # Write all hosts to inventory for id
  set_csv_columns
  echo '[all]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    echo "$K8S_node ip=$K8S_ip1 etcd_member_name=$K8S_node ansible_ssh_host=$K8S_ip1 ansible_ssh_port=$K8S_sshPort ansible_user=$K8S_provisionerUser" >> $KUBASH_ANSIBLE_HOSTS
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[kube-node]' >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[kube-node:vars]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'ansible_ssh_extra_args="-o StrictHostKeyChecking=no"' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[calico-rr]' >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS
  echo '[kube-master]' >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[kube-master:vars]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'ansible_ssh_extra_args="-o StrictHostKeyChecking=no"' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[etcd]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "etcd"  || "$K8S_role" == "primary_etcd" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
        echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
      fi
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[vault]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "etcd"  || "$K8S_role" == "primary_etcd" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
      if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
        echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
      fi
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[ingress]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "ingress" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[k8s-cluster:children]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'kube-node' >> $KUBASH_ANSIBLE_HOSTS
  echo 'kube-master' >> $KUBASH_ANSIBLE_HOSTS
}

removestalekeys () {
  squawk 1 " removestalekeys $@"
  node_ip=$1
  ssh-keygen -f "$HOME/.ssh/known_hosts" -R "$node_ip"
}

w8_kubedns () {
  squawk 3 "wait on Kube-DNS to become available" -n
  sleep 1

  # while loop
  kubedns_countone=1
  # timeout for 15 minutes
  while [[ $kubedns_countone -lt 151 ]]
  do
    squawk 1 '.' -n
    RESULT=$(kubectl --kubeconfig=$KUBECONFIG get po --namespace kube-system |grep kube-dns|grep Running)
    if [[ "$RESULT" ]]; then
        sleep 3
        squawk 1 '.' -n
        squawk 3 "$RESULT"
        break
    fi
    ((++kubedns_countone))
    sleep 3
  done

  echo "Kube-DNS is now up and running"
  sleep 1
}

w8_kubectl () {
  squawk 3 "Wait on the K8S cluster to become available" -n
  squawk 3 "Errors on the first few tries are normal give it a few minutes to spin up" -n
  sleep 15
  # while loop
  countone_w8_kubectl=1
  countlimit_w8_kubectl=151
  # timeout for 15 minutes
  while [[ "$countone_w8_kubectl" -lt "$countlimit_w8_kubectl" ]]; do
    squawk 1 '.' -n
    if [[ "$VERBOSITY" -gt "11" ]] ; then
      kubectl --kubeconfig=$KUBECONFIG get pods -n kube-system | grep kube-apiserver
    fi
    result=$(kubectl --kubeconfig=$KUBECONFIG get pods -n kube-system 2>/dev/null | grep kube-apiserver |grep Running)
    squawk 3 "Result is $result"
    if [[ "$result" ]]; then
      squawk 5 "Result nailed $result"
      ((++countone_w8_kubectl))
      break
    fi
    ((++countone_w8_kubectl))
    squawk 9 "$countone_w8_kubectl"
    if [[ "$countone_w8_kubectl" -ge "$countlimit_w8_kubectl"  ]]; then
      echo 'Master is not coming up, investigate, breaking'
      exit 1
    fi
    sleep 5
  done
  squawk 3  "."
  squawk 1 "kubectl commands are now able to interact with the kubernetes cluster"
}

w8_node () {
  node_name=$1
  squawk 3 "Wait on the K8S node $node_name to become available" -n
  sleep 5
  # while loop
  countone_w8_node=1
  countlimit_w8_node=151
  # timeout for 15 minutes
  set +e
  while [[ "$countone_w8_node" -lt "$countlimit_w8_node" ]]; do
    squawk 1 '.' -n
    if [[ "$VERBOSITY" -gt "11" ]] ; then
      kubectl --kubeconfig=$KUBECONFIG get node $node_name
    fi
    result=$(kubectl --kubeconfig=$KUBECONFIG get node $node_name | grep -v NotReady | grep Ready)
    squawk 3 "Result is $result"
    if [[ "$result" ]]; then
      squawk 5 "Result nailed $result"
      ((++countone_w8_node))
      break
    fi
    ((++countone_w8_node))
    squawk 9 "$countone_w8_node"
    sleep 3
  done
  set -e
  squawk 3  "."
  squawk 3  "kubectl commands are now able to interact with the kubernetes node"
}

remove_vagrant_user () {
  remove_vagrant_user_tmp_para=$(mktemp -d)
  squawk 2 ' Remove vagrant user from all hosts using ssh'
  touch $remove_vagrant_user_tmp_para/hopper
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 1 "$K8S_ip1"
    squawk 3 "$K8S_user"
    squawk 3 "$K8S_os"
    if [[ "$K8S_os" == 'coreos' ]]; then
      squawk 9 'coreos so skipping'
    else
      REMMY="userdel -fr vagrant"
      squawk 6 "ssh -n -p $K8S_sshPort $K8S_user@$K8S_ip1 \"$REMMY\""
      echo "ssh -n -p $K8S_sshPort $K8S_user@$K8S_ip1 \"$REMMY\""\
        >> $remove_vagrant_user_tmp_para/hopper
    fi
  done < $KUBASH_HOSTS_CSV

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $remove_vagrant_user_tmp_para/hopper
  fi

  set +e #some of the new builds have been erroring out as vagrant has been removed already, softening
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $remove_vagrant_user_tmp_para/hopper
  else
    bash $remove_vagrant_user_tmp_para/hopper
  fi
  set -e # End softening

  rm -Rf $remove_vagrant_user_tmp_para
}

hostname_in_parallel () {
  hostname_tmp_para=$(mktemp -d --suffix='.para.tmp')
  squawk 2 ' Hostnaming all hosts using ssh'
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    my_HOST=$K8S_node
    my_IP=$K8S_ip1
    my_PORT=$K8S_sshPort
    my_USER=$K8S_provisionerUser
    command2run="ssh -n -p $my_PORT $my_USER@$my_IP '$PSEUDO hostname $my_HOST && echo $my_HOST | $PSEUDO tee /etc/hostname && echo \"127.0.1.1 $my_HOST.$my_DOMAIN $my_HOST  \" | $PSEUDO tee -a /etc/hosts'"
    squawk 5 "$command2run"
    echo "$command2run" \
      >> $hostname_tmp_para/hopper
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $hostname_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $hostname_tmp_para/hopper
  else
    bash $hostname_tmp_para/hopper
  fi
  rm -Rf $hostname_tmp_para
}

ping_in_parallel () {
  ping_tmp_para=$(mktemp -d --suffix='.para.tmp')
  squawk 2 ' Pinging all hosts using ssh'
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 1 "$K8S_ip1"
    squawk 3 "$K8S_user"
    MY_ECHO="hostname; echo '$K8S_ip1 $K8S_provisionerUser pong'" 
    squawk 5 "ssh -n -p $K8S_sshPort $K8S_provisionerUser@$K8S_ip1 \"$MY_ECHO\""
    echo "ssh -n -p $K8S_sshPort $K8S_provisionerUser@$K8S_ip1 \"$MY_ECHO\""\
        >> $ping_tmp_para/hopper
  done < $KUBASH_HOSTS_CSV

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $ping_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $ping_tmp_para/hopper
  else
    bash $ping_tmp_para/hopper
  fi
  rm -Rf $ping_tmp_para
}

ping () {
  squawk 2 ' Pinging all hosts using ssh'
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 1 "$K8S_ip1"
    squawk 3 "$K8S_user"
    if [[ "$VERBOSITY" -gt 10 ]]; then
      ssh -n -p $K8S_sshPort $K8S_user@$K8S_ip1 'echo pong'
      squawk 3 "$K8S_provisionerUser"
      ssh -n -p $K8S_sshPort $K8S_provisionerUser@$K8S_ip1 'echo pong'
    else
      ssh -n -p $K8S_sshPort $K8S_user@$K8S_ip1 'touch /tmp/sshpingtest-kubash'
      ssh -n -p $K8S_sshPort $K8S_provisionerUser@$K8S_ip1 'touch /tmp/sshpingtest-kubash'
    fi
  done < $KUBASH_HOSTS_CSV
}

ansible-ping () {
  squawk 1 ' Pinging all hosts using Ansible'
  ansible -i $KUBASH_ANSIBLE_HOSTS -m ping all
}

chkdir () {
  if [[ ! -w $1 ]] ; then
    sudo mkdir -p $1
    sudo chown $USER. $1
  fi
  if [[ ! -w $1 ]] ; then
    echo "Cannot write to $1, please check your permissions"
    exit 2
  fi
}

dotfiles_install () {
  squawk 1 ' Adjusting dotfiles'
  touch $HOME/.zshrc
  touch $HOME/.bashrc
  # make a bin dir in $HOME and add it to path
  chkdir $KUBASH_BIN
  LINE_TO_ADD="$(printf "export PATH=%s:\$PATH" $KUBASH_BIN)"
  TARGET_FILE_FOR_ADD=$HOME/.bashrc
  check_if_line_exists || add_line_to
  TARGET_FILE_FOR_ADD=$HOME/.zshrc
  check_if_line_exists || add_line_to

  LINE_TO_ADD="export GOPATH=$GOPATH"
  TARGET_FILE_FOR_ADD=$HOME/.bashrc
  check_if_line_exists || add_line_to
  TARGET_FILE_FOR_ADD=$HOME/.zshrc
  check_if_line_exists || add_line_to
}

do_grab () {
  squawk 1 " do_grab"
  do_grab_master_count=0
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master" ]]; then
      if [[ "$do_grab_master_count" -lt "1" ]]; then
        master_grab_kube_config $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_sshPort
      fi
      ((++do_grab_master_count))
    fi
  done < $KUBASH_HOSTS_CSV
}

check_coreos () {
  squawk 1 " check_coreos"
  do_coreos_init_count=0
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_os" == "coreos" ]]; then
      if [[ "$do_coreos_init_count" -lt "1" ]]; then
        do_coreos_initialization
  break
      fi
      ((++do_coreos_init_count))
    fi
  done < $KUBASH_HOSTS_CSV
}

master_join () {
  squawk 1 " master_join $@"
  my_node_name=$1
  my_node_ip=$2
  my_node_user=$3
  my_node_port=$4


  if [[ "$DO_MASTER_JOIN" == "true" ]] ; then
    #finish_pki_for_masters $my_node_user $my_node_ip $my_node_name $my_node_port
    ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSUEDO hostname;$PSUEDO  uname -a"
    run_join=$(cat $KUBASH_CLUSTER_DIR/join.sh)
    squawk 1 " run join $run_join"
    ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO $run_join"
    w8_node $my_node_name
    rolero $my_node_name master
  fi
}

master_init_join () {
  squawk 1 " master_init_join $@"
  my_master_name=$1
  my_master_ip=$2
  my_master_user=$3
  my_master_port=$4
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi

  #finish_pki_for_masters $my_master_user $my_master_ip $my_master_name $my_master_port

  rm -f $KUBASH_CLUSTER_DIR/ingress.ip1
  rm -f $KUBASH_CLUSTER_DIR/ingress.ip2
  rm -f $KUBASH_CLUSTER_DIR/ingress.ip3
  rm -f $KUBASH_CLUSTER_DIR/primary_master.ip1
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "ingress" ]]; then
      echo "$K8S_ip1" >> $KUBASH_CLUSTER_DIR/ingress.ip1
      echo "$K8S_ip2" >> $KUBASH_CLUSTER_DIR/ingress.ip2
      echo "$K8S_ip3" >> $KUBASH_CLUSTER_DIR/ingress.ip3
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_ip1" >> $KUBASH_CLUSTER_DIR/primary_master.ip1
    fi
  done <<< "$kubash_hosts_csv_slurped"
  if [[ -e  "$KUBASH_CLUSTER_DIR/ingress.ip2" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/ingress.ip2)
  elif [[ -e  "$KUBASH_CLUSTER_DIR/ingress.ip3" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/ingress.ip3)
  elif [[ -e  "$KUBASH_CLUSTER_DIR/ingress.ip1" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/ingress.ip1)
  elif [[ -e  "$KUBASH_CLUSTER_DIR/primary_master.ip1" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/primary_master.ip1)
  else
    echo 'no load balancer ip'
    exit 1
  fi

  if [[ "DO_KEEPALIVED" == 'true' ]]; then
    #keepalived
    setup_keepalived_tmp=$(mktemp -d)

    MASTER_VIP=$my_master_ip \
    envsubst < $KUBASH_DIR/templates/check_apiserver.sh \
    > $setup_keepalived_tmp/check_apiserver.sh
    copy_in_parallel_to_role master $setup_keepalived_tmp/check_apiserver.sh "/tmp/"
    command2run='sudo  mv /tmp/check_apiserver.sh /etc/keepalived/'
    do_command_in_parallel_on_role "master" "$command2run"

    MASTER_OR_BACKUP=BACKUP \
    PRIORITY=100 \
    INTERFACE_NET=$INTERFACE_NET \ 
    MASTER_VIP=$my_master_ip \
    envsubst < $KUBASH_DIR/templates/keepalived.conf
    > $setup_keepalived_tmp/keepalived.conf
    copy_in_parallel_to_role master $setup_keepalived_tmp/keepalived.conf "/tmp/"
    command2run='sudo  mv /tmp/keepalived.conf /etc/keepalived/'
    do_command_in_parallel_on_role "master" "$command2run"
    # Then let's overwrite that on our primary master
    MASTER_OR_BACKUP=MASTER \
    PRIORITY=101 \
    INTERFACE_NET=$INTERFACE_NET \ 
    MASTER_VIP=$my_master_ip \
    envsubst < $KUBASH_DIR/templates/keepalived.conf
    > $setup_keepalived_tmp/keepalived.conf
    rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $setup_keepalived_tmp/keepalived.conf $my_master_user@$my_master_ip:/tmp/keepalived.conf
    command2run='sudo  mv /tmp/keepalived.conf /etc/keepalived/'
    ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"

    rm -f $setup_keepalived_tmp/keepalived.conf $setup_keepalived_tmp/check_apiserver.sh
    rmdir $setup_keepalived_tmp
  fi

  squawk 3 " master_init_join $my_master_name $my_master_ip $my_master_user $my_master_port"
  if [[ "$DO_MASTER_JOIN" == "true" ]] ; then
    ssh -n -p $my_master_port $my_master_user@$my_master_ip "$PSEUDO hostname;$PSEUDO  uname -a"
    my_grep='kubeadm join --token'
    squawk 3 'master_init_join kubeadm init'
    command2run='sudo systemctl restart kubelet'
    do_command_in_parallel_on_role "primary_master" "$command2run"
    do_command_in_parallel_on_role "master" "$command2run"
    #ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"
    command2run='sudo systemctl stop kubelet'
    #ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"
    do_command_in_parallel_on_role "primary_master" "$command2run"
    do_command_in_parallel_on_role "master" "$command2run"
    command2run='sudo netstat -ntpl'
    do_command_in_parallel_on_role "master" "$command2run"
    ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"
    if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
      #kubeadmin_config_tmp=$(mktemp)
      #KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
      #my_master_ip=$my_master_ip \
      #load_balancer_ip=$K8S_load_balancer_ip \
      #my_KUBE_CIDR=$my_KUBE_CIDR \
      #ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/endpoints.line) \
      #envsubst  < $KUBASH_DIR/templates/kubeadm-config-1.12.yaml \
        #> $kubeadmin_config_tmp
      #squawk 19 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $my_master_port' $kubeadmin_config_tmp  $my_master_user@$my_master_ip:/tmp/config.yaml"
      #rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $kubeadmin_config_tmp  $my_master_user@$my_master_ip:/tmp/config.yaml
      #squawk 6 "kubedmin_config_tmp =\n $(cat $kubeadmin_config_tmp)" -e
      #rm $kubeadmin_config_tmp
      my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/etc/kubernetes/kubeadmcfg.yaml"
      squawk 5 "$my_KUBE_INIT"
      run_join=$(ssh -n $my_master_user@$my_master_ip "$my_KUBE_INIT" | tee $TMP/rawresults.k8s | grep -- "$my_grep")
      if [[ -z "$run_join" ]]; then
        horizontal_rule
        echo 'kubeadm init failed!'
        exit 1
      fi
      #command2run='sudo  rm -f /tmp/config.yaml'
      #ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"
    else
      #my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --pod-network-cidr=$my_KUBE_CIDR"
      #my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/etc/kubernetes/kubeadmcfg-external.yaml"
      my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/etc/kubernetes/kubeadmcfg.yaml"
      squawk 5 "$my_KUBE_INIT"
      run_join=$(ssh -n $my_master_user@$my_master_ip "$my_KUBE_INIT" | tee $TMP/rawresults.k8s | grep -- "$my_grep")
      if [[ -z "$run_join" ]]; then
        horizontal_rule
        echo 'kubeadm init failed!'
        exit 1
      fi
    fi
    squawk 9 "$(cat $TMP/rawresults.k8s)"
    echo $run_join > $KUBASH_CLUSTER_DIR/join.sh
    if [[ "$KUBASH_OIDC_AUTH" == 'true' ]]; then
      command2run='sudo sed -i "/- kube-apiserver/a\    - --oidc-issuer-url=https://accounts.google.com\n    - --oidc-username-claim=email\n    - --oidc-client-id=" /etc/kubernetes/manifests/kube-apiserver.yaml'
      ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"
    fi
    master_grab_kube_config $my_master_name $my_master_ip $my_master_user $my_master_port
    sudo_command $my_master_port $my_master_user $my_master_ip "$command2run"
    w8_kubectl
    rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $KUBASH_DIR/scripts/grabkubepki $my_master_user@$my_master_ip:/tmp/grabkubepki
    command2run="bash /tmp/grabkubepki"
    sudo_command $this_port $this_user $this_host "$command2run"
    rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $my_master_user@$my_master_ip:/tmp/kube-pki.tgz $KUBASH_CLUSTER_DIR/
    squawk 5 'and copy it to master and etcd hosts'
    copy_in_parallel_to_role "master" "$KUBASH_CLUSTER_DIR/kube-pki.tgz" "/tmp/"
    if [ "$VERBOSITY" -gt 5 ]; then
      command2run='cd /; tar ztvf /tmp/kube-pki.tgz'
      do_command_in_parallel_on_role "master"        "$command2run"
    fi
    command2run='cd /; tar zxf /tmp/kube-pki.tgz'
    do_command_in_parallel_on_role "master"        "$command2run"
    command2run='rm /tmp/kube-pki.tgz'
    do_command_in_parallel_on_role "master"        "$command2run"
    do_net
  fi
}

master_grab_kube_config () {
  my_master_name=$1
  my_master_ip=$2
  my_master_user=$3
  my_master_port=$4
  squawk 1 ' refresh-kube-config'
  squawk 3 " master_grab_kube_config $my_master_name $my_master_ip $my_master_user $my_master_port"
  squawk 5 "mkdir -p ~/.kube && sudo cp -av /etc/kubernetes/admin.conf ~/.kube/config && sudo chown -R $my_master_user. ~/.kube"
  ssh -n -p $my_master_port $my_master_user@$my_master_ip "mkdir -p ~/.kube && sudo cp -av /etc/kubernetes/admin.conf ~/.kube/config && sudo chown -R $my_master_user. ~/.kube"

  chkdir $HOME/.kube
  squawk 3 ' grab config'
  rm -f $KUBASH_CLUSTER_CONFIG
  ssh -n -p $my_master_port $my_master_user@$my_master_ip 'cat .kube/config' > $KUBASH_CLUSTER_CONFIG
  sed -i "s/^  name: kubernetes$/  name: $KUBASH_CLUSTER_NAME/" $KUBASH_CLUSTER_CONFIG
  sed -i "s/^    cluster: kubernetes$/    cluster: $KUBASH_CLUSTER_NAME/" $KUBASH_CLUSTER_CONFIG

  sudo chmod 600 $KUBASH_CLUSTER_CONFIG
  sudo chown -R $USER. $KUBASH_CLUSTER_CONFIG
}

node_join () {
  my_node_name=$1
  my_node_ip=$2
  my_node_user=$3
  my_node_port=$4
  squawk 1 " node_join $my_node_name $my_node_ip $my_node_user $my_node_port"
  if [[ "$DO_NODE_JOIN" == "true" ]] ; then
    result=$(ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO hostname;$PSEUDO uname -a")
    squawk 3 "hostname and uname is $result"
    squawk 3 "Kubeadmin join"
    run_join=$(cat $KUBASH_CLUSTER_DIR/join.sh)
    #result=$(ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO $run_join --ignore-preflight-errors=IsPrivilegedUser")
    result=$(ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO $run_join --ignore-preflight-errors=IsPrivilegedUser")
    squawk 3 "run_join result is $result"
    w8_node $my_node_name
    rolero $my_node_name node
  fi
}

checks () {
  squawk 5 " checks"
  check_cmd git
  check_cmd nc
  check_cmd ssh
  check_cmd rsync
  check_cmd ansible
  check_cmd curl
  check_cmd nmap
  check_cmd uname
  check_cmd envsubst
  check_cmd ct
  check_cmd jinja2
  check_cmd yaml2json
  check_cmd jq
  check_cmd rlwrap
  check_cmd expr
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    check_cmd parallel
  fi
  check_cmd 'grep'
  check_cmd 'sed'
}


initialize () {
  squawk 1 " initialize"
  check_csv
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  check_coreos
  process_hosts_csv
}

kubeadm2ha_initialize () {
  squawk 1 "kubeadm2ha initialize"
  check_csv
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    squawk 1 'Hosts file found, not overwriting'
  else
    write_ansible_kubeadm2ha_hosts
  fi
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/cluster-setup.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/cluster-dashboard.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/cluster-load-balanced.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/etcd-operator.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/local-access.yaml
}

kubespray_initialize () {
  squawk 1 "kubespray initialize"
  check_csv
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    squawk 1 'Hosts file found, not overwriting'
  else
    write_ansible_kubespray_hosts
  fi
  #yes yes|ansible-playbook \
    #-i $KUBASH_ANSIBLE_HOSTS \
    #-e kube_version=$KUBE_VERSION \
    #$KUBASH_DIR/submodules/kubespray/reset.yml
  ansible-playbook \
    -i $KUBASH_ANSIBLE_HOSTS \
    -e kube_version=$KUBE_VERSION \
    $KUBASH_DIR/submodules/kubespray/cluster.yml
}

openshift_initialize () {
  squawk 1 "openshift initialize"
  check_csv
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    squawk 1 'Hosts file found, not overwriting'
  else
    write_ansible_openshift_hosts
  fi
  ansible-playbook \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/openshift-ansible/playbooks/prerequisites.yml
  ansible-playbook \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/openshift-ansible/playbooks/deploy_cluster.yml
}

read_csv () {
  squawk 1 " read_csv"
  read_master_count=0

  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 5 "$K8S_node $K8S_user $K8S_ip1 $K8S_sshPort $K8S_role $K8S_provisionerUser $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort"
    if [[ "$K8S_role" == "master" ]]; then
      if [[ "$read_master_count" -lt "1" ]]; then
        echo "master_init_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_sshPort"
      else
        echo "master_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_sshPort"
      fi
      ((++read_master_count))
    fi
  done < $KUBASH_HOSTS_CSV

  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" || "$K8S_role" == "ingress" ]]; then
      echo "node_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_sshPort"
    fi
  done < $KUBASH_HOSTS_CSV
}

check_csv () {
  squawk 4 " check_csv"
  if [[ ! -e $KUBASH_HOSTS_CSV ]]; then
    horizontal_rule
    echo "$KUBASH_HOSTS_CSV file not found!"
    echo "You must provision a cluster first, and specify a valid cluster with the --clustername option and place your hosts.csv file in its directory!"
    exit 1
  fi
}

grant () {
  user_role=$3
  grant_tmp=$(mktemp)
  USERNAME_OF_ADMIN=$1 \
  EMAIL_ADDRESS_OF_ADMIN=$2 \
  envsubst < $KUBASH_DIR/templates/$user_role-role \
    > $grant_tmp
  kubectl --kubeconfig=$KUBECONFIG apply -f $grant_tmp
  rm $grant_tmp
}

grant_users () {
  grant_users_tmp_para=$(mktemp -d --suffix='.para.tmp' 2>/dev/null || mktemp -d -t '.para.tmp')
  touch $grant_users_tmp_para/hopper
  slurpy="$(grep -v '^#' $KUBASH_USERS_CSV)"
  # user_csv_columns="user_email user_role"
  set_csv_columns
  while IFS="," read -r $user_csv_columns
  do
    squawk 9 "user_name=$user_name user_email=$user_email user_role=$user_role"
    echo "kubash -n $KUBASH_CLUSTER_NAME grant $user_name $user_email $user_role" >> $grant_users_tmp_para/hopper
  done <<< "$slurpy"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $grant_users_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $grant_users_tmp_para/hopper
  else
    bash $grant_users_tmp_para/hopper
  fi
  rm -Rf $grant_users_tmp_para
}

finish_pki_for_masters () {
  squawk 5 "finish_pki_for_masters $@"
  if [[ $# -ne 4 ]]; then
    kubash_interactive
    echo 'Arguments does not equal 4!'
    echo "Arguments: $@"
    exit 1
  fi
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4
  command2run='mkdir -p /etc/kubernetes/pki/etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  squawk 5 'cp the etcd pki files'
  command2run="cp -v /etc/etcd/pki/ca.pem /etc/etcd/pki/client.pem /etc/etcd/pki/client-key.pem /etc/kubernetes/pki/etcd/"
  sudo_command $this_port $this_user $this_host "$command2run"
}

get_major_minor_kube_version () {
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4
  #command2run="kubeadm version 2>/dev/null |sed \'s/^.*Major:\"\([1234567890]*\)\", Minor:\"\([1234567890]*\)\", GitVersion:.*$/\1,\2/\'"
  command2run="kubeadm version 2>/dev/null"
  TEST_KUBEADM_VER=$(sudo_command $this_port $this_user $this_host "$command2run" \
    |grep -v -P '^#'\
    |sed 's/^.*Major:\"\([1234567890]*\)\", Minor:\"\([1234567890]*\)\", GitVersion:.*$/\1,\2/' \
  )
  KUBE_MAJOR_VER=$(echo $TEST_KUBEADM_VER|cut -f1 -d,)
  KUBE_MINOR_VER=$(echo $TEST_KUBEADM_VER|cut -f2 -d,)
  squawk 185 "kube major: $KUBE_MAJOR_VER kube minor: $KUBE_MINOR_VER"
}

finish_etcd () {
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4
  get_major_minor_kube_version $this_user $this_host $this_name $this_port
  if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
    squawk 20 'Major Version 1'
    if [[ $KUBE_MINOR_VER -lt 12 ]]; then
      finish_etcd_direct_download $this_user $this_host $this_name $this_port
    else
      echo 'stubbed not working yet'
      exit 1
      #finish_etcd_kubelet_download $this_user $this_host $this_name $this_port
    fi
  elif [[ $MAJOR_VER -eq 0 ]]; then
    squawk 1 'Major Version 0 unsupported'
    exit 1
  else
    squawk 1 'Major Version Unknown'
    exit 1
  fi
}

finish_etcd_kubelet_download () {
  squawk 5 'finish_etcd_kubelet_download'
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4
}

finish_etcd_direct_download () {
  squawk 5 'finish_etcd_direct_download'
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4

  command2run="cd /etc/etcd/pki; cfssl print-defaults csr > config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="sed -i '0,/CN/{s/example\.net/'$this_name'/}' /etc/etcd/pki/config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="sed -i 's/www\.example\.net/'$this_host'/' /etc/etcd/pki/config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="sed -i 's/example\.net/'$this_name'/' /etc/etcd/pki/config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="cd /etc/etcd/pki; cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server config.json | cfssljson -bare server"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="cd /etc/etcd/pki; cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer config.json | cfssljson -bare peer"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='chown -R etcd:etcd /etc/etcd/pki'
  sudo_command $this_port $this_user $this_host "$command2run"

  if [[ -e $KUBASH_DIR/tmp/etcd-${ETCD_VERSION}-linux-amd64.tar.gz ]]; then
    squawk 9 'Etcd binary already downloaded'
  else
    cd $KUBASH_DIR/tmp
    wget -c https://github.com/coreos/etcd/releases/download/${ETCD_VERSION}/etcd-${ETCD_VERSION}-linux-amd64.tar.gz
  fi
  command2run='id -u etcd &>/dev/null || useradd etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  etcd_extract_tmp=$(mktemp -d)
  sudo tar --strip-components=1 -C $etcd_extract_tmp -xzf $KUBASH_DIR/tmp/etcd-${ETCD_VERSION}-linux-amd64.tar.gz
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $etcd_extract_tmp/etcd $this_user@$this_host:/tmp/
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $etcd_extract_tmp/etcdctl $this_user@$this_host:/tmp/
  $PSEUDO rm -Rf $etcd_extract_tmp
  command2run='sudo mv /tmp/etcd /usr/local/bin/'
  do_command $this_port $this_user $this_host "$command2run"
  command2run='sudo mv /tmp/etcdctl /usr/local/bin/'
  do_command $this_port $this_user $this_host "$command2run"
  etctmp=$(mktemp)
  KUBASH_CLUSTER_NAME=$KUBASH_CLUSTER_NAME \
  PEER_NAME=$this_name \
  PRIVATE_IP=$this_host \
  ETCD_INITCLUSER_LINE="$(cat $KUBASH_CLUSTER_DIR/etcd.line)" \
  envsubst < $KUBASH_DIR/templates/etcd.conf.yml \
  > $etctmp
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $etctmp  $this_user@$this_host:/tmp/etcd.conf.yml
  command2run="mv /tmp/etcd.conf.yml /etc/etcd/etcd.conf.yml"
  sudo_command $this_port $this_user $this_host "$command2run"

  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $KUBASH_DIR/templates/etcd.service  $this_user@$this_host:/tmp/etcd.service
  command2run='mv /tmp/etcd.service /lib/systemd/system/etcd.service'
  sudo_command $this_port $this_user $this_host "$command2run"

  rm $etctmp
  command2run='mkdir -p /etc/etcd; chown -R etcd.etcd /etc/etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='mkdir -p /var/lib/etcd; chown -R etcd.etcd /var/lib/etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='systemctl daemon-reload'
  sudo_command $this_port $this_user $this_host "$command2run"
}

start_etcd () {

  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  # Run kubeadm init on master0
  start_etcd_tmp_para=$(mktemp -d --suffix='.para.tmp' 2>/dev/null)
  touch $start_etcd_tmp_para/hopper
  squawk 3 " start_etcd"

  countzero=0
  touch $start_etcd_tmp_para/endpoints.line
  #echo 'etcd:' >> $start_etcd_tmp_para/endpoints.line
  echo ' external:' >> $start_etcd_tmp_para/endpoints.line
  echo '  endpoints:' >> $start_etcd_tmp_para/endpoints.line
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "etcd" || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
      if [[ "$countzero" -lt "3" ]]; then
  command2run='systemctl start etcd'
  squawk 5 "ssh -n -p $K8S_sshPort $K8S_provisionerUser@$K8S_ip1 'sudo bash -c \"$command2run\"'"
  echo "ssh -n -p $K8S_sshPort $K8S_provisionerUser@$K8S_ip1 'sudo bash -c \"$command2run\"'" >> $start_etcd_tmp_para/hopper
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $start_etcd_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $start_etcd_tmp_para/hopper
  else
    bash $start_etcd_tmp_para/hopper
  fi
  rm -Rf $start_etcd_tmp_para
}

kubeadm_reset () {
  squawk 3 "Kubeadmin reset"
  command2run="PATH=$K8S_SU_PATH yes y|kubeadm reset"
  # hack if debugging to skip this step
  set +e
  do_command_in_parallel "$command2run"
  #set -e
}

prep_init_etcd () {
  prep_init_etcd_user=$1
  prep_init_etcd_host=$2
  prep_init_etcd_name=$3
  prep_init_etcd_port=$4

  get_major_minor_kube_version $prep_init_etcd_user $prep_init_etcd_host $prep_init_etcd_name $prep_init_etcd_port
  if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
    squawk 175 'Kube Major Version 1 for prep init etcd'
    if [[ $KUBE_MINOR_VER -lt 12 ]]; then
      #echo "$KUBE_MAJOR_VER.$KUBE_MINOR_VER less than 12 broken atm prep_init_etcd_kubelet_download $prep_init_etcd_user $prep_init_etcd_host $prep_init_etcd_name $prep_init_etcd_port"
      #exit 1
      squawk 175 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER Kube Minor Version less than 12 for prep init etcd"
      prep_init_etcd_classic $prep_init_etcd_user $prep_init_etcd_host $prep_init_etcd_name $prep_init_etcd_port
    else
      squawk 175 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER for prep init etcd"
      squawk 55 "prep_init_etcd_kubelet_download $prep_init_etcd_user $prep_init_etcd_host $prep_init_etcd_name $prep_init_etcd_port"
      prep_init_etcd_kubelet_download $prep_init_etcd_user $prep_init_etcd_host $prep_init_etcd_name $prep_init_etcd_port
      squawk 83 'End pre_init_etcd'
    fi
  elif [[ $MAJOR_VER -eq 0 ]]; then
    squawk 1 'Major Version 0 unsupported'
    exit 1
  else
    squawk 1 'Major Version Unknown'
    exit 1
  fi
}

prep_init_etcd_kubelet_download  () {
  squawk 5 prep_init_etcd_kubelet_download
  prep_init_etcd_kubelet_download_tmp=$(mktemp -d)
  prep_init_etcd_kubelet_download_user=$1
  prep_init_etcd_kubelet_download_host=$2
  prep_init_etcd_kubelet_download_name=$3
  prep_init_etcd_kubelet_download_port=$4

  squawk 55 "prep_20-etcd-service-manager $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host $prep_init_etcd_kubelet_download_name $prep_init_etcd_kubelet_download_port"
  prep_20-etcd-service-manager $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host $prep_init_etcd_kubelet_download_name $prep_init_etcd_kubelet_download_port
  squawk 76 'end etcd prep_20'

  sleep 3

  command2run='netstat -ntpl'
  sudo_command $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host "$command2run"
  command2run='kubeadm  alpha phase certs etcd-ca'
  sudo_command $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host "$command2run"
  command2run='ls -lh /etc/kubernetes/pki/etcd/ca.crt'
  #sudo_command $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host "$command2run"
  command2run='ls -lh /etc/kubernetes/pki/etcd/ca.key'
  #sudo_command $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host "$command2run"

  squawk 55 "prep_etcd_gen_certs $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host"
  prep_etcd_gen_certs $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host $prep_init_etcd_kubelet_download_port $prep_init_etcd_kubelet_download_user $prep_init_etcd_kubelet_download_host
}

prep_20-etcd-service-manager () {
  if [ $# -ne 4 ]; then
    # Print usage
    echo 'Error! wrong number of arguments'
    echo 'usage:'
    echo "$0 user host name port"
    exit 1
  fi
  squawk 5 prep_init_etcd_kubelet_download
  prep_20_etcd_service_manager_tmp=$(mktemp -d)
  prep_20_etcd_service_manager_user=$1
  prep_20_etcd_service_manager_host=$2
  prep_20_etcd_service_manager_name=$3
  prep_20_etcd_service_manager_port=$4

  prep_20_etcd_service_manager_host=$2 \
  envsubst < \
    $KUBASH_DIR/templates/20-etcd-service-manager.conf \
    > $prep_20_etcd_service_manager_tmp/20-etcd-service-manager.conf
  squawk 55 "rsync -zave ssh -p $prep_20_etcd_service_manager_port $prep_20_etcd_service_manager_tmp/20-etcd-service-manager.conf $prep_20_etcd_service_manager_user@$prep_20_etcd_service_manager_host:/etc/systemd/system/kubelet.service.d/20-etcd-service-manager.conf"
  rsync -zave "ssh -p $prep_20_etcd_service_manager_port" $prep_20_etcd_service_manager_tmp/20-etcd-service-manager.conf $prep_20_etcd_service_manager_user@$prep_20_etcd_service_manager_host:/etc/systemd/system/kubelet.service.d/20-etcd-service-manager.conf
  rm $prep_20_etcd_service_manager_tmp/20-etcd-service-manager.conf
  rmdir $prep_20_etcd_service_manager_tmp
  command2run='systemctl daemon-reload && systemctl restart kubelet'
  squawk 55 "sudo_command $prep_20_etcd_service_manager_port $prep_20_etcd_service_manager_user $prep_20_etcd_service_manager_host $command2run"
  sudo_command $prep_20_etcd_service_manager_port $prep_20_etcd_service_manager_user $prep_20_etcd_service_manager_host "$command2run"
  squawk 99 'End prep_20-etcd-service-manager'
}

prep_etcd_gen_certs () {
  prepetcdgencerts_port=$1
  prepetcdgencerts_user=$2
  prepetcdgencerts_host=$3
  prepetcdgencerts_primary_etcd_master_port=$4
  prepetcdgencerts_primary_etcd_master_user=$5
  prepetcdgencerts_primary_etcd_master=$6
  squawk 55 "prep_etcd_gen_certs port $prepetcdgencerts_port user $prepetcdgencerts_user host $prepetcdgencerts_host on master $prepetcdgencerts_primary_etcd_master_user '@' $prepetcdgencerts_primary_etcd_master : $prepetcdgencerts_primary_etcd_master_port"
  command2run="find /tmp/${prepetcdgencerts_host} -name ca.key -type f -delete -print \
    && find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete -print \
    && kubeadm alpha phase certs etcd-server --config=/tmp/${prepetcdgencerts_host}/kubeadmcfg.yaml \
    && kubeadm alpha phase certs etcd-peer --config=/tmp/${prepetcdgencerts_host}/kubeadmcfg.yaml \
    && kubeadm alpha phase certs etcd-healthcheck-client --config=/tmp/${prepetcdgencerts_host}/kubeadmcfg.yaml \
    && kubeadm alpha phase certs apiserver-etcd-client --config=/tmp/${prepetcdgencerts_host}/kubeadmcfg.yaml \
    && cp -R /etc/kubernetes/pki /tmp/${prepetcdgencerts_host}/"
  sudo_command $prepetcdgencerts_primary_etcd_master_port  $prepetcdgencerts_primary_etcd_master_user  $prepetcdgencerts_primary_etcd_master "$command2run"
  squawk 86 'cleanup non-reusable certificates'
  command2run="find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete -print"
  sudo_command $prepetcdgencerts_primary_etcd_master_port  $prepetcdgencerts_primary_etcd_master_user  $prepetcdgencerts_primary_etcd_master "$command2run"
  if [[ "$prepetcdgencerts_host" == "$prepetcdgencerts_primary_etcd_master" ]]; then
    command2run="rsync -av /tmp/${prepetcdgencerts_host}/* /etc/kubernetes/"
    squawk 25 "$command2run"
    sudo_command $prepetcdgencerts_primary_etcd_master_port  $prepetcdgencerts_primary_etcd_master_user  $prepetcdgencerts_primary_etcd_master "$command2run"
    command2run="chown -R root:root /etc/kubernetes/pki"
    sudo_command $prepetcdgencerts_port $prepetcdgencerts_user $prepetcdgencerts_host "$command2run"
  else
    squawk 25 "$prepetcdgencerts_host !=  $prepetcdgencerts_primary_etcd_master"
    command2run="rsync -ave \"ssh -p $prepetcdgencerts_port\" /tmp/${prepetcdgencerts_host}/pki ${prepetcdgencerts_user}@${prepetcdgencerts_host}:/etc/kubernetes/"
    squawk 25 "$command2run"
    sudo_command $prepetcdgencerts_primary_etcd_master_port  $prepetcdgencerts_primary_etcd_master_user  $prepetcdgencerts_primary_etcd_master "$command2run"
    command2run="chown -R root:root /etc/kubernetes/pki"
    sudo_command $prepetcdgencerts_port $prepetcdgencerts_user $prepetcdgencerts_host "$command2run"
  fi
  squawk 86 "clean up certs that should not be copied off prepetcdgencerts host"
  command2run="find /tmp/${prepetcdgencerts_host} -name ca.key -type f -delete -print"
  sudo_command $prepetcdgencerts_primary_etcd_master_port  $prepetcdgencerts_primary_etcd_master_user  $prepetcdgencerts_primary_etcd_master "$command2run"
}

finalize_etcd_gen_certs () {
  finalize_etcdgencerts_port=$1
  finalize_etcdgencerts_user=$2
  finalize_etcdgencerts_host=$3
  squawk 55 "finalize_etcd_gen_certs port $finalize_etcdgencerts_port user $finalize_etcdgencerts_user host $finalize_etcdgencerts_host"
  command2run="cp -R  /tmp/${finalize_etcdgencerts_host}/kubeadmcfg.yaml /etc/kubernetes/ \
    && cp -R  /tmp/${finalize_etcdgencerts_host}/pki /etc/kubernetes/ \
    && chown -R root:root /etc/kubernetes/pki"
  sudo_command $finalize_etcdgencerts_port $finalize_etcdgencerts_user $finalize_etcdgencerts_host "$command2run"
}

prep_init_etcd_classic () {
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4

  init_etcd_tmp=$(mktemp -d)
  mkdir $init_etcd_tmp/pki
  cp $KUBASH_DIR/templates/ca-config.json $init_etcd_tmp/pki/ca-config.json
  cp $KUBASH_DIR/templates/client.json $init_etcd_tmp/pki/client.json
  jinja2 $KUBASH_DIR/templates/ca-csr.json $KUBASH_CLUSTER_DIR/ca-data.yaml --format=yaml > $init_etcd_tmp/pki/ca-csr.json
  command2run='mkdir -p /etc/etcd'
  squawk 5 "command2run $command2run"
  sudo_command $this_port $this_user $this_host "$command2run"
  squawk 15 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $this_port' $init_etcd_tmp/pki $this_user@$this_host:/tmp/"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $init_etcd_tmp/pki $this_user@$this_host:/tmp/
  command2run='ls -lh /tmp/pki'
  #sudo_command $this_port $this_user $this_host "$command2run"
  command2run='rm -Rf /etc/etcd/pki'
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='mv /tmp/pki /etc/etcd/pki'
  sudo_command $this_port $this_user $this_host "$command2run"
  rm -Rf $init_etcd_tmp

  command2run="chown $this_user /etc/etcd/pki"
  sudo_command $this_port $this_user $this_host "$command2run"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $KUBASH_DIR/templates/ca-config.json $this_user@$this_host:/tmp/ca-config.json
  command2run='mv /tmp/ca-config.json /etc/etcd/pki/ca-config.json'
  sudo_command $this_port $this_user $this_host "$command2run"

  # crictl
  if [[ $DO_CRICTL = 'true' ]]; then
    real_path_crictl=$(realpath ${KUBASH_BIN}/crictl)
    copy_in_parallel_to_all "$real_path_crictl" "/tmp/crictl"
    command2run='mv /tmp/crictl /usr/local/bin/crictl'
    do_command_in_parallel "$command2run"
  fi

  copy_in_parallel_to_all "${KUBASH_BIN}/cfssljson" "/tmp/cfssljson"
  command2run='mv /tmp/cfssljson /usr/local/bin/cfssljson'
  sudo_command $this_port $this_user $this_host "$command2run"
  do_command_in_parallel "$command2run"

  copy_in_parallel_to_all "${KUBASH_BIN}/cfssl" "/tmp/cfssl"
  command2run='mv /tmp/cfssl /usr/local/bin/cfssl'
  sudo_command $this_port $this_user $this_host "$command2run"
  do_command_in_parallel "$command2run"

  # Hack, delete after rebuild
  #command2run="echo 'PATH=/usr/local/bin:$PATH' >> /root/.bash_profile"
  #sudo_command $this_port $this_user $this_host "$command2run"
  #do_command_in_parallel_on_role "etcd"          "$command2run"
  #if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
  #  do_command_in_parallel_on_role "master"        "$command2run"
  #fi

  # add etcd user if it doesn't exist
  command2run='id -u etcd &>/dev/null || useradd etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
    do_command_in_parallel_on_role "master"        "$command2run"
  fi

  command2run='cd /etc/etcd/pki; cfssl gencert -initca ca-csr.json | cfssljson -bare ca -'
  sudo_command $this_port $this_user $this_host "$command2run"

  command2run='cd /etc/etcd/pki; cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client'
  sudo_command $this_port $this_user $this_host "$command2run"

  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $KUBASH_DIR/scripts/grabpki $this_user@$this_host:/tmp/grabpki
  command2run="bash /tmp/grabpki"
  sudo_command $this_port $this_user $this_host "$command2run"
  squawk 5 'pull etcd-pki.tgz from primary master'
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $this_user@$this_host:/tmp/etcd-pki.tgz $KUBASH_CLUSTER_DIR/
  squawk 5 'and copy it to master and etcd hosts'
  copy_in_parallel_to_role "etcd" "$KUBASH_CLUSTER_DIR/etcd-pki.tgz" "/tmp/"
  copy_in_parallel_to_role "master" "$KUBASH_CLUSTER_DIR/etcd-pki.tgz" "/tmp/"
  command2run='cd /; tar zxf /tmp/etcd-pki.tgz'
  do_command_in_parallel_on_role "master"        "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  command2run='rm /tmp/etcd-pki.tgz'
  do_command_in_parallel_on_role "master"        "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  finish_etcd $this_user $this_host $this_name $this_port
}

prep_etcd () {
  squawk 5 'prep_etcd'
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4

  get_major_minor_kube_version $this_user $this_host $this_name $this_port
  if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
    squawk 175 'Kube Major Version 1 for prep etcd'
    if [[ $KUBE_MINOR_VER -lt 12 ]]; then
      squawk 75 'Kube Minor Version less than 12 for prep etcd'
      finish_etcd $this_user $this_host $this_name $this_port
    else
      squawk 75 'Kube Major Version greater than or equal to 12 for prep etcd'
      if [[ -e $KUBASH_CLUSTER_DIR/kube_primary_etcd ]]; then
        kube_primary=$(cat $KUBASH_CLUSTER_DIR/kube_primary_etcd)
        kube_primary_port=$(cat $KUBASH_CLUSTER_DIR/kube_primary_etcd_port)
        kube_primary_user=$(cat $KUBASH_CLUSTER_DIR/kube_primary_etcd_user)
      elif [[ -e $KUBASH_CLUSTER_DIR/kube_primary ]]; then
        kube_primary=$(cat $KUBASH_CLUSTER_DIR/kube_primary)
        kube_primary_port=$(cat $KUBASH_CLUSTER_DIR/kube_primary_port)
        kube_primary_user=$(cat $KUBASH_CLUSTER_DIR/kube_primary_user)
      else
        echo 'no master found'
        exit 1
      fi
      prep_etcd_gen_certs $this_port $this_user $this_host $kube_primary_port $kube_primary_user $kube_primary
      #prep_etcd_gen_certs $this_port $this_user $this_host $this_port $kube_primary_user $kube_primary
    fi
  elif [[ $MAJOR_VER -eq 0 ]]; then
    squawk 1 'Major Version 0 unsupported'
    exit 1
  else
    squawk 1 'Major Version Unknown'
    exit 1
  fi
}

set_ip_files () {
  # First find the primary etcd master
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master"  ]]; then
      if [[ "$countprimarymaster" -eq "0" ]]; then
        # save these values for clusterwide usage
        echo $K8S_ip1 > $KUBASH_CLUSTER_DIR/kube_primary
        echo $K8S_sshPort > $KUBASH_CLUSTER_DIR/kube_primary_port
        echo $K8S_provisionerUser > $KUBASH_CLUSTER_DIR/kube_primary_user
      else
        echo 'there should only be one primary master'
        exit 1
      fi
      ((++countprimarymaster))
    elif [[ "$K8S_role" == "primary_etcd"  ]]; then
      if [[ "$countprimaryetcd" -eq "0" ]]; then
        # save these values for clusterwide usage
        echo $K8S_ip1 > $KUBASH_CLUSTER_DIR/kube_primary_etcd
        echo $K8S_sshPort > $KUBASH_CLUSTER_DIR/kube_primary_etcd_port
        echo $K8S_provisionerUser > $KUBASH_CLUSTER_DIR/kube_primary_etcd_user
      else
        echo 'there should only be one primary etcd'
        exit 1
      fi
      ((++countprimaryetcd))
    elif [[ "$K8S_role" == "master"  ]]; then
      echo $K8S_ip1 > $KUBASH_CLUSTER_DIR/kube_master${countmaster}
      echo $K8S_sshPort > $KUBASH_CLUSTER_DIR/kube_master${countmaster}_port
      echo $K8S_provisionerUser > $KUBASH_CLUSTER_DIR/kube_master${countmaster}_user
      ((++countmaster))
    elif [[ "$K8S_role" == "etcd"  ]]; then
      echo $K8S_ip1 > $KUBASH_CLUSTER_DIR/kube_etcd${countetcd}
      echo $K8S_sshPort > $KUBASH_CLUSTER_DIR/kube_etcd${countetcd}_port
      echo $K8S_provisionerUser > $KUBASH_CLUSTER_DIR/kube_etcd${countetcd}_user
      ((++countetcd))
    fi
  done <<< "$kubash_hosts_csv_slurped"
}

write_kubeadmcfg_yaml () {
  squawk 3 " write kubeadmcfg.yaml files"
  do_etcd_tmp_para=$(mktemp -d --suffix='.para.tmp' 2>/dev/null || mktemp -d -t '.para.tmp')
  touch $do_etcd_tmp_para/hopper
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi

  countprimarymaster=0
  countprimaryetcd=0
  countmaster=1
  countetcd=1
  set_csv_columns
  set_ip_files
  my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary)
  my_master_user=$( cat $KUBASH_CLUSTER_DIR/kube_primary_user)
  my_master_port=$( cat $KUBASH_CLUSTER_DIR/kube_primary_port)
  # create  config files

  # create tmpdirs for configs
  while IFS="," read -r $csv_columns
  do
        if [[ -e $KUBASH_CLUSTER_DIR/kube_primary_etcd ]]; then
          my_primary_etcd_port=$(cat $KUBASH_CLUSTER_DIR/kube_primary_etcd_port)
          my_primary_etcd_user=$(cat  $KUBASH_CLUSTER_DIR/kube_primary_etcd_user)
          my_primary_etcd_ip=$(cat $KUBASH_CLUSTER_DIR/kube_primary_etcd)
          command2run="mkdir -p /tmp/${K8S_ip1}"
          sudo_command $my_primary_etcd_port $my_primary_etcd_user $my_primary_etcd_ip "$command2run"
        elif [[ -e $KUBASH_CLUSTER_DIR/kube_primary ]]; then
          command2run="mkdir -p /tmp/${K8S_ip1}"
          sudo_command $my_master_port $my_master_user $my_master_ip "$command2run"
        else
          echo 'no master found'
          exit 1
        fi
  done <<< "$kubash_hosts_csv_slurped"
  countzero=0
  touch $do_etcd_tmp_para/endpoints.line
  touch $do_etcd_tmp_para/etcd.line
  #echo 'etcd:' > $do_etcd_tmp_para/etcd.line

  # servercertSANS
  echo "${TAB_2}serverCertSANS:" >> $do_etcd_tmp_para/servercertsans.line
  echo "${TAB_2}- '127.0.0.1'" >> $do_etcd_tmp_para/servercertsans.line
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
      echo "${TAB_2}- '$K8S_ip1'" >> $do_etcd_tmp_para/servercertsans.line
    fi
  done <<< "$kubash_hosts_csv_slurped"
  # peercertSANS
  echo "${TAB_2}peerCertSANS:" >> $do_etcd_tmp_para/peercertsans.line
  echo "${TAB_2}- '127.0.0.1'" >> $do_etcd_tmp_para/peercertsans.line
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
      echo "${TAB_2}- '$K8S_ip1'" >> $do_etcd_tmp_para/peercertsans.line
    fi
  done <<< "$kubash_hosts_csv_slurped"

  echo "${TAB_2}extraArgs:" > $do_etcd_tmp_para/extraargs.head
  echo -n "${TAB_3}initial-cluster: " > $do_etcd_tmp_para/initial-cluster.head
  count_etcd=0
  countetcdnodes=0
  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        if [[ $countetcdnodes -gt 0 ]]; then
          printf ',' >> $do_etcd_tmp_para/initial-cluster.line
        fi
        printf "${K8S_node}=https://${K8S_ip1}:2380" >> $do_etcd_tmp_para/initial-cluster.line
        ((++countetcdnodes))
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        if [[ $countetcdnodes -gt 0 ]]; then
          printf ',' >> $do_etcd_tmp_para/initial-cluster.line
        fi
        printf "${K8S_node}=https://${K8S_ip1}:2380" >> $do_etcd_tmp_para/initial-cluster.line
        ((++countetcdnodes))
      fi
    fi
    ((++count_etcd))
  done <<< "$kubash_hosts_csv_slurped"
  printf " \n" >> $do_etcd_tmp_para/initial-cluster.line
  echo "${TAB_1}external:" >> $do_etcd_tmp_para/external-endpoints.line
  echo "${TAB_2}endpoints:" >> $do_etcd_tmp_para/external-endpoints.line
  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        echo "${TAB_2}- https://${K8S_ip1}:2379" >> $do_etcd_tmp_para/external-endpoints.line
      fi
    else
      if [[ "$K8S_role" == 'etcd' ]]; then
        echo "${TAB_2}- https://${K8S_ip1}:2379" >> $do_etcd_tmp_para/external-endpoints.line
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"
  echo "${TAB_2}caFile: /etc/kubernetes/pki/etcd/ca.crt"                 >> $do_etcd_tmp_para/external-endpoints.line
  echo "${TAB_2}certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt" >> $do_etcd_tmp_para/external-endpoints.line
  echo "${TAB_2}keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key"  >> $do_etcd_tmp_para/external-endpoints.line

  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        echo "${TAB_1}local:" > $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}serverCertSANS:" >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}- '$K8S_ip1'"    >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}peerCertSANS:"   >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}- '$K8S_ip1'"    >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #printf " \n" >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "${TAB_3}initial-cluster-state: new" >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "${TAB_3}name: $K8S_node"            >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "${TAB_3}listen-peer-urls: https://${K8S_ip1}:2380"    >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        echo "${TAB_1}local:" > $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}serverCertSANS:" >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}- '$K8S_ip1'"    >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}peerCertSANS:"   >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #echo "${TAB_2}- '$K8S_ip1'"    >> $do_etcd_tmp_para/${K8S_node}etcd.line
        #printf " \n" >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "${TAB_3}initial-cluster-state: new" >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "${TAB_3}name: $K8S_node"       >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "${TAB_3}listen-peer-urls: https://${K8S_ip1}:2380"    >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        echo -n "${TAB_3}listen-client-urls: " >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "https://${K8S_ip1}:2379"     >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        echo -n "${TAB_3}listen-client-urls: " >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo "https://${K8S_ip1}:2379"     >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        echo -n "${TAB_3}advertise-client-urls: " >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo  "https://${K8S_ip1}:2379" >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        echo -n "${TAB_3}advertise-client-urls: " >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo  "https://${K8S_ip1}:2379" >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        echo -n "${TAB_3}initial-advertise-peer-urls: " >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo  "https://${K8S_ip1}:2380"             >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        echo -n "${TAB_3}initial-advertise-peer-urls: " >> $do_etcd_tmp_para/${K8S_node}extraargs.line
        echo  "https://${K8S_ip1}:2380"             >> $do_etcd_tmp_para/${K8S_node}extraargs.line
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  # deprecated these are no longer used in the current kubeadm
  #echo '  caFile: /etc/kubernetes/pki/etcd/ca.pem' >> $do_etcd_tmp_para/etcdcerts.line
  #echo '  certFile: /etc/kubernetes/pki/etcd/client.pem' >> $do_etcd_tmp_para/etcdcerts.line
  #echo '  keyFile: /etc/kubernetes/pki/etcd/client-key.pem' >> $do_etcd_tmp_para/etcdcerts.line

  squawk 19 "check number of etcd nodes"
  if [[ "$countetcdnodes" -lt "3" ]]; then
    horizontal_rule
    echo "not enough etcd nodes, [$countetcdnodes]"
    exit 1
  else
    if [[ "$((countetcdnodes%2))" -eq 0 ]]; then
      horizontal_rule
      echo "number of etcd nodes, [$countetcdnodes] is even which is not supported"
      exit 1
    fi
  fi

  if [[ -e $KUBASH_CLUSTER_DIR/kube_primary_etcd ]]; then
    my_master_ip=$(cat $KUBASH_CLUSTER_DIR/kube_primary_etcd)
    my_master_user=$(cat  $KUBASH_CLUSTER_DIR/kube_primary_etcd_user)
    my_master_port=$(cat $KUBASH_CLUSTER_DIR/kube_primary_etcd_port)
  elif [[ -e $KUBASH_CLUSTER_DIR/kube_primary ]]; then
    my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary)
    my_master_user=$( cat $KUBASH_CLUSTER_DIR/kube_primary_user)
    my_master_port=$( cat $KUBASH_CLUSTER_DIR/kube_primary_port)
  else
    echo 'no master found'
    exit 1
  fi
  # create  config files
  while IFS="," read -r $csv_columns
  do
    get_major_minor_kube_version $K8S_user $K8S_ip1  $K8S_node $K8S_sshPort
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' || "$K8S_role" == 'primary_etcd' ]]; then
        cat $do_etcd_tmp_para/endpoints.line \
        $do_etcd_tmp_para/${K8S_node}etcd.line \
        $do_etcd_tmp_para/servercertsans.line \
        $do_etcd_tmp_para/peercertsans.line \
        $do_etcd_tmp_para/extraargs.head \
        $do_etcd_tmp_para/initial-cluster.head \
        $do_etcd_tmp_para/initial-cluster.line \
        $do_etcd_tmp_para/${K8S_node}extraargs.line \
        > $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line

        if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
          squawk 20 'Major Version 1'
          if [[ $KUBE_MINOR_VER -lt 9 ]]; then
            echo "$KUBE_MINOR_VER is too old may not ever be supported"
            exit 1
          elif [[ $KUBE_MINOR_VER -eq 11 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-1.11.yaml \
              > $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml
          elif [[ $KUBE_MINOR_VER -eq 12 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-1.12.yaml \
              > $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml
          else
            squawk 10 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER supported"
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$my_master_ip \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-${KUBE_MAJOR_VER}.${KUBE_MINOR_VER}.yaml \
              > $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml
          fi
        elif [[ $MAJOR_VER -eq 0 ]]; then
          squawk 1 'Major Version 0 unsupported'
          exit 1
        else
          squawk 1 'Major Version Unknown'
          exit 1
        fi

        # now for the external
        cat $do_etcd_tmp_para/endpoints.line \
        $do_etcd_tmp_para/external-endpoints.line \
        > $do_etcd_tmp_para/${K8S_node}endpoints.line

        if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
          squawk 20 'Major Version 1'
          if [[ $KUBE_MINOR_VER -lt 9 ]]; then
            echo "$KUBE_MAJOR_VER.$KUBE_MINOR_VER is too old may not ever be supported"
            exit 1
          elif [[ $KUBE_MINOR_VER -eq 11 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $do_etcd_tmp_para/${K8S_node}endpoints.line) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-external-1.11.yaml \
              > $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml
          elif [[ $KUBE_MINOR_VER -eq 12 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $do_etcd_tmp_para/${K8S_node}endpoints.line) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-external-1.12.yaml \
              > $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml
          else
            squawk 10 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER supported"
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$my_master_ip \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/endpoints.line) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-external-${KUBE_MAJOR_VER}.${KUBE_MINOR_VER}.yaml \
              > $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml
          fi
        elif [[ $MAJOR_VER -eq 0 ]]; then
          squawk 1 'Major Version 0 unsupported'
          exit 1
        else
          squawk 1 'Major Version Unknown'
          exit 1
        fi

        #squawk 25 "scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $K8S_SU_USER@$K8S_ip1:/tmp/kubeadmcfg.yaml"
        #scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $K8S_SU_USER@$K8S_ip1:/tmp/kubeadmcfg.yaml
        command2run="mkdir -p /tmp/${K8S_ip1}"
        sudo_command $my_master_port $my_master_user $my_master_ip "$command2run"
        squawk 25 "scp -P $my_master_port $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $my_master_user@$my_master_ip:/tmp/${K8S_ip1}/kubeadmcfg.yaml"
        scp -P $my_master_port $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $my_master_user@$my_master_ip:/tmp/${K8S_ip1}/kubeadmcfg.yaml
        scp -P $my_master_port $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml $my_master_user@$my_master_ip:/tmp/${K8S_ip1}/kubeadmcfg-external.yaml
        #csv_columns="K8S_node K8S_role K8S_cpuCount K8S_Memory K8S_sshPort K8S_network1 K8S_mac1 K8S_ip1 K8S_routingprefix1 K8S_subnetmask1 K8S_broadcast1 K8S_gateway1 K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt K8S_network2 K8S_mac2 K8S_ip2 K8S_routingprefix2 K8S_subnetmask2 K8S_broadcast2 K8S_gateway2 K8S_network3 K8S_mac3 K8S_ip3 K8S_routingprefix3 K8S_subnetmask3 K8S_broadcast3 K8S_gateway3"
        squawk 25 "scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $K8S_user@${K8S_ip1}:/etc/kubernetes/kubeadmcfg.yaml"
        scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $K8S_user@${K8S_ip1}:/etc/kubernetes/kubeadmcfg.yaml
        scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml $K8S_user@${K8S_ip1}:/etc/kubernetes/kubeadmcfg-external.yaml
        squawk 73 'etcd prep_20'
        prep_20-etcd-service-manager $K8S_user ${K8S_ip1} ${K8S_node} $K8S_sshPort
        squawk 78 'end etcd prep_20'
      fi
    else
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
        cat $do_etcd_tmp_para/endpoints.line \
        $do_etcd_tmp_para/${K8S_node}etcd.line \
        $do_etcd_tmp_para/servercertsans.line \
        $do_etcd_tmp_para/peercertsans.line \
        $do_etcd_tmp_para/extraargs.head \
        $do_etcd_tmp_para/initial-cluster.head \
        $do_etcd_tmp_para/initial-cluster.line \
        $do_etcd_tmp_para/${K8S_node}extraargs.line \
        > $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line

        if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
          squawk 20 'Major Version 1'
          if [[ $KUBE_MINOR_VER -lt 9 ]]; then
            echo "$KUBE_MINOR_VER is too old may not ever be supported"
            exit 1
          elif [[ $KUBE_MINOR_VER -eq 11 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-1.11.yaml \
              > $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml
          elif [[ $KUBE_MINOR_VER -eq 12 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-1.12.yaml \
              > $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml
          else
            squawk 10 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER supported"
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$my_master_ip \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-${KUBE_MAJOR_VER}.${KUBE_MINOR_VER}.yaml \
              > $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml
          fi
        elif [[ $MAJOR_VER -eq 0 ]]; then
          squawk 1 'Major Version 0 unsupported'
          exit 1
        else
          squawk 1 'Major Version Unknown'
          exit 1
        fi

        command2run="mkdir -p /tmp/${K8S_ip1}"
        sudo_command $my_master_port $my_master_user $my_master_ip "$command2run"
        squawk 25 "scp -P $my_master_port $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $my_master_user@$my_master_ip:/tmp/${K8S_ip1}/kubeadmcfg.yaml"
        scp -P $my_master_port $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $my_master_user@$my_master_ip:/tmp/${K8S_ip1}/kubeadmcfg.yaml
        squawk 25 "scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $K8S_user@${K8S_ip1}:/etc/kubernetes/kubeadmcfg.yaml"
        scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}kubeadmcfg.yaml $K8S_user@${K8S_ip1}:/etc/kubernetes/kubeadmcfg.yaml
        squawk 74 'etcd prep_20'
        prep_20-etcd-service-manager $K8S_user ${K8S_ip1} ${K8S_node} $K8S_sshPort
        squawk 74 'end etcd prep_20'

      elif [[ "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
        # now for the external
        cat $do_etcd_tmp_para/endpoints.line \
        $do_etcd_tmp_para/external-endpoints.line \
        > $do_etcd_tmp_para/${K8S_node}endpoints.line


        if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
          squawk 20 'Major Version 1'
          if [[ $KUBE_MINOR_VER -lt 9 ]]; then
            echo "$KUBE_MAJOR_VER.$KUBE_MINOR_VER is too old may not ever be supported"
            exit 1
          elif [[ $KUBE_MINOR_VER -eq 11 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $do_etcd_tmp_para/${K8S_node}endpoints.line) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-external-1.11.yaml \
              > $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml
          elif [[ $KUBE_MINOR_VER -eq 12 ]]; then
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary) \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $do_etcd_tmp_para/${K8S_node}endpoints.line) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-external-1.12.yaml \
              > $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml
          else
            squawk 10 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER supported"
            kubeadmin_config_tmp=$(mktemp)
            my_master_ip=$my_master_ip \
            KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
            load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
            my_KUBE_CIDR=$my_KUBE_CIDR \
            ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/endpoints.line) \
            envsubst  < $KUBASH_DIR/templates/kubeadm-config-external-${KUBE_MAJOR_VER}.${KUBE_MINOR_VER}.yaml \
              > $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml
          fi
        elif [[ $MAJOR_VER -eq 0 ]]; then
          squawk 1 'Major Version 0 unsupported'
          exit 1
        else
          squawk 1 'Major Version Unknown'
          exit 1
        fi
        command2run="mkdir -p /tmp/${K8S_ip1}"
        sudo_command $my_master_port $my_master_user $my_master_ip "$command2run"
        squawk 25 "scp -P $my_master_port $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml $my_master_user@$my_master_ip:/tmp/${K8S_ip1}/kubeadmcfg.yaml"
        scp -P $my_master_port $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml $my_master_user@$my_master_ip:/tmp/${K8S_ip1}/kubeadmcfg.yaml
        squawk 25 "scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml $K8S_user@${K8S_ip1}:/etc/kubernetes/kubeadmcfg.yaml"
        scp -P $K8S_sshPort $do_etcd_tmp_para/${K8S_node}-external-kubeadmcfg.yaml $K8S_user@${K8S_ip1}:/etc/kubernetes/kubeadmcfg.yaml
        squawk 75 'External master prep_20'
        prep_20-etcd-service-manager $K8S_user ${K8S_ip1} ${K8S_node} $K8S_sshPort
        squawk 75 'End create config loop'
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"
}

do_etcd () {
  squawk 3 " do_etcd"
  do_etcd_tmp_para=$(mktemp -d --suffix='.para.tmp' 2>/dev/null || mktemp -d -t '.para.tmp')
  touch $do_etcd_tmp_para/hopper
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi

  countprimarymaster=0
  countprimaryetcd=0
  countmaster=1
  countetcd=1
  set_csv_columns
  set_ip_files
  my_master_ip=$( cat $KUBASH_CLUSTER_DIR/kube_primary)
  my_master_user=$( cat $KUBASH_CLUSTER_DIR/kube_primary_user)
  my_master_port=$( cat $KUBASH_CLUSTER_DIR/kube_primary_port)
  # create  config files
  write_kubeadmcfg_yaml

  countprimarymaster=0
  set_csv_columns
  # First find the primary etcd master
  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == "primary_master"  ]]; then
        if [[ "$countprimarymaster" -eq "0" ]]; then
          ((++countprimarymaster))
          prep_init_etcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort
          # save these values for clusterwide usage
          #kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort
        else
          echo 'there should only be one primary master'
          exit 1
        fi
      fi
    else
      if [[ "$K8S_role" == "primary_etcd"  ]]; then
        if [[ "$countprimarymaster" -eq "0" ]]; then
          ((++countprimarymaster))
          prep_init_etcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort
          # save these values for clusterwide usage
          #kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort
        else
          echo 'there should only be one primary etcd'
          exit 1
        fi
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  prepTMP=$(mktemp -d)
  touch $prepTMP/hopper
  # Then prep the other etcd hosts
  while IFS="," read -r $csv_columns
  do
    #squawk 3 "kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort"
    #echo     "kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort" >> $prepTMP/hopper
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      #if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' || "$K8S_role" == 'primary_etcd' ]]; then
      #if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_etcd' ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_etcd' ]]; then
          #squawk 19 "$K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_sshPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3"
          squawk 3 "kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort"
          echo     "kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort" >> $prepTMP/hopper
      fi
    else
      #if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' || "$K8S_role" == 'primary_etcd' ]]; then
      #if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'primary_etcd' ]]; then
      #if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
          squawk 3 "kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort"
          echo     "kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort" >> $prepTMP/hopper
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"
  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $prepTMP/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    #$PARALLEL  -j $PARALLEL_JOBS -- < $prepTMP/hopper
    bash $prepTMP/hopper
  else
    bash $prepTMP/hopper
  fi
  rm -Rf $prepTMP

  countprimarymaster=0
  set_csv_columns
  # First find the primary etcd master
  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == "primary_master"  ]]; then
        if [[ "$countprimarymaster" -eq "0" ]]; then
          ((++countprimarymaster))
          kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort
          finalize_etcd_gen_certs $K8S_sshPort $K8S_provisionerUser $K8S_ip1
        else
          echo 'there should only be one primary master'
          exit 1
        fi
      fi
    else
      if [[ "$K8S_role" == "primary_etcd"  ]]; then
        if [[ "$countprimarymaster" -eq "0" ]]; then
          ((++countprimarymaster))
          kubash -n $KUBASH_CLUSTER_NAME --verbosity=$VERBOSITY prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_sshPort
          finalize_etcd_gen_certs $K8S_sshPort $K8S_provisionerUser $K8S_ip1
        else
          echo 'there should only be one primary etcd'
          exit 1
        fi
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  squawk 75 "create the manifests"
  command2run="kubeadm alpha phase etcd local --config=/etc/kubernetes/kubeadmcfg.yaml"
  if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
    do_command_in_parallel_on_role "primary_master"          "$command2run"
    do_command_in_parallel_on_role "primary_etcd"            "$command2run"
    do_command_in_parallel_on_role "master"                  "$command2run"
    do_command_in_parallel_on_role "etcd"                    "$command2run"
  else
    do_command_in_parallel_on_role "primary_etcd"            "$command2run"
    do_command_in_parallel_on_role "etcd"                    "$command2run"
  fi
  squawk 5 'sleep 33'
  sleep 33
}

do_primary_master () {
  squawk 3 " do_primary_master"
  do_master_count=0

  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master" ]]; then
      if [[ "$do_master_count" -lt "1" ]]; then
        squawk 9 "master_init_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_sshPort"
        master_init_join $K8S_node $K8S_ip1 $K8S_SU_USER $K8S_sshPort
      else
  echo 'There should only be one init master! Skipping this master'
        echo "master_init_join $K8S_node $K8S_ip1 $K8S_SU_USER $K8S_sshPort"
      fi
      ((++do_master_count))
    fi
  done <<< "$kubash_hosts_csv_slurped"
}

do_masters () {
  squawk 3 " do_masters"

  # hijack
  do_masters_in_parallel
}

do_scale_up_kube_dns () {
  squawk 3 "do_scale_up_kube_dns"
  do_scale_up_kube_dns=0

  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
    ((++do_scale_up_kube_dns))
    fi
  done <<< "$kubash_hosts_csv_slurped"

  kubectl scale --replicas=$do_scale_up_kube_dns -n kube-system  deployment/kube-dns
}

do_masters_in_parallel () {
  squawk 3 " do_masters_in_parallel"
  do_master_count=0


  do_master_tmp=$(mktemp -d)
  touch $do_master_tmp/hopper
  touch $do_master_tmp/hopper2
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    # get major minor vers
    if [[ "$K8S_role" == "primary_master" ]]; then
      get_major_minor_kube_version $K8S_user $K8S_ip1  $K8S_node $K8S_sshPort
      break
    fi
  done
  #command2run='sudo  rm /etc/kubernetes/pki/apiserver.crt'
  #do_command_in_parallel_on_role "master" "$command2run"
  if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
    if [[ $KUBE_MAJOR_VER -eq 1 ]]; then
      squawk 20 'Major Version 1'
      if [[ $KUBE_MINOR_VER -lt 9 ]]; then
        squawk 9 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER is too old may not ever be supported"
        exit 1
      elif [[ $KUBE_MINOR_VER -gt 13 ]]; then
        squawk 13 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER is  may not yet supported"
        exit 1
      elif [[ $KUBE_MINOR_VER -eq 11 ]]; then
        squawk 11 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER supported"
        kubeadmin_config_tmp=$(mktemp)
        my_master_ip=$my_master_ip \
        KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
        load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
        my_KUBE_CIDR=$my_KUBE_CIDR \
        ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
        envsubst  < $KUBASH_DIR/templates/kubeadm-config-1.11.yaml \
          > $kubeadmin_config_tmp
      elif [[ $KUBE_MINOR_VER -eq 12 ]]; then
        squawk 12 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER supported"
        kubeadmin_config_tmp=$(mktemp)
        my_master_ip=$my_master_ip \
        KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
        load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
        my_KUBE_CIDR=$my_KUBE_CIDR \
        ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
        envsubst  < $KUBASH_DIR/templates/kubeadm-config-1.12.yaml \
          > $kubeadmin_config_tmp
      else
        squawk 10 "$KUBE_MAJOR_VER.$KUBE_MINOR_VER supported"
        kubeadmin_config_tmp=$(mktemp)
        my_master_ip=$my_master_ip \
        KUBERNETES_VERSION=$( cat $KUBASH_CLUSTER_DIR/kubernetes_version) \
        load_balancer_ip=$( cat $KUBASH_CLUSTER_DIR/kube_master1) \
        my_KUBE_CIDR=$my_KUBE_CIDR \
        ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/${K8S_node}endpoints.line ) \
        envsubst  < $KUBASH_DIR/templates/kubeadm-config-${KUBE_MAJOR_VER}.${KUBE_MINOR_VER}.yaml \
          > $kubeadmin_config_tmp
      fi
    elif [[ $MAJOR_VER -eq 0 ]]; then
      squawk 1 'Major Version 0 unsupported'
      exit 1
    else
      squawk 1 'Major Version Unknown'
      exit 1
    fi
    squawk 5 "copy_in_parallel_to_role master '$kubeadmin_config_tmp' '/tmp/config.yaml'"
    copy_in_parallel_to_role master "$kubeadmin_config_tmp" "/tmp/config.yaml"
    rm $kubeadmin_config_tmp
  fi
  command2run='systemctl stop kubectl'
  do_command_in_parallel_on_role "master" "$command2run"
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
        my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/tmp/config.yaml"
        squawk 5 "$my_KUBE_INIT"
        echo "ssh -n $K8S_SU_USER@$K8S_ip1 '$my_KUBE_INIT'" >> $do_master_tmp/hopper
      else
        my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --pod-network-cidr=$my_KUBE_CIDR"
        squawk 5 "$my_KUBE_INIT"
        echo "ssh -n $K8S_SU_USER@$K8S_ip1 '$my_KUBE_INIT'" >> $do_master_tmp/hopper
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"
  command2run='systemctl start kubectl'
  do_command_in_parallel_on_role "master" "$command2run"
  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_master_tmp/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_master_tmp/hopper
  else
    bash $do_master_tmp/hopper
  fi
  rm -Rf $do_master_tmp
  if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
    do_command_in_parallel_on_role "master" "rm -f /tmp/config.yaml"
  fi
  #do_scale_up_kube_dns
}

do_nodes () {
  do_nodes_in_parallel
}

do_nodes_in_parallel () {
  do_nodes_tmp_para=$(mktemp -d)
  touch $do_nodes_tmp_para/hopper
  squawk 3 " do_nodes_in_parallel"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  countzero_do_nodes=0
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" || "$K8S_role" == "ingress" ]]; then
      squawk 81 " K8S_role NODE"
      squawk 81 " K8S_role $K8S_role $K8S_ip1 $K8S_user $K8S_sshPort"
      echo "kubash -n $KUBASH_CLUSTER_NAME node_join --node-join-name $K8S_node --node-join-ip $K8S_ip1 --node-join-user $K8S_SU_USER --node-join-port $K8S_sshPort --node-join-role node" \
        >> $do_nodes_tmp_para/hopper
    else
      squawk 91 " K8S_role NOT NODE"
      squawk 91 " K8S_role $K8S_role $K8S_ip1 $K8S_user $K8S_sshPort"
    fi
    ((++countzero_do_nodes))
    squawk 3 " count $countzero_do_nodes"
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_nodes_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_nodes_tmp_para/hopper
  else
    bash $do_nodes_tmp_para/hopper
  fi
  rm -Rf $do_nodes_tmp_para
  taint_all_ingress
}

do_command_in_parallel () {
  do_command_tmp_para=$(mktemp -d)
  command2run=$1
  touch $do_command_tmp_para/hopper
  squawk 3 " do_command_in_parallel $@"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    squawk 19 'slurp empty'
    hosts_csv_slurp
  else
    squawk 19 "host slurp $(echo $kubash_hosts_csv_slurped)"
  fi
  countzero_do_nodes=0
  squawk 20 'Start while loop'
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    ((++countzero_do_nodes))
    squawk 19 " count $countzero_do_nodes"
    squawk 5 "ssh -n -p $K8S_sshPort $K8S_SU_USER@$K8S_ip1 \"sudo bash -c '$command2run'\""
    echo "ssh -n -p $K8S_sshPort $K8S_SU_USER@$K8S_ip1 \"sudo bash -c '$command2run'\""\
        >> $do_command_tmp_para/hopper
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_command_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_command_tmp_para/hopper
  else
    bash $do_command_tmp_para/hopper
  fi
  rm -Rf $do_command_tmp_para
}

do_command () {
  squawk 3 " do_command $@"
  if [[ ! $# -eq 4 ]]; then
    echo "do_command $@ <--- arguments does not equal 4!!!"
    exit 1
  fi
  do_command_port=$1
  do_command_user=$2
  do_command_host=$3
  command2run=$4
  if [[ "$do_command_host" == "localhost" ]]; then
    squawk 5 "bash -c '$command2run'"
    bash -c "$command2run"
  else
    squawk 5 "ssh -n -p $do_command_port $do_command_user@$do_command_host \"bash -c '$command2run'\""
    ssh -n -p $do_command_port $do_command_user@$do_command_host "bash -c '$command2run'"
  fi
}

sudo_command () {
  if [[ ! $# -eq 4 ]]; then
    echo "sudo_command $@ <--- arguments does not equal 4!!!"
    exit 1
  fi
  squawk 3 " sudo_command '$1' '$2' '$3 '$4'"
  sudo_command_port=$1
  sudo_command_user=$2
  sudo_command_host=$3
  command2run=$4
  if [[ "$sudo_command_host" == "localhost" ]]; then
    squawk 5 "sudo bash -c '$command2run'"
    sudo bash -c "$command2run"
  else
    squawk 5 "ssh -n -p $sudo_command_port $sudo_command_user@$sudo_command_host \"$PSEUDO bash -l -c '$command2run'\""
    ssh -n -p $sudo_command_port $sudo_command_user@$sudo_command_host "$PSEUDO bash -l -c '$command2run'"
  fi
}

copy_known_hosts () {
  squawk 15 'copy known_hosts to all servers'
  copy_in_parallel_to_all ~/.ssh/known_hosts /tmp/known_hosts
  command2run="cp -v /tmp/known_hosts /root/.ssh/known_hosts"
  do_command_in_parallel "$command2run"
  command2run="mv -v /tmp/known_hosts /home/$K8S_SU_USER/.ssh/known_hosts"
  do_command_in_parallel "$command2run"
}

copy_in_parallel_to_all () {
  copy_in_to_all_tmp_para=$(mktemp -d)
  file2copy=$(realpath $1)
  destination=$2
  touch $copy_in_to_all_tmp_para/hopper
  squawk 3 " copy_in_parallel_to_all $@"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_sshPort' $file2copy $K8S_SU_USER@$K8S_ip1:$destination"
    echo "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_sshPort' $file2copy $K8S_SU_USER@$K8S_ip1:$destination"\
      >> $copy_in_to_all_tmp_para/hopper
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_in_to_all_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_in_to_all_tmp_para/hopper
  else
    bash $copy_in_to_all_tmp_para/hopper
  fi
  rm -Rf $copy_in_to_all_tmp_para
}

copy_in_parallel_to_role () {
  copy_in_to_role_tmp_para=$(mktemp -d)
  role2copy2=$1
  file2copy=$(realpath $2)
  destination=$3
  touch $copy_in_to_role_tmp_para/hopper
  squawk 3 " copy_in_parallel_to_role $@"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "$role2copy2" ]]; then
      squawk 3 " count $countzero_do_nodes"
      squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_sshPort' $file2copy $K8S_SU_USER@$K8S_ip1:$destination"
      echo "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_sshPort' $file2copy $K8S_SU_USER@$K8S_ip1:$destination"\
        >> $copy_in_to_role_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_in_to_role_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_in_to_role_tmp_para/hopper
  else
    bash $copy_in_to_role_tmp_para/hopper
  fi
  rm -Rf $copy_in_to_role_tmp_para
}

copy_in_parallel_to_os () {
  copy_in_to_os_tmp_para=$(mktemp -d)
  os2copy2=$1
  file2copy=$(realpath $2)
  destination=$3
  touch $copy_in_to_os_tmp_para/hopper
  squawk 3 " copy_in_parallel_to_os $@"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_os" == "$os2copy2" ]]; then
      squawk 3 " count $countzero_do_nodes"
      squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_sshPort' $file2copy $K8S_SU_USER@$K8S_ip1:$destination"
      echo "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_sshPort' $file2copy $K8S_SU_USER@$K8S_ip1:$destination"\
        >> $copy_in_to_os_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_in_to_os_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_in_to_os_tmp_para/hopper
  else
    bash $copy_in_to_os_tmp_para/hopper
  fi
  rm -Rf $copy_in_to_os_tmp_para
}

do_command_in_parallel_on_role () {
  do_command_on_role_tmp_para=$(mktemp -d)
  role2runiton=$1
  command2run=$2
  touch $do_command_on_role_tmp_para/hopper
  squawk 3 " do_command_in_parallel_on_role $@"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "$role2runiton" ]]; then
      squawk 19 " count $countzero_do_nodes"
      squawk 5 "ssh -n -p $K8S_sshPort $K8S_SU_USER@$K8S_ip1 \"sudo bash -c '$command2run'\""
      echo "ssh -n -p $K8S_sshPort $K8S_SU_USER@$K8S_ip1 \"sudo bash -c '$command2run'\""\
        >> $do_command_on_role_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_command_on_role_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_command_on_role_tmp_para/hopper
  else
    bash $do_command_on_role_tmp_para/hopper
  fi
  rm -Rf $do_command_on_role_tmp_para
}

do_test () {
  squawk 3 " do_test $@"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    echo "K8S_node=$K8S_node
K8S_role=$K8S_role
K8S_cpuCount=$K8S_cpuCount
K8S_Memory=$K8S_Memory
K8S_sshPort=$K8S_sshPort
K8S_network1=$K8S_network1
K8S_mac1=$K8S_mac1
K8S_ip1=$K8S_ip1
K8S_provisionerHost=$K8S_provisionerHost
K8S_SU_USER=$K8S_SU_USER
K8S_provisionerPort=$K8S_provisionerPort
K8S_provisionerBasePath=$K8S_provisionerBasePath
K8S_os=$K8S_os
K8S_virt=$K8S_virt
K8S_network2=$K8S_network2
K8S_mac2=$K8S_mac2
K8S_ip2=$K8S_ip2
K8S_network3=$K8S_network3
K8S_mac3=$K8S_mac3
K8S_ip3=$K8S_ipv3"
  done <<< "$kubash_hosts_csv_slurped"
}

do_command_in_parallel_on_os () {
  do_command_on_os_tmp_para=$(mktemp -d)
  os2runiton=$1
  command2run=$2
  touch $do_command_on_os_tmp_para/hopper
  squawk 3 " do_command_in_parallel $@"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_os" == "$os2runiton" ]]; then
      squawk 19 " count $countzero_do_nodes"
      squawk 5 "ssh -n -p $K8S_sshPort $K8S_SU_USER@$K8S_ip1 \"sudo bash -c '$command2run'\""
      echo "ssh -n -p $K8S_sshPort $K8S_SU_USER@$K8S_ip1 \"sudo bash -c '$command2run'\""\
        >> $do_command_on_os_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_command_on_os_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_command_on_os_tmp_para/hopper
  else
    bash $do_command_on_os_tmp_para/hopper
  fi
  rm -Rf $do_command_on_os_tmp_para
}

process_hosts_csv () {
  squawk 3 " process_hosts_csv"
  #do_etcd
  #write_kubeadmcfg_yaml
  #etcd_kubernetes_ext_etcd_method
  if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
    etcd_kubernetes_docs_stacked_method
  else
    etcd_kubernetes_ext_etcd_method
  fi
  #start_etcd
  #do_primary_master
  do_net
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    #do_masters_in_parallel
    do_nodes_in_parallel
  else
    #do_masters
    do_nodes
  fi
}

prep () {
  squawk 5 " prep"
  set_csv_columns
  while IFS="," read -r $csv_columns
  do
    preppy $K8S_node $K8S_ip1 $K8S_sshPort
  done < $KUBASH_HOSTS_CSV
}

preppy () {
  squawk 7 " preppy"
  node_name=$1
  node_ip=$2
  node_port=$3
  removestalekeys $node_ip
  ssh-keyscan -p $node_port $node_ip >> ~/.ssh/known_hosts
}

do_decom () {
  if [[ "$ANSWER_YES" == "yes" ]]; then
    decom_kvm
    rm -f $KUBASH_HOSTS_CSV
    rm -f $KUBASH_ANSIBLE_HOSTS
    rm -f $KUBASH_CLUSTER_CONFIG
  else
    read -p "This will destroy all VMs defined in the $KUBASH_HOSTS_CSV. Are you sure? [y/N] " -n 1 -r
    echo    # (optional) move to a new line
    if [[ $REPLY =~ ^[Yy]$ ]]
    then
      decom_kvm
      rm -f $KUBASH_HOSTS_CSV
      rm -f $KUBASH_ANSIBLE_HOSTS
      rm -f $KUBASH_CLUSTER_CONFIG
    fi
  fi
}

do_coreos_initialization () {
  CNI_VERSION="v0.6.0"
  RELEASE="$(curl -sSL https://dl.k8s.io/release/stable.txt)"
  CORETMP=$KUBASH_DIR/tmp
  cd $CORETMP

  do_command_in_parallel_on_os 'coreos' "mkdir -p /opt/cni/bin"
  wget -c "https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-amd64-${CNI_VERSION}.tgz"
  copy_in_parallel_to_os "coreos" $CORETMP/cni-plugins-amd64-${CNI_VERSION}.tgz /tmp/
  #rm $CORETMP/cni-plugins-amd64-${CNI_VERSION}.tgz
  do_command_in_parallel_on_os "coreos" "tar -C /opt/cni/bin -xzf /tmp/cni-plugins-amd64-${CNI_VERSION}.tgz"
  do_command_in_parallel_on_os "coreos" "rm -f /tmp/cni-plugins-amd64-${CNI_VERSION}.tgz"

  do_command_in_parallel_on_os "coreos" "mkdir -p /opt/bin"

  if [[ -e "$CORETMP/kubelet" ]]; then
    squawk 9 "kubelet has no headers and will not continue skipping for now"
  else
    wget -c https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/amd64/{kubeadm,kubelet,kubectl}
  fi
  # cd /opt/bin
  copy_in_parallel_to_os "coreos" $CORETMP/kubeadm /tmp/
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubeadm /opt/bin/"
  #rm $CORETMP/kubeadm
  copy_in_parallel_to_os "coreos" $CORETMP/kubelet /tmp/
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubelet /opt/bin/"
  #rm $CORETMP/kubelet
  copy_in_parallel_to_os "coreos" $CORETMP/kubectl /tmp/
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubectl /opt/bin/"
  #rm $CORETMP/kubectl
  do_command_in_parallel_on_os "coreos" "cd /opt/bin; chmod +x {kubeadm,kubelet,kubectl}"

  if [[ -e "$CORETMP/kubelet.service" ]]; then
    squawk 9 "already retrieved"
  else
    wget -c "https://raw.githubusercontent.com/kubernetes/kubernetes/${RELEASE}/build/debs/kubelet.service"
    sed -i 's:/usr/bin:/opt/bin:g' $CORETMP/kubelet.service
  fi
  copy_in_parallel_to_os "coreos" $CORETMP/kubelet.service /tmp/kubelet.service
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubelet.service /etc/systemd/system/kubelet.service"
  rm $CORETMP/kubelet.service
  do_command_in_parallel_on_os "coreos" "mkdir -p /etc/systemd/system/kubelet.service.d"
  if [[ -e "$CORETMP/10-kubeadm.conf" ]]; then
    squawk 9 "already retrieved"
  else
    wget -c "https://raw.githubusercontent.com/kubernetes/kubernetes/${RELEASE}/build/debs/10-kubeadm.conf"
    sed -i 's:/usr/bin:/opt/bin:g' $CORETMP/10-kubeadm.conf
  fi
  copy_in_parallel_to_os "coreos" $CORETMP/10-kubeadm.conf /tmp/10-kubeadm.conf
  do_command_in_parallel_on_os "coreos" " mv /tmp/10-kubeadm.conf /etc/systemd/system/kubelet.service.d/10-kubeadm.conf"
  rm $CORETMP/10-kubeadm.conf

  do_command_in_parallel_on_os "coreos" " systemctl restart docker.service ; systemctl enable docker.service"

  #do_command_in_parallel_on_os "coreos" "systemctl unmask kubelet.service ; systemctl restart kubelet.service ; systemctl enable kubelet.service"
  do_command_in_parallel_on_os "coreos" "systemctl restart kubelet.service ; systemctl enable kubelet.service"

  #rmdir $CORETMP
}

do_openebs () {
  kubectl --kubeconfig=$KUBECONFIG create -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-operator.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-storageclasses.yaml
}

coreos_build  () {
  build_virt=$1
  target_os=$2
  CHANNEL=$3
  chkdir $KVM_builderDir
  chkdir $KVM_builderTMP

  rsync $KUBASH_RSYNC_OPTS "ssh -p$KVM_builderPort" $KUBASH_DIR/pax/CoreOS_Image_Signing_Key.asc $KVM_builderUser@$KVM_builderHost:/tmp/
  command2run="gpg --import --keyid-format LONG /tmp/CoreOS_Image_Signing_Key.asc"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="cd $KVM_builderTMP; wget -c https://$CHANNEL.release.core-os.net/amd64-usr/current/coreos_production_qemu_image.img.bz2{,.sig}"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="cd $KVM_builderTMP;gpg --verify coreos_production_qemu_image.img.bz2.sig"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="cd $KVM_builderTMP;rm coreos_production_qemu_image.img.bz2.sig"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="cd $KVM_builderTMP;bunzip2 coreos_production_qemu_image.img.bz2"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"

  TARGET_FILE="$KVM_builderTMP/coreos_production_qemu_image.img"
  DESTINATION_FILE="$KVM_builderBasePath/$target_os-$KVM_BASE_IMG"
  command2run="$MV_CMD $TARGET_FILE $DESTINATION_FILE"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
}

packer_build  () {
  build_virt=$1
  target_os=$2
  target_build=$3
  chkdir $KVM_builderDir
  chkdir $KVM_builderTMP

  if [[ $VERBOSITY -gt '1' ]]; then
    LN_CMD='ln -fsv'
  else
    LN_CMD='ln -fs'
  fi

  command2run="cd $KUBASH_DIR/pax;if [ ! -e "$KUBASH_DIR/pax/build" ]; then $LN_CMD $KVM_builderDir $KUBASH_DIR/pax/builds; fi"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"

  cd $KUBASH_DIR/pax/$target_os
  squawk 2 " Executing packer build..."

  if [[ "$debug" == "true" ]]; then
    debug_flag='-debug -on-error=ask'
    PACKER_LOG=1
  else
    debug_flag=''
    PACKER_LOG=0
  fi
  squawk 2 "TMPDIR=$KVM_builderTMP packer build -only=$build_virt $debug_flag $target_build.json"
  packer_build_cmd="packer build -only=$build_virt $debug_flag $target_build.json"
  command2run="cd $KUBASH_DIR/pax/$target_os; PACKER_LOG=$PACKER_LOG TMPDIR=$KVM_builderTMP $packer_build_cmd"
  do_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"

  TARGET_FILE=$KVM_builderDir/packer-$target_build-$build_virt/$target_build
  DESTINATION_FILE=$KVM_builderBasePath/$target_os-$KVM_BASE_IMG
  command2run="$MV_CMD $TARGET_FILE $DESTINATION_FILE"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="rm -Rf $KVM_builderDir/packer-$target_build-$build_virt"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
}

activate_monitoring () {
  # Prometheus
  cd $KUBASH_DIR/submodules/openebs/k8s/openebs-monitoring/configs
  kubectl --kubeconfig=$KUBECONFIG create -f \
    prometheus-config.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f \
    prometheus-env.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f \
    prometheus-alert-rules.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f \
    alertmanager-templates.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f \
    alertmanager-config.yaml
  cd $KUBASH_DIR/submodules/openebs/k8s/openebs-monitoring
  kubectl --kubeconfig=$KUBECONFIG create -f \
    prometheus-operator.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f \
    alertmanager.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f \
    grafana-operator.yaml
}

build_all_in_parallel () {
  squawk 1 'Building all targets in parallel'
  $PSEUDO rm -Rf $KVM_builderTMP
  $PSEUDO rm -Rf $KVM_builderDir
  build_all_tmp_para=$(mktemp -d --suffix='.para.tmp')
  touch $build_all_tmp_para/hopper
  OS_LIST=(centos kubeadm kubeadm2ha kubespray openshift ubuntu debian coreos)
  build_count=0
  while [ "x${OS_LIST[build_count]}" != "x" ]
  do
    command2run="kubash build --target-os=${OS_LIST[build_count]} -y"
    squawk 5 "$command2run"
    echo "$command2run" >> $build_all_tmp_para/hopper
    ((++build_count))
  done

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $build_all_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $build_all_tmp_para/hopper
  else
    bash $build_all_tmp_para/hopper
  fi
  rm -Rf $build_all_tmp_para
  squawk 1 'Done Building all targets'
}

yaml2cluster () {
  squawk 15 "yaml2cluster"
  yaml2cluster_tmp=$(mktemp -d)
  if [[ -z "$1" ]]; then
    echo 'yaml2cluster requires an argument'
    exit 1
  fi
  this_yaml=$1
  this_json=$yaml2cluster_tmp/this.json
  yaml2json $this_yaml > $this_json
  json2cluster $this_json
  rm $this_json
  rm -Rf $yaml2cluster_tmp
}

json2cluster () {
  squawk 15 "json2cluster"
  json2cluster_tmp=$(mktemp -d)
  if [[ -z "$1" ]]; then
    echo 'json2cluster requires an argument'
    exit 1
  fi
  this_json=$1

  if [[ -e $KUBASH_DIR/clusters/$KUBASH_CLUSTER_NAME ]]; then
    horizontal_rule
    echo "The cluster directory already exists! $KUBASH_DIR/clusters/$KUBASH_CLUSTER_NAME"
    horizontal_rule
    exit 1
  fi

  # csv_version
  # should be a string not an int!
  jq -r '.csv_version | "\(.)" ' \
    $this_json > $json2cluster_tmp/csv_version
  # kubernetes_version
  # should be a string not an int!
  jq -r '.kubernetes_version | "\(.)" ' \
    $this_json > $json2cluster_tmp/kubernetes_version

  KUBASH_CSV_VER=$(cat $json2cluster_tmp/csv_version)
  squawk 11 "CSV_VER=$KUBASH_CSV_VER"
  if [ "$KUBASH_CSV_VER" = '2.0.0' ]; then
    # provision.csv
    jq -r \
      '.hosts[] | "\(.hostname),\(.role),\(.cpuCount),\(.Memory),\(.sshPort),\(.network1.network),\(.network1.mac),\(.network1.ip),\(.network1.routingprefix),\(.network1.subnetmask),\(.network1.broadcast),\(.network1.gateway),\(.provisioner.Host),\(.provisioner.User),\(.provisioner.Port),\(.provisioner.BasePath),\(.os),\(.virt),\(.network2.network),\(.network2.mac),\(.network2.ip),\(.network2.routingprefix),\(.network2.subnetmask),\(.network2.broadcast),\(.network2.gateway),\(.network3.network),\(.network3.mac),\(.network3.ip),\(.network3.routingprefix),\(.network3.subnetmask),\(.network3.broadcast),\(.network3.gateway)"' \
      $this_json >  $json2cluster_tmp/tmp.csv
  elif [ "$KUBASH_CSV_VER" = '1.0.0' ]; then
    # provision.csv
    jq -r \
      '.hosts[] | "\(.hostname),\(.role),\(.cpuCount),\(.Memory),\(.sshPort),\(.network1.network),\(.network1.mac),\(.network1.ip),\(.provisioner.Host),\(.provisioner.User),\(.provisioner.Port),\(.provisioner.BasePath),\(.os),\(.virt),\(.network2.network),\(.network2.mac),\(.network2.ip),\(.network3.network),\(.network3.mac),\(.network3.ip)"' \
      $this_json >  $json2cluster_tmp/tmp.csv
  else
    echo 'CSV columns cannot be set CSV Version not recognized'
    exit 1
  fi

  set_csv_columns $KUBASH_CSV_VER
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_mac1" == 'null' ]]; then
      K8S_mac1=$(VERBOSITY=0 kubash --verbosity=1 genmac)
    fi
    if [[ "$K8S_network2" != 'null' ]]; then
      if [[ "$K8S_mac2" == 'null' ]]; then
        K8S_mac2=$(VERBOSITY=0 kubash --verbosity=1 genmac)
      fi
    fi
    if [[ "$K8S_network3" != 'null' ]]; then
      if [[ "$K8S_mac3" == 'null' ]]; then
        K8S_mac3=$(VERBOSITY=0 kubash --verbosity=1 genmac)
      fi
    fi
    if [ "$KUBASH_CSV_VER" = '2.0.0' ]; then
      squawk 6 "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_sshPort,$K8S_network1,$K8S_mac1,$K8S_ip1,$K8S_routingprefix1,$K8S_subnetmask1,$K8S_broadcast1,$K8S_gateway1,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_routingprefix2,$K8S_subnetmask2,$K8S_broadcast2,$K8S_gateway2,$K8S_network3,$K8S_mac3,$K8S_ip3,$K8S_routingprefix3,$K8S_subnetmask3,$K8S_broadcast3,$K8S_gateway3"
      echo "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_sshPort,$K8S_network1,$K8S_mac1,$K8S_ip1,$K8S_routingprefix1,$K8S_subnetmask1,$K8S_broadcast1,$K8S_gateway1,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_routingprefix2,$K8S_subnetmask2,$K8S_broadcast2,$K8S_gateway2,$K8S_network3,$K8S_mac3,$K8S_ip3,$K8S_routingprefix3,$K8S_subnetmask3,$K8S_broadcast3,$K8S_gateway3" \
        >>  $json2cluster_tmp/provision.csv
    elif [ "$KUBASH_CSV_VER" = '1.0.0' ]; then
      echo "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_sshPort,$K8S_network1,$K8S_mac1,$K8S_ip1,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_network3,$K8S_mac3,$K8S_ip3" \
        >>  $json2cluster_tmp/provision.csv
    else
      echo 'CSV columns cannot be set CSV Version not recognized'
      exit 1
    fi
  done < "$json2cluster_tmp/tmp.csv"

  rm $json2cluster_tmp/tmp.csv
  squawk 5 "$(cat $json2cluster_tmp/provision.csv)"

  # ca-data.yaml
#### BEGIN --> Indentation break warning <-- BEGIN
  jq -r \
    '.ca[] | "CERT_COMMON_NAME: \(.CERT_COMMON_NAME)
CERT_COUNTRY: \(.CERT_COUNTRY)
CERT_LOCALITY: \(.CERT_LOCALITY)
CERT_ORGANISATION: \(.CERT_ORGANISATION)
CERT_STATE: \(.CERT_STATE)
CERT_ORG_UNIT: \(.CERT_ORG_UNIT)"' \
    $this_json >  $json2cluster_tmp/ca-data.yaml
#### END --> Indentation break warning <-- END
  squawk 5 "$(cat $json2cluster_tmp/ca-data.yaml)"

  # net_set
  jq -r '.net_set | "\(.)" ' \
    $this_json >  $json2cluster_tmp/net_set
  squawk 7 "$(cat $json2cluster_tmp/net_set)"

  # users.csv
  jq -r '.users | to_entries[] | "\(.key),\(.value.role)"' \
    $this_json >  $json2cluster_tmp/users.csv


  $CP_CMD $KUBASH_DIR/templates/ca-csr.json $json2cluster_tmp/
  $CP_CMD $KUBASH_DIR/templates/ca-config.json $json2cluster_tmp/
  $CP_CMD $KUBASH_DIR/templates/client.json $json2cluster_tmp/

  $MV_CMD $json2cluster_tmp $KUBASH_DIR/clusters/$KUBASH_CLUSTER_NAME
}

kubash_interactive () {
  horizontal_rule
  echo "Interactive Kubash Shell Enter 'help' for help, 'kh' for kubectl help or 'quit' to quit"
  echo "working with the $KUBASH_CLUSTER_NAME kubash cluster, or set with 'clustername'"
  set +e

  while true
  do
    myinput=$(rlwrap -f $KUBASH_DIR/.kubash_completions -s $KUBASH_HISTORY_LIMIT -S 'K8$ ' -H $KUBASH_HISTORY -D2 head -n1)
    read command args <<< $myinput
    squawk 29 "$command $args"
    case $command
    in
      quit|exit)             exit 0                       ;;
      help|\?)               interactive_usage            ;;
      khelp|kh)               kubectl_interactive_usage   ;;
      verbosity)             set_verbosity $args          ;;
      v)                increase_verbosity $args          ;;
      switch|use|n|cluster|name) set_name  $args          ;;
      k|kubectl) kubectl_passthru $args                   ;;
      h|helm) helm_passthru $args                         ;;
      g|get) kubectl_passthru get $args                   ;;
      l|list) helm_passthru list                          ;;
      d|describe) kubectl_passthru describe $args         ;;
      keti) kubectl_passthru exec -ti $args               ;;
      kgn) kubectl_passthru get nodes $args               ;;
      kgpa) kubectl_passthru get pods --all-namespaces $args | grep -v '^pvc-' ;;
      kgp) kubectl_passthru get pods $args | grep -v '^pvc-' ;;
      kgpvc) kubectl_passthru get pods $args | grep '^pvc-' ;;
      klp) kubectl_passthru logs pods $args               ;;
      kep) kubectl_passthru logs pods $args               ;;
      kdp) kubectl_passthru describe pods $args           ;;
      kdelp) kubectl_passthru delete pods $args           ;;
      kgs) kubectl_passthru get svc $args                 ;;
      kes) kubectl_passthru edit svc $args                ;;
      kds) kubectl_passthru describe svc $args            ;;
      kdels) kubectl_passthru delete svc $args            ;;
      kgsec) kubectl_passthru get secret $args            ;;
      kdsec) kubectl_passthru decribe secret $args        ;;
      kdelsec) kubectl_passthru delete secret $args       ;;
      kgd) kubectl_passthru get deployment $args          ;;
      ked) kubectl_passthru edit deployment $args         ;;
      kei) kubectl_passthru edit ingress.voyager.appscode.com $args ;;
      kdd) kubectl_passthru describe deployment $args     ;;
      kdeld) kubectl_passthru delete deployment $args     ;;
      ksd) kubectl_passthru scale deployment $args        ;;
      krsd) kubectl_passthru rollout status deployment $args ;;
      kgrs) kubectl_passthru get rs $args                 ;;
      krh) kubectl_passthru get rollout history $args     ;;
      kru) kubectl_passthru get rollout undo $args        ;;
      *) interactive_results=$(kubash -n $KUBASH_CLUSTER_NAME $command $args) ;;
    esac
    echo "$interactive_results"
  done
  set -e
}

kubectl_passthru () {
    squawk 5 "kubectl --kubeconfig=$KUBASH_CLUSTER_DIR/config $@"
    kubectl --kubeconfig=$KUBASH_CLUSTER_DIR/config $@
}

helm_passthru () {
    squawk 5 "KUBECONFIG=$KUBASH_CLUSTER_DIR/config helm $@"
    KUBECONFIG=$KUBASH_CLUSTER_DIR/config helm $@
}

set_verbosity () {
  if ! [[ "$1" =~ ^[0-9]+$ ]]; then
    VERBOSITY=0
  else
    VERBOSITY=$1
  fi
  squawk 5 " verbosity is now $VERBOSITY"
}

increase_verbosity () {
  ((++VERBOSITY))
  squawk 5 " verbosity is now $VERBOSITY"
}

set_name () {
  squawk 9 "set_name $1"
  squawk 8 "Kubash will now work with the $1 cluster"
  KUBASH_CLUSTER_NAME="$1"
  KUBASH_CLUSTER_DIR=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME
  KUBASH_CLUSTER_CONFIG=$KUBASH_CLUSTER_DIR/config
  export KUBECONFIG=$KUBASH_CLUSTER_CONFIG
  KUBASH_HOSTS_CSV=$KUBASH_CLUSTER_DIR/hosts.csv
  KUBASH_ANSIBLE_HOSTS=$KUBASH_CLUSTER_DIR/hosts
  KUBASH_PROVISION_CSV=$KUBASH_CLUSTER_DIR/provision.csv
  KUBASH_USERS_CSV=$KUBASH_CLUSTER_DIR/users.csv
  KUBASH_CSV_VER_FILE=$KUBASH_CLUSTER_DIR/csv_version
  net_set
  if [[ -e $KUBASH_CLUSTER_DIR/csv_version ]]; then
    set_csv_columns
    if [[ -e $KUBASH_CLUSTER_DIR/provision.csv ]]; then
      provision_csv_slurp
      squawk 160 "slurpy -----> $(echo $kubash_provision_csv_slurped)"
    fi
    if [[ -e $KUBASH_CLUSTER_DIR/hosts.csv ]]; then
      hosts_csv_slurp
      squawk 150 "slurpy -----> $(echo $kubash_hosts_csv_slurped)"
      while IFS="," read -r $csv_columns
      do
        if [[ "$K8S_role" == 'etcd' ]]; then
        export MASTERS_AS_ETCD="false"
        fi
      done <<< "$kubash_hosts_csv_slurped"
    fi
  fi
}

main () {
  checks
  # save original io
  exec 3>&1 4>&2
  # Let's display everything on stderr.
  exec 1>&2

  # If cmd empty print usage
  if [[ -z "$1" ]]; then
    kubash_interactive
    exit 0
  fi

  squawk 5 'parse opts'

  # Execute getopt on the arguments passed to this program, identified by the special character $@
  short_opts="c:hvyn:"
  long_opts="version,oidc,clustername:,initializer:,csv:,help,yes,verbose,verbosity:,target-os:,target-build:,build-virt:,node-join-name:,node-join-user:,node-join-ip:,node-join-port:,node-join-role:,parallel:,builder:,debug,provisioner:"
  PARSED_OPTIONS=$(getopt -n "$0" -o "$short_opts" --long "$long_opts" -- "$@")

  #Bad arguments, something has gone wrong with the getopt command.
  if [[ $? -ne 0 ]];
  then
    horizontal_rule
    echo 'bad argruments'
    exit 1
  fi

  # A little magic, necessary when using getopt.
  eval set -- "$PARSED_OPTIONS"

  squawk 5 'loop through opts'

  opt_loop_count=1
  while true; do
    squawk 5 "$opt_loop_count $@"
    opt_loop_count=`expr $opt_loop_count + 1`
    case "$1" in
      -h|--help)
        print_help=true
        shift;;
      --debug)
        debug=true
        shift;;
      --version)
        echo "Kubash, version $KUBASH_VERSION"
        exit 0
        shift;;
      -y|--yes)
        ANSWER_YES=yes
        shift;;
      -n|--clustername)
        set_name "$2"
        shift 2 ;;
      -c|--csv)
        KUBASH_HOSTS_CSV="$2"
        RAISON=true
        shift 2 ;;
      --provisioner)
        provisioner="$2"
        shift 2 ;;
      --initializer)
        initializer="$2"
        shift 2 ;;
      --parallel)
        PARALLEL_JOBS="$2"
        shift 2 ;;
      --node-join-name)
        node_join_name="$2"
        shift 2 ;;
      --node-join-user)
        node_join_user="$2"
        shift 2 ;;
      --node-join-ip)
        node_join_ip="$2"
        shift 2 ;;
      --node-join-port)
        node_join_port="$2"
        shift 2 ;;
      --node-join-role)
        node_join_role="$2"
        shift 2 ;;
      --target-os)
        target_os="$2"
        shift 2 ;;
      --target-build)
        target_build="$2"
        shift 2 ;;
      --build-virt)
        build_virt="$2"
        shift 2 ;;
      -v|--verbose)
        increase_verbosity
        shift;;
      --verbosity)
        set_verbosity $2
        shift 2 ;;
      --oidc)
        KUBASH_OIDC_AUTH=true
        squawk 2 "OIDC Auth turned on"
        shift;;
      --builder)
        builder=$2
        shift 2 ;;
      --)
        shift
        break;;
    esac
  done

  if [[ $VERBOSITY -gt '1' ]]; then
    KUBASH_RSYNC_OPTS='-H -azve'
    if [[ "$ANSWER_YES" == "yes" ]]; then
      MV_CMD='mv -v'
      CP_CMD='cp -v'
    else
      MV_CMD='mv -iv'
      CP_CMD='cp -iv'
    fi
  else
    if [[ "$ANSWER_YES" == "yes" ]]; then
      MV_CMD='mv'
      CP_CMD='cp'
    else
      MV_CMD='mv -i'
      CP_CMD='cp -i'
    fi
  fi

  chkdir $KUBASH_CLUSTERS_DIR

  squawk 7 "Check args"

  if [[ $# -eq 0 ]]; then
    kubash_interactive
  fi
  RAISON=$1
  squawk 5 "Raison set to $RAISON"
  shift


  if [[ $RAISON = "false" || "$RAISON" = "help" ]]; then
    horizontal_rule
    usage
    exit 1
  fi

  if [[ $RAISON == "auto" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    squawk 1 "Full auto engaged"
    kubash provision \
      -n $KUBASH_CLUSTER_NAME
    kubash ping \
      -n $KUBASH_CLUSTER_NAME
    kubash configure_interfaces \
      -n $KUBASH_CLUSTER_NAME
    kubash init \
      -n $KUBASH_CLUSTER_NAME
    sleep 10
    kubash openebs \
      -n $KUBASH_CLUSTER_NAME
    sleep 10
    kubash dashboard \
      -n $KUBASH_CLUSTER_NAME
    kubash voyager \
      -n $KUBASH_CLUSTER_NAME
    kubash searchlight \
      -n $KUBASH_CLUSTER_NAME
    sleep 10
    kubash tiller  \
      -n $KUBASH_CLUSTER_NAME
    squawk 1 "Full auto finished"
    exit 0
  elif [[ $RAISON == "grab" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
        do_grab
  elif [[ $RAISON == "grant" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    if [[ $# -eq 0 ]]; then
      grant_users
    elif [[ $# -eq 2 ]]; then
      grant $1 $2
    else
      horizontal_rule
      usage
      exit 1
    fi
    exit 0
  elif [[ $RAISON == "openebs" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
        do_openebs
  elif [[ $RAISON == "genmac" ]]; then
    genmac
  elif [[ $RAISON == "dry" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
        VERBOSITY=`expr $VERBOSITY + 1`
        do_test
  elif [[ $RAISON == "hosts" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    write_ansible_hosts
    exit 0
  elif [[ $RAISON == "dotfiles" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    squawk 5 'Adjusting dotfiles'
    dotfiles_install
    exit 0
  elif [[ $RAISON == "show" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    VERBOSITY=`expr $VERBOSITY + 10`
    read_csv
  elif [[ $RAISON == "test" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    VERBOSITY=`expr $VERBOSITY + 10`
    do_test
  elif [[ $RAISON == "ping" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    ping_in_parallel
    else
      ping
    fi
  elif [[ $RAISON == "aping" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    write_ansible_hosts
    ansible-ping
  elif [[ $RAISON == "monitoring" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    activate_monitoring
  elif [[ $RAISON == "prep" ]]; then
    prep
  elif [[ $RAISON == "provision" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      provision_usage
      exit 1
    fi
    if [ "$provisioner" = 'gke' ]; then
      gke-provisioner $@
    else
      copy_image_to_all_provisioning_hosts
      provisioner
      squawk 1 "wating on hosts to come up"
      sleep 33
      refresh_network_addresses
      prep
      remove_vagrant_user
      hostname_in_parallel
      copy_known_hosts
    fi
  elif [[ $RAISON == "hostnamer" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    hostname_in_parallel
  elif [[ $RAISON == "decommission" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      decom_usage
      exit 1
    fi
    do_decom
  elif [[ $RAISON == "demo" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    demo
  elif [[ $RAISON == "ingress" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_nginx_ingress $KUBASH_INGRESS_NAME
  elif [[ $RAISON == "interactive" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    kubash_interactive $@
  elif [[ $RAISON == "masters" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    DO_MASTER_JOIN=true
    initialize
    do_grab
  elif [[ $RAISON == "minit" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    DO_MASTER_JOIN=false
    DO_NODE_JOIN=false
    initialize
  elif [[ $RAISON == "nodes" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    DO_NODE_JOIN=true
    initialize
    do_grab
  elif [[ $RAISON == "init" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    if [[ -z "$initializer" ]]; then
      initializer=kubeadm
      DO_NODE_JOIN=true
      DO_MASTER_JOIN=true
      kubeadm_reset
      copy_known_hosts
      squawk 5 "Initialize"
      initialize
      do_grab
      ping
      exit 0
    elif [[ "$initializer" == "kubespray" ]]; then
      kubespray_initialize
      exit 0
    elif [[ "$initializer" == "openshift" ]]; then
      openshift_initialize
      exit 0
    elif [[ "$initializer" == "kubeadm2ha" ]]; then
      kubeadm2ha_initialize
      exit 0
    fi
  elif [[ $RAISON == "extras" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    do_tiller
  elif [[ $RAISON == "yaml2cluster" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    yaml2cluster $@
  elif [[ $RAISON == "json2cluster" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    json2cluster $@
  elif [[ $RAISON == "searchlight" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_searchlight
  elif [[ $RAISON == "taint_ingress" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    taint_ingress $@
  elif [[ $RAISON == "dashboard" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_dashboard
  elif [[ $RAISON == "kafka" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_kafka
  elif [[ $RAISON == "redis" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_redis
  elif [[ $RAISON == "postgres" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
  do_postgres
  elif [[ $RAISON == "rabbitmq" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
  do_rabbitmq
  elif [[ $RAISON == "percona" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
  do_percona
  elif [[ $RAISON == "jupyter" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
  do_jupyter
  elif [[ $RAISON == "mongodb" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
  do_mongodb
  elif [[ $RAISON == "jenkins" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
  do_jenkins
  elif [[ $RAISON == "voyager" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_voyager
  elif [[ $RAISON == "configure_interfaces" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    configure_secondary_network_interfaces
  elif [[ $RAISON == "traefik" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_traefik
  elif [[ $RAISON == "linkerd" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_linkerd
  elif [[ $RAISON == "tiller" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_tiller
  elif [[ $RAISON == "refresh" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    refresh_network_addresses
  elif [[ $RAISON == "armor_fix" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    apparmor_fix_all_provisioning_hosts
  elif [[ $RAISON == "known_hosts" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    copy_known_hosts $@
  elif [[ $RAISON == "prepetcd" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    prep_etcd $@
  elif [[ $RAISON == "copy" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    copy_image_to_all_provisioning_hosts
  elif [[ $RAISON == "reset" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    kubeadm_reset
  elif [[ $RAISON == "build-all" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    build_all_in_parallel
  elif [[ $RAISON == "etcd_ext" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      etcd_kubernetes_docs_stacked_method
    else
      etcd_kubernetes_ext_etcd_method
    fi
  elif [[ $RAISON == "do_net" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_net
  elif [[ $RAISON == "build" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      build_usage
      exit 1
    fi
    if [[ -z "$builder" ]]; then
      builder='packer'
    fi
    if [[ -z "$target_os" ]]; then
      target_os=kubeadm
      if [[ -z "$target_build" ]]; then
        target_build=kubeadm-7.4-x86_64
      fi
    elif [[ "$target_os" == "debian" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=debian-9.3-amd64
      fi
    elif [[ "$target_os" == "centos" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=centos-7.4-x86_64
      fi
    elif [[ "$target_os" == "openshift" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=openshift-7.4-x86_64
      fi
    elif [[ "$target_os" == "kubespray" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=kubespray-7.5-x86_64
      fi
    elif [[ "$target_os" == "kubeadm2ha" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=kubeadm2ha-7.4-x86_64
      fi
    elif [[ "$target_os" == "kubeadm" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=kubeadm-7.4-x86_64
      fi
    elif [[ "$target_os" == "fedora" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=fedora-27-x86_64
      fi
    elif [[ "$target_os" == "kubeadm197" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=kubeadm197-7.4-x86_64
      fi
    elif [[ "$target_os" =~ 'ubuntu' ]]; then
      if [[ -z "$target_build" ]]; then
        echo "matching $target_os"
        build_num=$(echo $target_os | sed 's/ubuntu//')
        target_build=ubuntu$build_num-16.04-amd64
      fi
    elif [[ "$target_os" == "coreos" ]]; then
      #override packer atm
      builder=coreos
      if [[ $builder == "packer" ]]; then
        horizontal_rule
        echo 'packer not supported for coreos at this time'
        exit 1
      elif [[ $builder == "coreos" ]]; then
        if [[ -z "$target_build" ]]; then
    squawk 5 "Setting coreos channel to stable"
          target_build=stable
        fi
      fi
    fi
    if [[ -z "$target_build" ]]; then
      target_build=ubuntu-16.04-amd64
    fi
    if [[ -z "$build_virt" ]]; then
      build_virt=qemu
    fi
    if [[ $builder == "packer" ]]; then
      squawk 5 "packer_build $build_virt $target_os $target_build"
      packer_build $build_virt $target_os $target_build
    elif [[ $builder == "coreos" ]]; then
      squawk 5 "coreos_build $build_virt $target_os $target_build"
      coreos_build $build_virt $target_os $target_build
    elif [[ $builder == "veewee" ]]; then
      squawk 2 " Executing vee wee build..."
      # veewee_build
      horizontal_rule
      echo 'VeeWee support not built yet :('
      exit 1
    else
      horizontal_rule
      echo 'builder not recognized'
      exit 1
    fi
    exit 0
  elif [[ $RAISON == "node_join" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      node_usage
      exit 1
    fi
    if [[ -z "$node_join_name" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-name option'
      exit 1
    fi
    if [[ -z "$node_join_ip" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-ip option'
      exit 1
    fi
    if [[ -z "$node_join_user" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-user option'
      exit 1
    fi
    if [[ -z "$node_join_port" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-port option'
      exit 1
    fi
    if [[ -z "$node_join_role" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-role option'
      exit 1
    fi
    if [[ $node_join_role == "node" ]]; then
      squawk 2 " Executing node join..."
      DO_NODE_JOIN=true
      node_join $node_join_name $node_join_ip $node_join_user $node_join_port
    elif [[ $node_join_role == "master" ]]; then
      squawk 2 " Executing master join..."
      DO_MASTER_JOIN=true
      master_join $node_join_name $node_join_ip $node_join_user $node_join_port
    fi
    exit 0
  else
    squawk 8 'passthru'
    # Else fall through to passing on to kubectl for the current cluster
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    squawk 5 "kubectl -n $KUBASH_CLUSTER_NAME --kubeconfig=$KUBASH_CLUSTER_DIR/config $RAISON $@"
    kubectl -n $KUBASH_CLUSTER_NAME --kubeconfig=$KUBASH_CLUSTER_DIR/config $RAISON $@
  fi

  if [[ $print_help == "true" ]]; then
    horizontal_rule
    usage
    exit 1
  fi

  exit 0
  # End main block
}

main "$@"
