#!/usr/bin/env bash
KUBASH_VERSION=v1.9.3
: ${KUBERNETES_VERSION:=$KUBASH_VERSION}
: ${KUBASH_CLUSTER_NAME=default}
: ${KUBASH_DIR:=$HOME/.kubash}
: ${KUBASH_BIN:=$KUBASH_DIR/bin}
: ${KUBASH_CLUSTERS_DIR:=$KUBASH_DIR/clusters}
: ${KUBASH_CLUSTER_DIR:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME}
: ${KUBASH_CLUSTER_CONFIG:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/config}
: ${KUBASH_HOSTS_CSV:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/hosts.csv}
: ${KUBASH_ANSIBLE_HOSTS:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/hosts}
: ${KUBASH_PROVISION_CSV:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/provision.csv}
: ${KUBASH_USERS_CSV:=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/users.csv}
: ${KUBASH_INGRESS_NAME:='kubashingress'}
: ${KUBASH_OIDC_AUTH:='false'}
: ${KUBEADMIN_IGNORE_PREFLIGHT_CHECKS:='--ignore-preflight-errors cri'}
: ${VERBOSITY:=0}
: ${KVM_builderBasePath:=/var/lib/libvirt/images}
: ${KVM_builderHost:=localhost}
: ${KVM_builderPort:=22}
: ${KVM_builderUser:=coopadmin}
: ${KVM_builderTMP:=$KVM_builderBasePath/kubashtmp}
: ${KVM_builderDir:=$KVM_builderBasePath/kubashbuilds}
: ${KVM_BASE_IMG:=kubash.qcow2}
: ${KVM_RAM:=4096}
: ${KVM_CPU:=2}
: ${KVM_NET:='default'}
: ${PSEUDO:=sudo -i}
: ${K8S_user:=root}
: ${K8S_NET:=calico}
: ${K8S_provisionerPort:=22}
: ${K8S_SU_PATH:='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin'}
: ${my_DOMAIN:=example.com}
: ${GOPATH:=~/.go}
: ${KUTIME:="/usr/bin/time -v"}
: ${PARALLEL_JOBS:=1}
: ${PARALLEL:="parallel"}
: ${OPENSHIFT_REGION:=lab}
: ${OPENSHIFT_ZONE:=baremetal}
: ${MASTERS_AS_ETCD:='true'}
: ${BROADCAST_TO_NETWORK:='10.0.23.0/24'}
: ${INTERFACE_NET:='eth0'}
: ${DO_KEEPALIVED:='false'}
: ${DO_CRICTL:='false'}
: ${ETCD_VERSION:=v3.2.16}
: ${KUBASH_RSYNC_OPTS:='-H -aze'}
: ${CALICO_URL:=https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml}
: ${FLANNEL_URL:=https://raw.githubusercontent.com/coreos/flannel/v0.9.1/Documentation/kube-flannel.yml}

set -e

net_set () {
  # Set networking defaults
  if [[ -e "$KUBASH_CLUSTER_DIR/net_set" ]]; then
    K8S_NET=$(cat $KUBASH_CLUSTER_DIR/net_set)
  fi
  if [[ "$K8S_NET" == "calico" ]]; then
    my_KUBE_CIDR="192.168.0.0/16"
  elif [[ "$K8S_NET" == "flannel" ]]; then
    my_KUBE_CIDR="10.244.0.0/16"
  else
    horizontal_rule
    echo 'unknown pod network'
    exit 1
  fi
}

net_set


export KUBECONFIG=$KUBASH_CLUSTER_CONFIG
# Rasion d'etre
RAISON=false

# global vars
ANSWER_YES=no
print_help=no

# prep the columns strings for csv input
user_csv_columns="user_email user_role"
csv_columns="K8S_node K8S_role K8S_cpuCount K8S_Memory K8S_network1 K8S_mac1 K8S_ip1 K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt K8S_network2 K8S_mac2 K8S_ip2 K8S_network3 K8S_mac3 K8S_ip3"
uniq_hosts_list_columns="K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt"

squawk () {
  # This function simplifies error reporting and verbosity
  # call it by preceding your message with a verbosity level
  # e.g. `squawk 3 "This is a squawk"`
  # if the current verbosity level is greater than or equal to
  # the number given then this function will echo out your message
  # and pad it with # to let you now how verbose that message was
  squawk_lvl=$1
  shift
  squawk=$1
  shift
  squawk_opt=$@

  if [[ "$VERBOSITY" -ge "$squawk_lvl" ]] ; then
  count_squawk=0
    while [[ "$count_squawk" -lt "$squawk_lvl" ]]; do
      echo -n "#"
      count_squawk=`expr $count_squawk + 1`
    done
    echo " $squawk"
  fi
}

horizontal_rule () {
  printf '%*s\n' "${COLUMNS:-$(tput cols)}" '' | tr ' ' -
}

squawk 3 "Kubash, by Josh Cox"

usage () {
  horizontal_rule
  # Print usage
  echo 'kubash, by Josh Cox 2018.01.31
usage: kubash COMMAND
This script automates the setup and maintenance of a kubernetes cluster
e.g.

kubash init
'
  horizontal_rule
echo '
commands:

build - build a base image

provision - provision individual nodes

init - initialize the cluster

reset - reset the cluster with `kubeadm reset` on all hosts

decommission - tear down the cluster and decommission nodes

show - show the analyzed input of the hosts file

ping - Perform ansible ping to all hosts

auto - Full auto will provision and initialize all hosts

masters - Perform initialization of masters

nodes - Perform initialization of nodes

dotfiles - Perform dotfiles auto configuration

grab - Grab the .kube/config from the master

hosts - Write ansible hosts file

dry - Perform dry run

copy - copy the built images to the provisioning hosts
'
  horizontal_rule
echo '
options:

 -h --help - Print usage

 -c --csv FILE - Set the csv file to be parsed

 --parallel NUMBER_OF_THREADS - set the number of parallel jobs for tasks that support it

 -v --verbose - Increase the verbosity (can set multiple times to incrementally increase e.g. `-vvvv`

 --verbosity NUMBER - or you can set the verbosity directly

 --debug - adds the debug flag

 -n --clustername - use a particular cluster by name
'
}

node_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash node_join
build - build a base image

This command joins a node to the cluster
e.g.

kubash node_join

options:

 -h --help - Print usage
 --node-join-name - set node name
 --node-join-user - set node user
 --node-join-ip   - set node ip
 --node-join-port - set node port
 --node-join-role - set node role
 -n --clustername - use a particular cluster by name
'
}

build_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash build
build - build a base image

This script automates the setup and maintenance of a kubernetes cluster
e.g.

kubash build

options:

 -h --help - Print usage
 --builder - choose builder (packer,coreos)
 --target-os - choose target-os (debian,ubuntu,centos,fedora,coreos)
 --target-build - choose target-build
'
}

init_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash init

This initializes the cluster

options:

 -h --help - Print usage
 --initializer - Choose the initialization method (kubeadm,kubespray,openshift)
 -n --clustername - use a particular cluster by name
'
}

provision_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash provision
provision - provision a base image

This provisions the base VMs

options:

 -h --help - Print usage
 -n --clustername - use a particular cluster by name
'
}

decom_usage () {
  horizontal_rule
  # Print usage
  echo '--
usage: kubash decom
decommission - decommission a cluster and destroy all VMs

This script automates the setup and maintenance of a kubernetes cluster
e.g.

kubash decommission

options:

 -h --help - Print usage
 -n --clustername - use a particular cluster by name
'
}

# Check if a command exists
check_cmd () {
  if ! test_cmd_loc="$(type -p "$1")" || [[ -z "$test_cmd_loc" ]]; then
    horizontal_rule
    echo "$1 was not found in your path!"
    echo "To proceed please install $1 to your path and try again!"
    exit 1
  fi
}

# Check if a file exists and is writable
check_file () {
  if [[ -w "$1" ]]; then
    horizontal_rule
    echo "$1 was not writable!"
    exit 1
  fi
}

check_cmd mktemp
TMP=$(mktemp -d --suffix='.kubash.tmp' 2>/dev/null || mktemp -d -t '.kubash.tmp')

chkdir () {
  if [[ ! -w "$1" ]] ; then
    sudo mkdir -p $1
    sudo chown $USER $1
  fi
  if [[ ! -w "$1" ]] ; then
    echo "Cannot write to $1, please check your permissions"
    exit 2
  fi
}

killtmp () {
  cd
  rm -Rf $TMP
}

trap killtmp EXIT
# these vars are used by the following functions
LINE_TO_ADD=''
TARGET_FILE_FOR_ADD=$HOME/.profile

check_if_line_exists()
{
  squawk 7 " Checking for '$LINE_TO_ADD'  in $TARGET_FILE_FOR_ADD"
  grep -qsFx "$LINE_TO_ADD" $TARGET_FILE_FOR_ADD
}

add_line_to()
{
  squawk 5 " Adding '$LINE_TO_ADD'  to $TARGET_FILE_FOR_ADD"
  TARGET_FILE=$TARGET_FILE_FOR_ADD
    [[ -w "$TARGET_FILE" ]] || TARGET_FILE=$TARGET_FILE_FOR_ADD
    printf "%s\n" "$LINE_TO_ADD" >> "$TARGET_FILE"
}

genmac () {
  # Generate a mac address
  hexchars="0123456789ABCDEF"
  : ${DEFAULT_MAC_ADDRESS_BLOCK:=52:54:00}

  if [[ ! -z "$1" ]]; then
    DEFAULT_MAC_ADDRESS_BLOCK=$1
  fi

  end=$( for i in {1..6} ; do echo -n ${hexchars:$(( $RANDOM % 16 )):1} ; done | sed -e 's/\(..\)/:\1/g' )

  echo "$DEFAULT_MAC_ADDRESS_BLOCK$end" >&3
}

rolero () {
  squawk 2 "rolero $@"
  node_name=$1
  NODE_ROLE=$2

  result=$(kubectl --kubeconfig=$KUBECONFIG label --overwrite node $node_name node-role.kubernetes.io/$NODE_ROLE=)
  squawk 4 "Result = $result"
}

hosts_csv_slurp () {
  squawk 19 "slurp hosts.csv"
  # Get rid of commented lines, and sort on the second and third mac address fields
  # This ensures hosts with more net interfaces are set after hosts with less interfaces
  kubash_hosts_csv_slurped="$(grep -v '^#' $KUBASH_HOSTS_CSV|sort -t , -k 18,18n  -k 15,15n)"
}

provision_csv_slurp () {
  squawk 19 "slurp provision.csv"
  # Get rid of commented lines, and sort on the second and third mac address fields
  # This ensures hosts with more net interfaces are set after hosts with less interfaces
  kubash_provision_csv_slurped="$(grep -v '^#' $KUBASH_PROVISION_CSV|sort -t , -k 18,18n  -k 15,15n)"
}

kvm-decommer () {
  squawk 5 "kvm-decommer-remote $@"
  REBASED_NODE=$1
  THRU_USER=$2
  THRU_HOST=$3
  THRU_PORT=$4
  NODE_PATH=$5
  qemunodeimg="$NODE_PATH/$KUBASH_CLUSTER_NAME-k8s-$REBASED_NODE.qcow2"

  command2run="virsh destroy $REBASED_NODE"
  squawk 8 "$command2run"
  sudo_command $THRU_PORT $THRU_USER $THRU_HOST "$command2run"
  command2run="virsh undefine $REBASED_NODE"
  squawk 8 "$command2run"
  sudo_command $THRU_PORT $THRU_USER $THRU_HOST "$command2run"
  command2run="rm $qemunodeimg"
  squawk 8 "$command2run"
  sudo_command $THRU_PORT $THRU_USER $THRU_HOST "$command2run"
}

remove_all_base_images_kvm () {
  # Now remove the cluster base images
  uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f8,9,10,11,12,13|sort|uniq)"
  squawk 8 "$uniq_hosts"
  copy_image_tmp_para=$(mktemp -d)
  while IFS="," read -r $uniq_hosts_list_columns
  do
    command2run="rm $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
    sudo_command $K8S_provisionerPort $K8S_provisionerUser $K8S_provisionerHost "$command2run"
  done <<< "$uniq_hosts"
}

decom_kvm () {
  squawk 1 "decom_kvm starting"
  provision_csv_slurp
  squawk 19 "slurpy -----> $(echo $kubash_provision_csv_slurped)"
  # Write all hosts to inventory for id
  # csv_columns="K8S_node K8S_role K8S_cpuCount K8S_Memory K8S_network1 K8S_mac1 K8S_ip1 K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt K8S_network2 K8S_mac2 K8S_ip2 K8S_network3 K8S_mac3 K8S_ip3"
  squawk 15 "decom_kvm loop starting"
  while IFS="," read -r $csv_columns
  do
    squawk 19 "Loop $K8S_node $K8S_user $K8S_ip1 $K8S_provisionerPort $K8S_role $K8S_provisionerUser $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort"
    set +e
    kvm-decommer $K8S_node $K8S_provisionerUser $K8S_provisionerHost $K8S_provisionerPort $K8S_provisionerBasePath 
    set -e
  done <<< "$kubash_provision_csv_slurped"
  squawk 16 'Looped through all hosts to be decommissioned'
  remove_all_base_images_kvm
}

vbox-provisioner () {
  squawk 1 "vbox-provisioner $@"

  K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_network1=$5
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}

  squawk 7 "K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_network1=$5
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}
  "

  echo 'Vbox provisioner not implemented yet'
  exit 1
}


qemu-provisioner () {
  squawk 1 "qemu-provisioner $@"

  K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_network1=$5
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}
  if [[ "$K8S_mac1" == 'null' ]]; then
    K8S_mac1=$(VERBOSITY=0 kubash --verbosity=1 genmac)
  fi
  if [[ "$K8S_network2" != 'null' ]]; then
    if [[ "$K8S_mac2" == 'null' ]]; then
      K8S_mac2=$(VERBOSITY=0 kubash --verbosity=1 genmac)
    fi
    SECOND_NIC="--network=$K8S_network2,mac=$K8S_mac2,model=virtio"
  fi
  if [[ "$K8S_network3" != 'null' ]]; then
    if [[ "$K8S_mac3" == 'null' ]]; then
      K8S_mac3=$(VERBOSITY=0 kubash --verbosity=1 genmac)
    fi
    THIRD_NIC="--network=$K8S_network3,mac=$K8S_mac3,model=virtio"
  fi

  squawk 7 "K8S_node=$1
  K8S_role=$2
  K8S_cpuCount=$3
  K8S_Memory=$4
  K8S_network1=$5
  K8S_mac1=$6
  K8S_ip1=$7
  K8S_provisionerHost=$8
  K8S_provisionerUser=$9
  K8S_provisionerPort=${10}
  K8S_provisionerBasePath=${11}
  K8S_os=${12}
  K8S_virt=${13}
  K8S_network2=${14}
  K8S_mac2=${15}
  K8S_ip2=${16}
  K8S_network3=${17}
  K8S_mac3=${18}
  K8S_ip3=${19}
  "

  # Create VM for node
  qemunodeimg="$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$K8S_node.qcow2"
  qemucmd2run="$PSEUDO qemu-img create -f qcow2 -b $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG $qemunodeimg"

  if [[ "$K8S_os" == "coreos" ]]; then
    squawk 5 Keyer
    KEYTMP=$(mktemp -d)
    touch $KEYTMP/keys
    if [ ! -z  "$KEYS_URL" ]; then
      curl --silent -L "$KEYS_URL"  >> $KEYTMP/keys 
    else
      echo 'no KEYS_URL given'
    fi
    if [ ! -z  "$KEYS_TO_ADD" ]; then
      echo "$KEYS_TO_ADD" >>  $KEYTMP/keys
    else
      echo 'no KEYS_TO_ADD given'
    fi
    squawk 18 "Keys $(cat $KEYTMP/keys)"
    echo '    ssh_authorized_keys:'>  $KEYTMP/keys.json
    cat  $KEYTMP/keys|sed 's/^/    - /' >> $KEYTMP/keys.json
    SSH_AUTHORIZED_KEYS=$(cat $KEYTMP/keys.json)
    squawk 19 "Keys.json $SSH_AUTHORIZED_KEYS"
    rm -Rf $KEYTMP
    chkdir $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node
    if [[ "$K8S_ip2" == 'null' && "$K8S_ip2" == 'null' ]]; then
      SSH_AUTHORIZED_KEYS=$SSH_AUTHORIZED_KEYS \
      K8S_provisionerUser=$K8S_provisionerUser \
      K8S_node=$K8S_node \
      envsubst < $KUBASH_DIR/templates/user_data \
      > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data
    elif [[ "$K8S_ip2" -ne 'null' && "$K8S_ip3" == 'null' ]]; then
      K8S_mac2=$K8S_mac2 \
      K8S_ip2=$K8S_ip2 \
      SSH_AUTHORIZED_KEYS=$SSH_AUTHORIZED_KEYS \
      K8S_provisionerUser=$K8S_provisionerUser \
      K8S_node=$K8S_node \
      envsubst < $KUBASH_DIR/templates/user_data_two_interface \
      > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data
    else
      K8S_mac2=$K8S_mac2 \
      K8S_ip2=$K8S_ip2 \
      K8S_network3=$K8S_network3 \
      K8S_mac3=$K8S_mac3 \
      K8S_ip3=$K8S_ip3 \
      SSH_AUTHORIZED_KEYS=$SSH_AUTHORIZED_KEYS \
      K8S_provisionerUser=$K8S_provisionerUser \
      K8S_node=$K8S_node \
      envsubst < $KUBASH_DIR/templates/user_data_three_interface \
      > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data
    fi
    ct < $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data \
       > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/user_data.ign

    virshcmd2run="$PSEUDO virt-install --connect qemu:///system \
  --import \
    --autostart \
    --name $K8S_node \
    --ram $K8S_Memory \
    --vcpus $K8S_cpuCount \
    --os-type=linux \
    --noautoconsole \
    --accelerate \
    --hvm \
    --os-variant=virtio26 \
    --disk path=$qemunodeimg,format=qcow2,bus=virtio \
    --network=$K8S_network1,mac=$K8S_mac1,model=virtio \
    $SECOND_NIC \
    $THIRD_NIC \
  --print-xml
  " >&3 2>&3
  else
    virshcmd2run="$PSEUDO virt-install --connect qemu:///system \
  --import \
    --autostart \
    --name $K8S_node \
    --ram $K8S_Memory \
    --vcpus $K8S_cpuCount \
    --os-type=linux \
    --noautoconsole \
    --accelerate \
    --hvm \
    --os-variant=virtio26 \
    --disk path=$qemunodeimg,format=qcow2,bus=virtio \
    --network=$K8S_network1,mac=$K8S_mac1,model=virtio \
    $SECOND_NIC \
    $THIRD_NIC"
  fi

  if [[ "$K8S_provisionerHost" = "localhost" ]]; then
    squawk 5 "$qemucmd2run"
    $qemucmd2run
    if [[ "$K8S_os" == "coreos" ]]; then
      squawk 5 "create domain.xml $virshcmd2run"
      $virshcmd2run > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i 's|type=\"kvm\"|type=\"kvm\" xmlns:qemu=\"http://libvirt.org/schemas/domain/qemu/1.0\"|' $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i "/<\/devices>/a <qemu:commandline>\n  <qemu:arg value='-fw_cfg'/>\n  <qemu:arg value='name=opt/com.coreos/config,file=$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME/$K8S_node/user_data.ign'/>\n</qemu:commandline>" $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      $PSEUDO virsh define $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      $PSEUDO virsh start $K8S_node
    else
      squawk 5 "$PSEUDO $virshcmd2run"
      $PSEUDO $virshcmd2run
    fi
  else
    squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $qemucmd2run"
    ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$qemucmd2run"

    if [[ "$K8S_os" == "coreos" ]]; then
      squawk 5 "create the domain.xml"
      squawk 1 "touch $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml"
      touch $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run" > $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i 's|type=\"kvm\"|type=\"kvm\" xmlns:qemu=\"http://libvirt.org/schemas/domain/qemu/1.0\"|' $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml
      sed -i "/<\/devices>/a <qemu:commandline>\n  <qemu:arg value='-fw_cfg'/>\n  <qemu:arg value='name=opt/com.coreos/config,file=$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME/$K8S_node/user_data.ign'/>\n</qemu:commandline>" $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml

      squawk 5 "sync the cluster directory"
      squawk 9 "rsync $KUBASH_RSYNC_OPTS 'ssh -p$K8S_provisionerPort' $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME $K8S_provisionerUser@$K8S_provisionerHost:~/"
      rsync $KUBASH_RSYNC_OPTS "ssh -p$K8S_provisionerPort" $KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME $K8S_provisionerUser@$K8S_provisionerHost:$K8S_provisionerBasePath/

      virshcmd2run="$PSEUDO virsh define $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME/$K8S_node/domain.xml"
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $virshcmd2run"
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run"

      virshcmd2run="$PSEUDO virsh start $K8S_node"
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $virshcmd2run"
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run"
    else
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost $virshcmd2run"
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$virshcmd2run"
    fi
  fi
}

provisioner () {
  squawk 1 " provisioner"
  slurpy="$(grep -v '^#' $KUBASH_PROVISION_CSV)"
  squawk 8 "$slurpy"
  apparmor_fixed='false'
  if [[ -e "$KUBASH_HOSTS_CSV" ]]; then
    horizontal_rule
    rm $KUBASH_HOSTS_CSV
  fi
  touch $KUBASH_HOSTS_CSV
  while IFS="," read -r $csv_columns
  do
      if [[ "$apparmor_fixed" == 'false' && "$K8S_os" == "coreos" ]]; then
        #apparmor_fix_all_provisioning_hosts
        apparmor_fixed='true'
      fi
      if [[ "$K8S_virt" = "qemu" ]]; then
        squawk 9 "qemu-provisioner $K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3"
        qemu-provisioner $K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3
      elif [[ "$K8S_virt" = "vbox" ]]; then
        vbox-provisioner $K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3
      else
  echo "virtualization technology '$K8S_virt' not recognized"
      fi
      squawk 4 "provisioned"
  done <<< "$slurpy"
}

refresh_network_addresses () {
  squawk 1 " provisioner"
  slurpy="$(grep -v '^#' $KUBASH_PROVISION_CSV)"
  squawk 8 "$slurpy"
  rm $KUBASH_HOSTS_CSV
  touch $KUBASH_HOSTS_CSV
  while IFS="," read -r $csv_columns
  do
      net_type=$(echo $K8S_network1|cut -f1 -d=)
      if [[ "$net_type" == "network" ]]; then
        K8S_networkDiscovery=virsh
      else
        K8S_networkDiscovery=arp
      fi
      if [[ "$K8S_networkDiscovery" == "virsh" ]]; then
        if [[ "$K8S_provisionerHost" == "localhost" ]]; then
          countzero=0
          while [[ -z "$this_node_ip" ]]; do
            squawk 7 "checking for IP address"
            squawk 8 "$PSEUDO virsh domifaddr $K8S_node --full"
            this_node_ip=$($PSEUDO virsh domifaddr $K8S_node --full|grep ipv4|head -n1|awk '{print $4}'|cut -f1 -d/ 2>/dev/null)
            if [[ "$countzero" -gt 2 ]]; then
              sleep 2
              fi
            ((++countzero))
          done
        else
          countzero=0
          this_node_ip=''
          while [[ "$this_node_ip" == '' ]]; do
            squawk 7 "checking for IP address"
            squawk 8 "$PSEUDO virsh domifaddr $K8S_node --full"
            this_node_ip=$(ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost "$PSEUDO virsh domifaddr $K8S_node --full"|grep ipv4|tail -n1|awk '{print $4}'|cut -f1 -d/ 2>/dev/null)
            if [[ "$countzero" -gt 2 ]]; then
              sleep 2
            fi
            ((++countzero))
          done
        fi
      elif [[ "$K8S_networkDiscovery" == "arp" ]]; then
        countzero=0
        this_node_ip=$($PSEUDO arp -n|grep $K8S_mac1|awk '{print $1}'|tail -n 1)
        while [[ -z "$this_node_ip" ]]; do
        squawk 2 "sudo nmap -p 22 $BROADCAST_TO_NETWORK"
        NMAP_OUTPUT=$($PSEUDO nmap -p 22 $BROADCAST_TO_NETWORK)
        squawk 1 "arp -n|grep $K8S_mac1|awk '{print \$1}'"
        this_node_ip=$($PSEUDO arp -n|grep $K8S_mac1|awk '{print $1}'|tail -n 1)
        if [[ "$countzero" -gt 2 ]]; then
          sleep 8
        fi
        sleep 2
        ((++countzero))
        done
      fi
      squawk 5 "adding to $KUBASH_HOSTS_CSV"
      if [[ "$K8S_os" == 'coreos' ]]; then
        this_K8S_user=$K8S_provisionerUser
      else
        this_K8S_user=$K8S_user
      fi
      squawk 9 "preview $K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_network1,$K8S_mac1,$this_node_ip,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_network3,$K8S_mac3,$K8S_ip3"
      countzero=0
      set +e
      this_ssh_status=254
      until [[ "$this_ssh_status" == '0' ]]
      do
        if [[ "$countzero" -gt 25 ]]; then
          echo "$K8S_node host not coming up investigate $this_node_ip"
          exit 1
        elif [[ "$countzero" -gt 2 ]]; then
          sleep 3
        fi
        squawk 19 "checking ssh $this_node_ip $countzero"
        ssh -o "UserKnownHostsFile /dev/null" -o "StrictHostKeyChecking no" -n -q $this_K8S_user@$this_node_ip exit
        this_ssh_status=$?
        ((++countzero))
      done
      set -e
      squawk 6 "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_network1,$K8S_mac1,$this_node_ip,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_network3,$K8S_mac3,$K8S_ip3"
      echo "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_network1,$K8S_mac1,$this_node_ip,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_network3,$K8S_mac3,$K8S_ip3" >> $KUBASH_HOSTS_CSV
      this_node_ip=''
  done <<< "$slurpy"
  squawk 19 'network addresses refreshed'
}

copy_image_to_all_provisioning_hosts () {
  squawk 0 "copy_image_to_all_provisioning_hosts"

  uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f8,9,10,11,12,13|sort|uniq)"
  squawk 8 "$uniq_hosts"
  copy_image_tmp_para=$(mktemp -d)
  touch $copy_image_tmp_para/hopper
  while IFS="," read -r $uniq_hosts_list_columns
  do
    squawk 9 " $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt"
    if [[ "$KVM_builderHost" == 'localhost' ]]; then
      if [[ "$K8S_provisionerHost" == 'localhost' ]]; then
        copyimagecommand2run="$PSEUDO cp -al $KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      else
        copyimagecommand2run="rsync $KUBASH_RSYNC_OPTS \"ssh -p $K8S_provisionerPort\" $KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerUser@$K8S_provisionerHost:$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      fi
    else
      if [[ "$K8S_provisionerHost" == "$KVM_builderHost" ]]; then
        copyimagecommand2run="$PSEUDO cp -al $KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      else
        copyimagecommand2run="rsync $KUBASH_RSYNC_OPTS \"ssh -p $K8S_provisionerPort\" $K8S_builderUser@$K8S_builderHost:$KVM_builderBasePath/$K8S_os-$KVM_BASE_IMG $K8S_provisionerUser@$K8S_provisionerHost:$K8S_provisionerBasePath/$KUBASH_CLUSTER_NAME-k8s-$KVM_BASE_IMG"
        squawk 7 "$copyimagecommand2run"
        echo  "$copyimagecommand2run" >> $copy_image_tmp_para/hopper
      fi
    fi
  done <<< "$uniq_hosts"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_image_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_image_tmp_para/hopper
  else
    bash $copy_image_tmp_para/hopper
  fi
  rm -Rf $copy_image_tmp_para
}

apparmor_fix_all_provisioning_hosts () {
  squawk 0 "apparmor_fix_all_provisioning_hosts"
  uniq_hosts="$(grep -v '^#' $KUBASH_PROVISION_CSV|cut -d, -f7,8,9,10,11,12|sort|uniq)"
  squawk 8 "$uniq_hosts"
  apparmor_tmp_para=$(mktemp -d)
  touch $apparmor_tmp_para/hopper
  #CURLY="bash $(curl -Ls https://raw.githubusercontent.com/kubash/kubash/master/scripts/libvirtarmor)"
  CURLY="curl -Ls https://raw.githubusercontent.com/kubash/kubash/master/scripts/libvirtarmor|bash"
  #"K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt"
  while IFS="," read -r $uniq_hosts_list_columns
  do
    if [[ "$K8S_provisionerHost" = 'localhost' ]]; then
      echo "$CURLY" >> $apparmor_tmp_para/hopper
    else
      squawk 9 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost \"$CURLY\""
      echo "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_provisionerHost \"$CURLY\"" \
        >> $apparmor_tmp_para/hopper
    fi
  done <<< "$uniq_hosts"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $apparmor_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $apparmor_tmp_para/hopper
  else
    bash $apparmor_tmp_para/hopper
  fi
  rm -Rf $apparmor_tmp_para
}

do_nginx_ingress () {
  INGRESS_NAME=$1
  KUBECONFIG=$KUBECONFIG helm install stable/nginx-ingress --name $INGRESS_NAME --set rbac.create=true
}

demo () {
   cd $KUBASH_DIR/submodules/openebs/k8s/demo/crunchy-postgres
   KUBECONFIG=$KUBECONFIG bash run.sh
   cd $KUBASH_DIR/submodules/openebs/k8s/demo/rabbitmq
   KUBECONFIG=$KUBECONFIG bash run.sh
   cd $KUBASH_DIR/submodules/openebs/k8s/demo/percona
   kubectl --kubeconfig=$KUBECONFIG apply -f \
     demo-percona-mysql-pvc.yaml
   cd $KUBASH_DIR/submodules/openebs/k8s/demo/jupyter
   kubectl --kubeconfig=$KUBECONFIG apply -f \
     demo-jupyter-openebs.yaml
   cd $KUBASH_DIR/submodules/openebs/k8s/demo/mongodb
   kubectl --kubeconfig=$KUBECONFIG apply -f \
     mongo-statefulset.yml
   cd $KUBASH_DIR/submodules/openebs/k8s/demo/jenkins
   kubectl --kubeconfig=$KUBECONFIG apply -f \
     jenkins.yml
}

do_net () {
  squawk 0 " do_net"
  slurpy="$(grep -v '^#' $KUBASH_PROVISION_CSV)"
  if [[ $K8S_NET == "calico" ]]; then
    kubectl --kubeconfig=$KUBECONFIG apply -f $CALICO_URL
  elif [[ $K8S_NET == "flannel" ]]; then
    kubectl --kubeconfig=$KUBECONFIG apply -f $FLANNEL_URL
  elif [[ $K8S_NET == "weavenet" ]]; then
    VERSION="$(kubectl version | base64 | tr -d '\n')"
    kubectl --kubeconfig=$KUBECONFIG apply -f "https://cloud.weave.works/k8s/net?k8s-version=${VERSION}"
  fi
}

do_tiller () {
  w8_kubedns
  squawk 1 " do_tiller"
  kubectl --kubeconfig=$KUBECONFIG create serviceaccount tiller --namespace kube-system
  kubectl --kubeconfig=$KUBECONFIG create -f $KUBASH_DIR/tiller/rbac-tiller-config.yaml
  KUBECONFIG=$KUBECONFIG helm init --service-account tiller
}

write_ansible_hosts () {
  write_ansible_kubespray_hosts
}

write_ansible_kubeadm2ha_hosts () {
  squawk 1 " Make a hosts file for kubeadm2ha ansible"
  # Make a fresh hosts file
  slurpy="$(grep -v '^#' $KUBASH_HOSTS_CSV)"
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    horizontal_rule
    rm $KUBASH_ANSIBLE_HOSTS
    touch $KUBASH_ANSIBLE_HOSTS
  else
    touch $KUBASH_ANSIBLE_HOSTS
  fi
  # Write all hosts to inventory for id
  while IFS="," read -r $csv_columns
  do
    echo "$K8S_node ansible_ssh_host=$K8S_ip1 ansible_ssh_port=$K8S_provisionerPort ansible_user=$K8S_provisionerUser" >> $KUBASH_ANSIBLE_HOSTS
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[primary-master]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"
  echo '' >> $KUBASH_ANSIBLE_HOSTS
  echo '[secondary-masters]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"
  echo '' >> $KUBASH_ANSIBLE_HOSTS
  echo '[masters]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[etcd]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "etcd" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
      if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
        echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
      fi
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[minions]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[nodes]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[nginx]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "ingress" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[nfs-server]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "nfs-server" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  cat $KUBASH_DIR/templates/my-cluster.inventory.tail >> $KUBASH_ANSIBLE_HOSTS
}

write_ansible_openshift_hosts () {
  squawk 1 " Make a hosts file for openshift ansible"
  # Make a fresh hosts file
  slurpy="$(grep -v '^#' $KUBASH_HOSTS_CSV)"
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    horizontal_rule
    rm $KUBASH_ANSIBLE_HOSTS
    touch $KUBASH_ANSIBLE_HOSTS
  else
    touch $KUBASH_ANSIBLE_HOSTS
  fi
  # Write all hosts to inventory for id
  while IFS="," read -r $csv_columns
  do
    echo "$K8S_node ansible_ssh_host=$K8S_ip1 ansible_ssh_port=$K8S_provisionerPort ansible_user=$K8S_provisionerUser" >> $KUBASH_ANSIBLE_HOSTS
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS
  echo '[OSEv3:children]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'masters' >> $KUBASH_ANSIBLE_HOSTS
  echo 'nodes' >> $KUBASH_ANSIBLE_HOSTS
  echo 'etcd' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[OSEv3:vars]
openshift_deployment_type=origin
deployment_type=origin
openshift_release=v3.7
openshift_release=v3.7
openshift_pkg_version=-3.7.0
debug_level=2
openshift_disable_check=disk_availability,memory_availability,docker_storage,docker_image_availability
openshift_master_default_subdomain=apps.cbqa.in
osm_default_node_selector="region=lab"' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[masters]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[etcd]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "etcd" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
      if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
        echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
      fi
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  openshift_labels="openshift_node_labels=\"{'region': '$OPENSHIFT_REGION', 'zone': '$OPENSHIFT_ZONE'}\" openshift_schedulable=true"
  echo '[nodes]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node $openshift_labels" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[ingress]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "ingress" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS
}

write_ansible_kubespray_hosts () {
  squawk 1 " Make a hosts file for ansible"
  # Make a fresh hosts file
  slurpy="$(grep -v '^#' $KUBASH_HOSTS_CSV)"
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    horizontal_rule
    rm $KUBASH_ANSIBLE_HOSTS
    touch $KUBASH_ANSIBLE_HOSTS
  else
    touch $KUBASH_ANSIBLE_HOSTS
  fi
  # Write all hosts to inventory for id
  while IFS="," read -r $csv_columns
  do
    echo "$K8S_node ansible_ssh_host=$K8S_ip1 ansible_ssh_port=$K8S_provisionerPort ansible_user=$K8S_provisionerUser" >> $KUBASH_ANSIBLE_HOSTS
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[kube-node]' >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[kube-node:vars]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'ansible_ssh_extra_args="-o StrictHostKeyChecking=no"' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[kube-master]' >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[kube-master:vars]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'ansible_ssh_extra_args="-o StrictHostKeyChecking=no"' >> $KUBASH_ANSIBLE_HOSTS

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[etcd]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "etcd" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    elif [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
        echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
      fi
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[ingress]'  >> $KUBASH_ANSIBLE_HOSTS
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" = "ingress" ]]; then
      echo "$K8S_node" >> $KUBASH_ANSIBLE_HOSTS
    fi
  done <<< "$slurpy"

  echo '' >> $KUBASH_ANSIBLE_HOSTS

  echo '[k8s-cluster:children]' >> $KUBASH_ANSIBLE_HOSTS
  echo 'kube-node' >> $KUBASH_ANSIBLE_HOSTS
  echo 'kube-master' >> $KUBASH_ANSIBLE_HOSTS
}

removestalekeys () {
  squawk 1 " removestalekeys $@"
  node_ip=$1
  ssh-keygen -f "$HOME/.ssh/known_hosts" -R "$node_ip"
}

w8_kubedns () {
  squawk 0 "wait on Kube-DNS to become available" -n
  sleep 1

  # while loop
  kubedns_countone=1
  # timeout for 15 minutes
  while [[ $kubedns_countone -lt 151 ]]
  do
    squawk 0 '.' -n
    RESULT=$(kubectl --kubeconfig=$KUBECONFIG get po --namespace kube-system |grep kube-dns|grep Running)
    if [[ "$RESULT" ]]; then
        sleep 3
        squawk 0 '.'
        squawk 0 "$RESULT"
        break
    fi
    ((++kubedns_countone))
    sleep 3
  done

  echo "Kube-DNS is now up and running"
  sleep 1
}

w8_kubectl () {
  squawk 0 "Wait on the K8S cluster to become available" -n
  squawk 0 "Errors on the first few tries are normal give it a few minutes to spin up" -n
  sleep 15
  # while loop
  countone_w8_kubectl=1
  countlimit_w8_kubectl=151
  # timeout for 15 minutes
  while [[ "$countone_w8_kubectl" -lt "$countlimit_w8_kubectl" ]]; do
    squawk 0 '.' -n
    if [[ "$VERBOSITY" -gt "11" ]] ; then
      kubectl --kubeconfig=$KUBECONFIG get pods -n kube-system | grep kube-apiserver
    fi
    result=$(kubectl --kubeconfig=$KUBECONFIG get pods -n kube-system 2>/dev/null | grep kube-apiserver |grep Running)
    squawk 3 "Result is $result"
    if [[ "$result" ]]; then
      squawk 5 "Result nailed $result"
      ((++countone_w8_kubectl))
      break
    fi
    ((++countone_w8_kubectl))
    squawk 9 "$countone_w8_kubectl"
    if [[ "$countone_w8_kubectl" -ge "$countlimit_w8_kubectl"  ]]; then
      echo 'Master is not coming up, investigate, breaking'
      exit 1
    fi
    sleep 5
  done
  squawk 0  "."
  squawk 1 "kubectl commands are now able to interact with the kubernetes cluster"
}

w8_node () {
  node_name=$1
  squawk 0 "Wait on the K8S node $node_name to become available" -n
  sleep 5
  # while loop
  countone_w8_node=1
  countlimit_w8_node=151
  # timeout for 15 minutes
  set +e
  while [[ "$countone_w8_node" -lt "$countlimit_w8_node" ]]; do
    squawk 0 '.' -n
    if [[ "$VERBOSITY" -gt "11" ]] ; then
      kubectl --kubeconfig=$KUBECONFIG get node $node_name
    fi
    result=$(kubectl --kubeconfig=$KUBECONFIG get node $node_name | grep -v NotReady | grep Ready)
    squawk 3 "Result is $result"
    if [[ "$result" ]]; then
      squawk 5 "Result nailed $result"
      ((++countone_w8_node))
      break
    fi
    ((++countone_w8_node))
    squawk 9 "$countone_w8_node"
    sleep 3
  done
  set -e
  squawk 0  "."
  squawk 0  "kubectl commands are now able to interact with the kubernetes node"
}

remove_vagrant_user () {
  remove_vagrant_user_tmp_para=$(mktemp -d)
  squawk 2 ' Remove vagrant user from all hosts using ssh'
  touch $remove_vagrant_user_tmp_para/hopper
  while IFS="," read -r $csv_columns
  do
    squawk 1 "$K8S_ip1"
    squawk 3 "$K8S_user"
    squawk 3 "$K8S_os"
    if [[ "$K8S_os" == 'coreos' ]]; then
      squawk 9 'coreos so skipping'
    else
      REMMY="userdel -f vagrant && rm -Rf /home/vagrant"
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_user@$K8S_ip1 \"$REMMY\""
      echo "ssh -n -p $K8S_provisionerPort $K8S_user@$K8S_ip1 \"$REMMY\""\
        >> $remove_vagrant_user_tmp_para/hopper
    fi
  done < $KUBASH_HOSTS_CSV

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $remove_vagrant_user_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $remove_vagrant_user_tmp_para/hopper
  else
    bash $remove_vagrant_user_tmp_para/hopper
  fi
  rm -Rf $remove_vagrant_user_tmp_para
}

hostname_in_parallel () {
  hostname_tmp_para=$(mktemp -d --suffix='.para.tmp')
  squawk 2 ' Hostnaming all hosts using ssh'
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do
    my_HOST=$K8S_node
    my_IP=$K8S_ip1
    my_PORT=$K8S_provisionerPort
    my_USER=$K8S_provisionerUser
    command2run="ssh -n -p $my_PORT $my_USER@$my_IP '$PSEUDO hostname $my_HOST && echo $my_HOST | $PSEUDO tee /etc/hostname && echo \"127.0.1.1 $my_HOST.$my_DOMAIN $my_HOST  \" | $PSEUDO tee -a /etc/hosts'"
    squawk 5 "$command2run"
    echo "$command2run" \
      >> $hostname_tmp_para/hopper
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $hostname_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $hostname_tmp_para/hopper
  else
    bash $hostname_tmp_para/hopper
  fi
  rm -Rf $hostname_tmp_para
}

ping_in_parallel () {
  ping_tmp_para=$(mktemp -d --suffix='.para.tmp')
  squawk 2 ' Pinging all hosts using ssh'
  while IFS="," read -r $csv_columns
  do
    squawk 1 "$K8S_ip1"
    squawk 3 "$K8S_user"
    MY_ECHO="hostname; echo '$K8S_ip1 $K8S_provisionerUser pong'" 
    squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"$MY_ECHO\""
    echo "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"$MY_ECHO\""\
        >> $ping_tmp_para/hopper
  done < $KUBASH_HOSTS_CSV

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $ping_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $ping_tmp_para/hopper
  else
    bash $ping_tmp_para/hopper
  fi
  rm -Rf $ping_tmp_para
}

ping () {
  squawk 2 ' Pinging all hosts using ssh'
  while IFS="," read -r $csv_columns
  do
    squawk 1 "$K8S_ip1"
    squawk 3 "$K8S_user"
    if [[ "$VERBOSITY" -gt 10 ]]; then
      ssh -n -p $K8S_provisionerPort $K8S_user@$K8S_ip1 'echo pong'
      squawk 3 "$K8S_provisionerUser"
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 'echo pong'
    else
      ssh -n -p $K8S_provisionerPort $K8S_user@$K8S_ip1 'touch /tmp/sshpingtest-kubash'
      ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 'touch /tmp/sshpingtest-kubash'
    fi
  done < $KUBASH_HOSTS_CSV
}

ansible-ping () {
  squawk 1 ' Pinging all hosts using Ansible'
  ansible -i $KUBASH_ANSIBLE_HOSTS -m ping all
}

chkdir () {
  if [[ ! -w $1 ]] ; then
    sudo mkdir -p $1
    sudo chown $USER. $1
  fi
  if [[ ! -w $1 ]] ; then
    echo "Cannot write to $1, please check your permissions"
    exit 2
  fi
}

dotfiles_install () {
  squawk 1 ' Adjusting dotfiles'
  touch $HOME/.zshrc
  touch $HOME/.bashrc
  # make a bin dir in $HOME and add it to path
  chkdir $KUBASH_BIN
  LINE_TO_ADD="$(printf "export PATH=%s:\$PATH" $KUBASH_BIN)"
  TARGET_FILE_FOR_ADD=$HOME/.bashrc
  check_if_line_exists || add_line_to
  TARGET_FILE_FOR_ADD=$HOME/.zshrc
  check_if_line_exists || add_line_to

  LINE_TO_ADD="export GOPATH=$GOPATH"
  TARGET_FILE_FOR_ADD=$HOME/.bashrc
  check_if_line_exists || add_line_to
  TARGET_FILE_FOR_ADD=$HOME/.zshrc
  check_if_line_exists || add_line_to
}

do_grab () {
  squawk 1 " do_grab"
  do_grab_master_count=0
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master" ]]; then
      if [[ "$do_grab_master_count" -lt "1" ]]; then
        master_grab_kube_config $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_provisionerPort
      fi
      ((++do_grab_master_count))
    fi
  done < $KUBASH_HOSTS_CSV
}

check_coreos () {
  squawk 1 " check_coreos"
  do_coreos_init_count=0
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_os" == "coreos" ]]; then
      if [[ "$do_coreos_init_count" -lt "1" ]]; then
        do_coreos_initialization
  break
      fi
      ((++do_coreos_init_count))
    fi
  done < $KUBASH_HOSTS_CSV
}

master_join () {
  squawk 1 " master_join $@"
  my_node_name=$1
  my_node_ip=$2
  my_node_user=$3
  my_node_port=$4


  if [[ "$DO_MASTER_JOIN" == "true" ]] ; then
    finish_pki_for_masters $my_node_user $my_node_ip $my_node_name
    ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSUEDO hostname;$PSUEDO  uname -a"
    run_join=$(cat $KUBASH_DIR/join.sh)
    squawk 1 " run join $run_join"
    ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO $run_join"
    w8_node $my_node_name
    rolero $my_node_name master
  fi
}

master_init_join () {
  squawk 1 " master_init_join $@"
  my_master_name=$1
  my_master_ip=$2
  my_master_user=$3
  my_master_port=$4
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi

  finish_pki_for_masters $my_master_user $my_master_ip $my_master_name

  rm -f $KUBASH_CLUSTER_DIR/ingress.ip1
  rm -f $KUBASH_CLUSTER_DIR/ingress.ip2
  rm -f $KUBASH_CLUSTER_DIR/ingress.ip3
  rm -f $KUBASH_CLUSTER_DIR/primary_master.ip1
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "ingress" ]]; then
      echo "$K8S_ip1" >> $KUBASH_CLUSTER_DIR/ingress.ip1
      echo "$K8S_ip2" >> $KUBASH_CLUSTER_DIR/ingress.ip2
      echo "$K8S_ip3" >> $KUBASH_CLUSTER_DIR/ingress.ip3
    elif [[ "$K8S_role" == "primary_master" ]]; then
      echo "$K8S_ip1" >> $KUBASH_CLUSTER_DIR/primary_master.ip1
    fi
  done <<< "$kubash_hosts_csv_slurped"
  if [[ -e  "$KUBASH_CLUSTER_DIR/ingress.ip2" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/ingress.ip2)
  elif [[ -e  "$KUBASH_CLUSTER_DIR/ingress.ip3" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/ingress.ip3)
  elif [[ -e  "$KUBASH_CLUSTER_DIR/ingress.ip1" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/ingress.ip1)
  elif [[ -e  "$KUBASH_CLUSTER_DIR/primary_master.ip1" ]]; then
    K8S_load_balancer_ip=$(head -n1 $KUBASH_CLUSTER_DIR/primary_master.ip1)
  else
    echo 'no load balancer ip'
    exit 1
  fi

  if [[ "DO_KEEPALIVED" == 'true' ]]; then
    #keepalived
    setup_keepalived_tmp=$(mktemp -d)

    MASTER_VIP=$my_master_ip \
    envsubst < $KUBASH_DIR/templates/check_apiserver.sh \
    > $setup_keepalived_tmp/check_apiserver.sh
    copy_in_parallel_to_role master $setup_keepalived_tmp/check_apiserver.sh "/tmp/"
    command2run='sudo  mv /tmp/check_apiserver.sh /etc/keepalived/'
    do_command_in_parallel_on_role "master" "$command2run"

    MASTER_OR_BACKUP=BACKUP \
    PRIORITY=100 \
    INTERFACE_NET=$INTERFACE_NET \ 
    MASTER_VIP=$my_master_ip \
    envsubst < $KUBASH_DIR/templates/keepalived.conf
    > $setup_keepalived_tmp/keepalived.conf
    copy_in_parallel_to_role master $setup_keepalived_tmp/keepalived.conf "/tmp/"
    command2run='sudo  mv /tmp/keepalived.conf /etc/keepalived/'
    do_command_in_parallel_on_role "master" "$command2run"
    # Then let's overwrite that on our primary master
    MASTER_OR_BACKUP=MASTER \
    PRIORITY=101 \
    INTERFACE_NET=$INTERFACE_NET \ 
    MASTER_VIP=$my_master_ip \
    envsubst < $KUBASH_DIR/templates/keepalived.conf
    > $setup_keepalived_tmp/keepalived.conf
    rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $setup_keepalived_tmp/keepalived.conf $my_master_user@$my_master_ip:/tmp/keepalived.conf
    command2run='sudo  mv /tmp/keepalived.conf /etc/keepalived/'
    ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"

    rm -f $setup_keepalived_tmp/keepalived.conf $setup_keepalived_tmp/check_apiserver.sh
    rmdir $setup_keepalived_tmp
  fi

  squawk 0 " master_init_join $my_master_name $my_master_ip $my_master_user $my_master_port"
  if [[ "$DO_MASTER_JOIN" == "true" ]] ; then
    ssh -n -p $my_master_port $my_master_user@$my_master_ip "$PSEUDO hostname;$PSEUDO  uname -a"
    my_grep='kubeadm join --token'
    squawk 3 'master_init_join kubeadm init'
    if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
      kubeadmin_config_tmp=$(mktemp)
      KUBERNETES_VERSION=$KUBERNETES_VERSION \
      my_master_ip=$my_master_ip \
      load_balancer_ip=$K8S_load_balancer_ip \
      my_KUBE_CIDR=$my_KUBE_CIDR \
      ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/endpoints.line) \
      envsubst  < $KUBASH_DIR/templates/kubeadm-config.yaml \
        > $kubeadmin_config_tmp
      squawk 19 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $my_master_port' $kubeadmin_config_tmp  $my_master_user@$my_master_ip:/tmp/config.yaml"
      rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $kubeadmin_config_tmp  $my_master_user@$my_master_ip:/tmp/config.yaml
      squawk 6 "kubedmin_config_tmp =\n $(cat $kubeadmin_config_tmp)" -e
      rm $kubeadmin_config_tmp
      my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/tmp/config.yaml"
      squawk 5 "$my_KUBE_INIT"
      run_join=$(ssh -n $my_master_user@$my_master_ip "$my_KUBE_INIT" | tee $TMP/rawresults.k8s | grep -- "$my_grep")
      if [[ -z "$run_join" ]]; then
        horizontal_rule
        echo 'kubeadm init failed!'
        exit 1
      fi
      command2run='sudo  rm -f /tmp/config.yaml'
      ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"
    else
      my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --pod-network-cidr=$my_KUBE_CIDR"
      squawk 5 "$my_KUBE_INIT"
      run_join=$(ssh -n $my_master_user@$my_master_ip "$my_KUBE_INIT" | tee $TMP/rawresults.k8s | grep -- "$my_grep")
    fi
    squawk 9 "$(cat $TMP/rawresults.k8s)"
    echo $run_join > $KUBASH_DIR/join.sh
    if [[ "$KUBASH_OIDC_AUTH" == 'true' ]]; then
      command2run='sudo sed -i "/- kube-apiserver/a\    - --oidc-issuer-url=https://accounts.google.com\n    - --oidc-username-claim=email\n    - --oidc-client-id=" /etc/kubernetes/manifests/kube-apiserver.yaml'
      ssh -n -p $my_master_port $my_master_user@$my_master_ip "$command2run"
    fi
    master_grab_kube_config $my_master_name $my_master_ip $my_master_user $my_master_port
    sudo_command $my_master_port $my_master_user $my_master_ip "$command2run"
    w8_kubectl
    rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $KUBASH_DIR/scripts/grabkubepki $my_master_user@$my_master_ip:/tmp/grabkubepki
    command2run="bash /tmp/grabkubepki"
    sudo_command $this_port $this_user $this_host "$command2run"
    rsync $KUBASH_RSYNC_OPTS "ssh -p $my_master_port" $my_master_user@$my_master_ip:/tmp/kube-pki.tgz $KUBASH_CLUSTER_DIR/
    squawk 5 'and copy it to master and etcd hosts'
    copy_in_parallel_to_role "master" "$KUBASH_CLUSTER_DIR/kube-pki.tgz" "/tmp/"
    command2run='cd /; tar zxf /tmp/kube-pki.tgz'
    do_command_in_parallel_on_role "master"        "$command2run"
    command2run='rm /tmp/kube-pki.tgz'
    do_command_in_parallel_on_role "master"        "$command2run"
    do_net
  fi
}

master_grab_kube_config () {
  my_master_name=$1
  my_master_ip=$2
  my_master_user=$3
  my_master_port=$4
  squawk 1 ' refresh-kube-config'
  squawk 3 " master_grab_kube_config $my_master_name $my_master_ip $my_master_user $my_master_port"
  squawk 5 "mkdir -p ~/.kube && sudo cp -av /etc/kubernetes/admin.conf ~/.kube/config && sudo chown -R $my_master_user. ~/.kube"
  ssh -n -p $my_master_port $my_master_user@$my_master_ip "mkdir -p ~/.kube && sudo cp -av /etc/kubernetes/admin.conf ~/.kube/config && sudo chown -R $my_master_user. ~/.kube"

  chkdir $HOME/.kube
  squawk 3 ' grab config'
  rm -f $KUBASH_CLUSTER_CONFIG
  ssh -n -p $my_master_port $my_master_user@$my_master_ip 'cat .kube/config' > $KUBASH_CLUSTER_CONFIG
  sed -i "s/^  name: kubernetes$/  name: $KUBASH_CLUSTER_NAME/" $KUBASH_CLUSTER_CONFIG
  sed -i "s/^    cluster: kubernetes$/    cluster: $KUBASH_CLUSTER_NAME/" $KUBASH_CLUSTER_CONFIG

  sudo chmod 600 $KUBASH_CLUSTER_CONFIG
  sudo chown -R $USER. $KUBASH_CLUSTER_CONFIG
}

node_join () {
  my_node_name=$1
  my_node_ip=$2
  my_node_user=$3
  my_node_port=$4
  squawk 1 " node_join $my_node_name $my_node_ip $my_node_user $my_node_port"
  if [[ "$DO_NODE_JOIN" == "true" ]] ; then
    result=$(ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO hostname;$PSEUDO uname -a")
    squawk 3 "hostname and uname is $result"
    squawk 3 "Kubeadmin join"
    run_join=$(cat $KUBASH_DIR/join.sh)
    #result=$(ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO $run_join --ignore-preflight-errors=IsPrivilegedUser")
    result=$(ssh -n -p $my_node_port $my_node_user@$my_node_ip "$PSEUDO $run_join --ignore-preflight-errors=IsPrivilegedUser")
    squawk 3 "run_join result is $result"
    w8_node $my_node_name
    rolero $my_node_name node
  fi
}

checks () {
  squawk 0 " checks"
  check_cmd git
  check_cmd nc
  check_cmd ssh
  check_cmd rsync
  check_cmd ansible
  check_cmd curl
  check_cmd nmap
  check_cmd uname
  check_cmd envsubst
  check_cmd ct
  check_cmd jinja2
  check_cmd yaml2json
  check_cmd jq
  check_cmd expr
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    check_cmd parallel
  fi
  check_cmd 'grep'
  check_cmd 'sed'
}


initialize () {
  squawk 1 " initialize"
  check_csv
  hosts_csv_slurp
  check_coreos
  process_hosts_csv
}

kubeadm2ha_initialize () {
  squawk 1 "kubeadm2ha initialize"
  check_csv
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    squawk 1 'Hosts file found, not overwriting'
  else
    write_ansible_kubeadm2ha_hosts
  fi
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/cluster-setup.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/cluster-dashboard.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/cluster-load-balanced.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/etcd-operator.yaml
  ansible-playbook \
    -f $PARALLEL_JOBS \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubeadm2ha/ansible/local-access.yaml
}

kubespray_initialize () {
  squawk 1 "kubespray initialize"
  check_csv
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    squawk 1 'Hosts file found, not overwriting'
  else
    write_ansible_kubespray_hosts
  fi
  ansible-playbook \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/kubespray/cluster.yml
}

openshift_initialize () {
  squawk 1 "openshift initialize"
  check_csv
  if [[ -e "$KUBASH_ANSIBLE_HOSTS" ]]; then
    squawk 1 'Hosts file found, not overwriting'
  else
    write_ansible_openshift_hosts
  fi
  ansible-playbook \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/openshift-ansible/playbooks/prerequisites.yml
  ansible-playbook \
    -i $KUBASH_ANSIBLE_HOSTS \
    $KUBASH_DIR/submodules/openshift-ansible/playbooks/deploy_cluster.yml
}

read_csv () {
  squawk 1 " read_csv"
  read_master_count=0

  while IFS="," read -r $csv_columns
  do
    squawk 5 "$K8S_node $K8S_user $K8S_ip1 $K8S_provisionerPort $K8S_role $K8S_provisionerUser $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort"
    if [[ "$K8S_role" == "master" ]]; then
      if [[ "$read_master_count" -lt "1" ]]; then
        echo "master_init_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_provisionerPort"
      else
        echo "master_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_provisionerPort"
      fi
      ((++read_master_count))
    fi
  done < $KUBASH_HOSTS_CSV

  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "node" || "$K8S_role" == "ingress" ]]; then
      echo "node_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_provisionerPort"
    fi
  done < $KUBASH_HOSTS_CSV
}

check_csv () {
  squawk 4 " check_csv"
  if [[ ! -e $KUBASH_HOSTS_CSV ]]; then
    horizontal_rule
    echo "$KUBASH_HOSTS_CSV file not found!"
    echo "You must provision a cluster first, and specify a valid cluster with the --clustername option and place your hosts.csv file in its directory!"
    exit 1
  fi
}

grant () {
  user_role=$3
  grant_tmp=$(mktemp)
  USERNAME_OF_ADMIN=$1 \
  EMAIL_ADDRESS_OF_ADMIN=$2 \
  envsubst < $KUBASH_DIR/templates/$user_role-role \
    > $grant_tmp
  kubectl --kubeconfig=$KUBECONFIG apply -f $grant_tmp
  rm $grant_tmp
}

grant_users () {
  grant_users_tmp_para=$(mktemp -d --suffix='.para.tmp' 2>/dev/null || mktemp -d -t '.para.tmp')
  touch $grant_users_tmp_para/hopper
  slurpy="$(grep -v '^#' $KUBASH_USERS_CSV)"
  # user_csv_columns="user_email user_role"
  while IFS="," read -r $user_csv_columns
  do
    squawk 9 "user_name=$user_name user_email=$user_email user_role=$user_role"
    echo "kubash -n $KUBASH_CLUSTER_NAME grant $user_name $user_email $user_role" >> $grant_users_tmp_para/hopper
  done <<< "$slurpy"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $grant_users_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $grant_users_tmp_para/hopper
  else
    bash $grant_users_tmp_para/hopper
  fi
  rm -Rf $grant_users_tmp_para
}

finish_pki_for_masters () {
  squawk 5 'finish_pki_for_masters'
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4
  command2run='mkdir -p /etc/kubernetes/pki/etcd'
  sudo_command $K8S_provisionerPort $this_user $this_host "$command2run"
  squawk 5 'cp the etcd pki files'
  command2run='cp /etc/etcd/pki/ca.pem /etc/etcd/pki/client.pem /etc/etcd/pki/client-key.pem /etc/kubernetes/pki/etcd/'
  sudo_command $K8S_provisionerPort $this_user $this_host "$command2run"
}

finish_etcd () {
  squawk 5 'finish_etcd'
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4

  command2run="cd /etc/etcd/pki; cfssl print-defaults csr > config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="sed -i '0,/CN/{s/example\.net/'$this_name'/}' /etc/etcd/pki/config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="sed -i 's/www\.example\.net/'$this_host'/' /etc/etcd/pki/config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="sed -i 's/example\.net/'$this_name'/' /etc/etcd/pki/config.json"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="cd /etc/etcd/pki; cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server config.json | cfssljson -bare server"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run="cd /etc/etcd/pki; cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer config.json | cfssljson -bare peer"
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='chown -R etcd:etcd /etc/etcd/pki'
  sudo_command $this_port $this_user $this_host "$command2run"

  if [[ -e $KUBASH_DIR/tmp/etcd-${ETCD_VERSION}-linux-amd64.tar.gz ]]; then
    squawk 9 'Etcd binary already downloaded'
  else
    cd $KUBASH_DIR/tmp
    wget -c https://github.com/coreos/etcd/releases/download/${ETCD_VERSION}/etcd-${ETCD_VERSION}-linux-amd64.tar.gz 
  fi
  command2run='id -u etcd &>/dev/null || useradd etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  etcd_extract_tmp=$(mktemp -d)
  sudo tar --strip-components=1 -C $etcd_extract_tmp -xzf $KUBASH_DIR/tmp/etcd-${ETCD_VERSION}-linux-amd64.tar.gz
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $etcd_extract_tmp/etcd $this_user@$this_host:/tmp/
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $etcd_extract_tmp/etcdctl $this_user@$this_host:/tmp/
  $PSEUDO rm -Rf $etcd_extract_tmp
  command2run='sudo mv /tmp/etcd /usr/local/bin/'
  do_command $this_port $this_user $this_host "$command2run"
  command2run='sudo mv /tmp/etcdctl /usr/local/bin/'
  do_command $this_port $this_user $this_host "$command2run"
  etctmp=$(mktemp)
  KUBASH_CLUSTER_NAME=$KUBASH_CLUSTER_NAME \
  PEER_NAME=$this_name \
  PRIVATE_IP=$this_host \
  ETCD_INITCLUSER_LINE="$(cat $KUBASH_CLUSTER_DIR/etcd.line)" \
  envsubst < $KUBASH_DIR/templates/etcd.conf.yml \
  > $etctmp
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $etctmp  $this_user@$this_host:/tmp/etcd.conf.yml
  command2run="mv /tmp/etcd.conf.yml /etc/etcd/etcd.conf.yml"
  sudo_command $this_port $this_user $this_host "$command2run"

  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $KUBASH_DIR/templates/etcd.service  $this_user@$this_host:/tmp/etcd.service
  command2run='cp /tmp/etcd.service /lib/systemd/system/etcd.service'
  sudo_command $this_port $this_user $this_host "$command2run"

  rm $etctmp
  command2run='mkdir -p /etc/etcd; chown -R etcd.etcd /etc/etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='mkdir -p /var/lib/etcd; chown -R etcd.etcd /var/lib/etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='systemctl daemon-reload'
  sudo_command $this_port $this_user $this_host "$command2run"
}

start_etcd () {

  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  # Run kubeadm init on master0
  start_etcd_tmp_para=$(mktemp -d --suffix='.para.tmp' 2>/dev/null)
  touch $start_etcd_tmp_para/hopper
  squawk 3 " do_etcd"

  countzero=0
  touch $start_etcd_tmp_para/endpoints.line
  echo 'etcd:' >> $start_etcd_tmp_para/endpoints.line
  echo '  endpoints:' > $start_etcd_tmp_para/endpoints.line
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "etcd" || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
      if [[ "$countzero" -lt "3" ]]; then
  command2run='systemctl start etcd'
  squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 'sudo bash -c \"$command2run\"'"
  echo "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 'sudo bash -c \"$command2run\"'" >> $start_etcd_tmp_para/hopper
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $start_etcd_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $start_etcd_tmp_para/hopper
  else
    bash $start_etcd_tmp_para/hopper
  fi
  rm -Rf $start_etcd_tmp_para
}

kubeadm_reset () {
  squawk 3 "Kubeadmin reset"
  command2run="PATH=$K8S_SU_PATH kubeadm reset"
  # hack if debugging to skip this step
  set +e
  do_command_in_parallel "$command2run"
  #set -e
}

prep_init_etcd () {
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4

  init_etcd_tmp=$(mktemp -d)
  mkdir $init_etcd_tmp/pki
  cp $KUBASH_DIR/templates/ca-config.json $init_etcd_tmp/pki/ca-config.json
  cp $KUBASH_DIR/templates/client.json $init_etcd_tmp/pki/client.json
  jinja2 $KUBASH_DIR/templates/ca-csr.json $KUBASH_CLUSTER_DIR/ca-data.yaml --format=yaml > $init_etcd_tmp/pki/ca-csr.json
  command2run='mkdir -p /etc/etcd'
  squawk 5 "command2run $command2run"
  sudo_command $this_port $this_user $this_host "$command2run"
  squawk 15 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $this_port' $init_etcd_tmp/pki $this_user@$this_host:/tmp/"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $init_etcd_tmp/pki $this_user@$this_host:/tmp/
  command2run='ls -lh /tmp/pki'
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='rm -Rf /etc/etcd/pki'
  sudo_command $this_port $this_user $this_host "$command2run"
  command2run='mv /tmp/pki /etc/etcd/pki'
  sudo_command $this_port $this_user $this_host "$command2run"
  rm -Rf $init_etcd_tmp

  command2run="chown $this_user /etc/etcd/pki"
  sudo_command $this_port $this_user $this_host "$command2run"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $KUBASH_DIR/templates/ca-config.json $this_user@$this_host:/tmp/ca-config.json
  command2run='mv /tmp/ca-config.json /etc/etcd/pki/ca-config.json'
  sudo_command $this_port $this_user $this_host "$command2run"

  # crictl
  if [[ "$DO_CRICTL" == 'true' ]]; then
    squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $this_port' '${KUBASH_BIN}/crictl' $this_user@$this_host:/tmp/crictl"
    rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" "${KUBASH_BIN}/crictl" $this_user@$this_host:/tmp/crictl
    copy_in_parallel_to_all "${KUBASH_BIN}/crictl" "/tmp/crictl"
    command2run='mv /tmp/crictl /usr/local/bin/crictl'
    do_command_in_parallel "$command2run"
  fi

  squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $this_port' '${KUBASH_BIN}/cfssl' $this_user@$this_host:/tmp/cfssl"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" "${KUBASH_BIN}/cfssl" $this_user@$this_host:/tmp/cfssl
  copy_in_parallel_to_role "master" "${KUBASH_BIN}/cfssl" "/tmp/cfssl"
  copy_in_parallel_to_role "etcd"   "${KUBASH_BIN}/cfssl" "/tmp/cfssl"
  command2run='mv /tmp/cfssl /usr/local/bin/cfssl'
  sudo_command $this_port $this_user $this_host "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
    do_command_in_parallel_on_role "master"        "$command2run"
  fi

  squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $this_port' ${KUBASH_BIN}/cfssljson $this_user@$this_host:/tmp/cfssljson"
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" "${KUBASH_BIN}/cfssljson" $this_user@$this_host:/tmp/cfssljson
  copy_in_parallel_to_role "master" "${KUBASH_BIN}/cfssljson" "/tmp/cfssljson"
  copy_in_parallel_to_role "etcd"   "${KUBASH_BIN}/cfssljson" "/tmp/cfssljson"
  command2run='mv /tmp/cfssljson /usr/local/bin/cfssljson'
  sudo_command $this_port $this_user $this_host "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
    do_command_in_parallel_on_role "master"        "$command2run"
  fi

  # Hack, delete after rebuild
  command2run="echo 'PATH=/usr/local/bin:$PATH' >> /root/.bash_profile"
  sudo_command $this_port $this_user $this_host "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
    do_command_in_parallel_on_role "master"        "$command2run"
  fi

  # add etcd user if it doesn't exist
  command2run='id -u etcd &>/dev/null || useradd etcd'
  sudo_command $this_port $this_user $this_host "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
    do_command_in_parallel_on_role "master"        "$command2run"
  fi

  command2run='cd /etc/etcd/pki; cfssl gencert -initca ca-csr.json | cfssljson -bare ca -'
  sudo_command $this_port $this_user $this_host "$command2run"

  command2run='cd /etc/etcd/pki; cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client'
  sudo_command $this_port $this_user $this_host "$command2run"

  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $KUBASH_DIR/scripts/grabpki $this_user@$this_host:/tmp/grabpki
  command2run="bash /tmp/grabpki"
  sudo_command $this_port $this_user $this_host "$command2run"
  squawk 5 'pull etcd-pki.tgz from primary master'
  rsync $KUBASH_RSYNC_OPTS "ssh -p $this_port" $this_user@$this_host:/tmp/etcd-pki.tgz $KUBASH_CLUSTER_DIR/
  squawk 5 'and copy it to master and etcd hosts'
  copy_in_parallel_to_role "etcd" "$KUBASH_CLUSTER_DIR/etcd-pki.tgz" "/tmp/"
  copy_in_parallel_to_role "master" "$KUBASH_CLUSTER_DIR/etcd-pki.tgz" "/tmp/"
  command2run='cd /; tar zxf /tmp/etcd-pki.tgz'
  do_command_in_parallel_on_role "master"        "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  command2run='rm /tmp/etcd-pki.tgz'
  do_command_in_parallel_on_role "master"        "$command2run"
  do_command_in_parallel_on_role "etcd"          "$command2run"
  finish_etcd $this_user $this_host $this_name $this_port
}

prep_etcd () {
  squawk 5 'prep_etcd'
  this_user=$1
  this_host=$2
  this_name=$3
  this_port=$4
  finish_etcd $this_user $this_host $this_name $this_port
}

do_etcd () {
  do_etcd_tmp_para=$(mktemp -d --suffix='.para.tmp' 2>/dev/null || mktemp -d -t '.para.tmp')
  touch $do_etcd_tmp_para/hopper
  squawk 3 " do_etcd"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi

  countzero=0
  touch $do_etcd_tmp_para/endpoints.line
  echo 'etcd:' >> $do_etcd_tmp_para/endpoints.line
  echo '  endpoints:' > $do_etcd_tmp_para/endpoints.line
  while IFS="," read -r $csv_columns
  do
    if [[ "$MASTERS_AS_ETCD" == "true" ]]; then
      if [[ "$K8S_role" == 'etcd' || "$K8S_role" == 'master' || "$K8S_role" == 'primary_master' ]]; then
    squawk 19 "$K8S_node=https://$K8S_ip1:2380  <-- $K8S_role"
    echo -n "$K8S_node=https://$K8S_ip1:2380" >> $do_etcd_tmp_para/etcd.line
    echo -n "," >> $do_etcd_tmp_para/etcd.line
  ((++countzero))
        echo "  - https://$K8S_ip1:2379" >> $do_etcd_tmp_para/endpoints.line
      fi
    else
      if [[ "$K8S_role" == 'etcd' ]]; then
    squawk 19 "$K8S_node=https://$K8S_ip1:2380  <-- $K8S_role"
    echo -n "$K8S_node=https://$K8S_ip1:2380" >> $do_etcd_tmp_para/etcd.line
    echo -n "," >> $do_etcd_tmp_para/etcd.line
  ((++countzero))
        echo "  - https://$K8S_ip1:2379" >> $do_etcd_tmp_para/endpoints.line
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"
  sed -i 's/,$//' $do_etcd_tmp_para/etcd.line
  echo '  caFile: /etc/kubernetes/pki/etcd/ca.pem' >> $do_etcd_tmp_para/endpoints.line
  echo '  certFile: /etc/kubernetes/pki/etcd/client.pem' >> $do_etcd_tmp_para/endpoints.line
  echo '  keyFile: /etc/kubernetes/pki/etcd/client-key.pem' >> $do_etcd_tmp_para/endpoints.line

  if [[ "$countzero" -lt "3" ]]; then
    horizontal_rule
    echo "not enough etcd nodes, [$countzero]"
    exit 1
  else
    if [[ "$((countzero%2))" -eq 0 ]]; then
      horizontal_rule
      echo "number of etcd nodes, [$countzero] is even which is not supported"
      exit 1
    fi
  fi

  # Only copy if etcd.line exists as the endpoints will have stuff in it regardless
  if [[ -e "$do_etcd_tmp_para/etcd.line" ]]; then
    mv $do_etcd_tmp_para/etcd.line $KUBASH_CLUSTER_DIR/
    mv $do_etcd_tmp_para/endpoints.line $KUBASH_CLUSTER_DIR/
  fi

  countzero=0
  prepTMP=$(mktemp -d)
  touch $prepTMP/hopper
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master"  ]]; then
      if [[ "$countzero" -eq "0" ]]; then
  ((++countzero))
        prep_init_etcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_provisionerPort
      else
        echo 'there should only be one primary'
        exit 1
      fi
    fi
    if [[ "$K8S_role" == "etcd" || "$K8S_role" == "master"  ]]; then
        squawk 19 "$K8S_node $K8S_role $K8S_cpuCount $K8S_Memory $K8S_network1 $K8S_mac1 $K8S_ip1 $K8S_provisionerHost $K8S_provisionerUser $K8S_provisionerPort $K8S_provisionerBasePath $K8S_os $K8S_virt $K8S_network2 $K8S_mac2 $K8S_ip2 $K8S_network3 $K8S_mac3 $K8S_ip3"
        squawk 3 "kubash -n $KUBASH_CLUSTER_NAME prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_provisionerPort"
        touch $prepTMP/hopper
        echo      "kubash -n $KUBASH_CLUSTER_NAME prepetcd $K8S_provisionerUser $K8S_ip1 $K8S_node $K8S_provisionerPort" >> $prepTMP/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $prepTMP/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $prepTMP/hopper
  else
    bash $prepTMP/hopper
  fi
  rm -Rf $prepTMP
}

do_primary_master () {
  squawk 3 " do_primary_master"
  do_master_count=0

  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "primary_master" ]]; then
      if [[ "$do_master_count" -lt "1" ]]; then
        master_init_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_provisionerPort
      else
  echo 'There should only be one init master! Skipping this master'
        echo "master_init_join $K8S_node $K8S_ip1 $K8S_provisionerUser $K8S_provisionerPort"
      fi
      ((++do_master_count))
    fi
  done <<< "$kubash_hosts_csv_slurped"
}

do_masters () {
  squawk 3 " do_masters"

  # hijack
  do_masters_in_parallel
}

do_scale_up_kube_dns () {
  squawk 3 "do_scale_up_kube_dns"
  do_scale_up_kube_dns=0

  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" || "$K8S_role" == "primary_master" ]]; then
    ((++do_scale_up_kube_dns))
    fi
  done <<< "$kubash_hosts_csv_slurped"

  kubectl scale --replicas=$do_scale_up_kube_dns -n kube-system  deployment/kube-dns
}

do_masters_in_parallel () {
  squawk 3 " do_masters_in_parallel"
  do_master_count=0

  #command2run='sudo  rm /etc/kubernetes/pki/apiserver.crt'
  #do_command_in_parallel_on_role "master" "$command2run"
  if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
    kubeadmin_config_tmp=$(mktemp)
    my_master_ip=$my_master_ip \
    KUBERNETES_VERSION=$KUBERNETES_VERSION \
    load_balancer_ip=$K8S_load_balancer_ip \
    my_KUBE_CIDR=$my_KUBE_CIDR \
    ENDPOINTS_LINES=$( cat $KUBASH_CLUSTER_DIR/endpoints.line) \
    envsubst  < $KUBASH_DIR/templates/kubeadm-config.yaml \
      > $kubeadmin_config_tmp
    squawk 5 "copy_in_parallel_to_role master '$kubeadmin_config_tmp' '/tmp/config.yaml'"
    copy_in_parallel_to_role master "$kubeadmin_config_tmp" "/tmp/config.yaml"
    rm $kubeadmin_config_tmp
  fi

  do_master_tmp=$(mktemp -d)
  touch $do_master_tmp/hopper
  touch $do_master_tmp/hopper2
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  #csv_columns="K8S_node K8S_role K8S_cpuCount K8S_Memory K8S_network1 K8S_mac1 K8S_ip1 K8S_provisionerHost K8S_provisionerUser K8S_provisionerPort K8S_provisionerBasePath K8S_os K8S_virt K8S_network2 K8S_mac2 K8S_ip2 K8S_network3 K8S_mac3 K8S_ip3"
  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_role" == "master" ]]; then
      if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
        my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --config=/tmp/config.yaml"
        squawk 5 "$my_KUBE_INIT"
        echo "ssh -n $K8S_provisionerUser@$K8S_ip1 '$my_KUBE_INIT'" >> $do_master_tmp/hopper
      else
        my_KUBE_INIT="PATH=$K8S_SU_PATH $PSEUDO kubeadm init $KUBEADMIN_IGNORE_PREFLIGHT_CHECKS --pod-network-cidr=$my_KUBE_CIDR"
        squawk 5 "$my_KUBE_INIT"
        echo "ssh -n $K8S_provisionerUser@$K8S_ip1 '$my_KUBE_INIT'" >> $do_master_tmp/hopper
      fi
    fi
  done <<< "$kubash_hosts_csv_slurped"
  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_master_tmp/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_master_tmp/hopper
  else
    bash $do_master_tmp/hopper
  fi
  rm -Rf $do_master_tmp
  if [[ -e "$KUBASH_CLUSTER_DIR/endpoints.line" ]]; then
    do_command_in_parallel_on_role "master" "rm -f /tmp/config.yaml"
  fi
  #do_scale_up_kube_dns
}

do_nodes () {
  do_nodes_in_parallel
}

do_nodes_in_parallel () {
  do_nodes_tmp_para=$(mktemp -d)
  touch $do_nodes_tmp_para/hopper
  squawk 3 " do_nodes_in_parallel"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  countzero_do_nodes=0
  while IFS="," read -r $csv_columns
  do 
    if [[ "$K8S_role" == "node" ]]; then
      echo "kubash -n $KUBASH_CLUSTER_NAME node_join --node-join-name $K8S_node --node-join-ip $K8S_ip1 --node-join-user $K8S_provisionerUser --node-join-port $K8S_provisionerPort --node-join-role node" \
        >> $do_nodes_tmp_para/hopper
    else
      squawk 1 " K8S_role NOT NODE"
      squawk 1 " K8S_role $K8S_role $K8S_ip1 $K8S_user $K8S_provisionerPort"
    fi
    ((++countzero_do_nodes))
    squawk 3 " count $countzero_do_nodes"
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_nodes_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_nodes_tmp_para/hopper
  else
    bash $do_nodes_tmp_para/hopper
  fi
  rm -Rf $do_nodes_tmp_para
}

do_command_in_parallel () {
  do_command_tmp_para=$(mktemp -d)
  command2run=$1
  touch $do_command_tmp_para/hopper
  squawk 3 " do_command_in_parallel $1"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    squawk 19 'slurp empty'
    hosts_csv_slurp
  else
    squawk 19 "host slurp $(echo $kubash_hosts_csv_slurped)"
  fi
  countzero_do_nodes=0
  squawk 20 'Start while loop'
  while IFS="," read -r $csv_columns
  do
    ((++countzero_do_nodes))
    squawk 19 " count $countzero_do_nodes"
    squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"sudo bash -c '$command2run'\""
    echo "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"sudo bash -c '$command2run'\""\
        >> $do_command_tmp_para/hopper
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_command_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_command_tmp_para/hopper
  else
    bash $do_command_tmp_para/hopper
  fi
  rm -Rf $do_command_tmp_para
}

do_command () {
  squawk 3 " do_command $@" 
  if [[ ! $# -eq 4 ]]; then
    echo "do_command $@ <--- arguments does not equal 4!!!" 
    exit 1
  fi
  this_port=$1
  this_user=$2
  this_host=$3
  command2run=$4
  if [[ "$this_host" == "localhost" ]]; then
    squawk 5 "bash -c '$command2run'"
    bash -c "$command2run"
  else
    squawk 5 "ssh -n -p $this_port $this_user@$this_host \"bash -c '$command2run'\""
    ssh -n -p $this_port $this_user@$this_host "bash -c '$command2run'"
  fi
}

sudo_command () {
  if [[ ! $# -eq 4 ]]; then
    echo "sudo_command $@ <--- arguments does not equal 4!!!" 
    exit 1
  fi
  squawk 3 " sudo_command '$1' '$2' '$3 '$4'" 
  this_port=$1
  this_user=$2
  this_host=$3
  command2run=$4
  if [[ "$this_host" == "localhost" ]]; then
    squawk 5 "sudo bash -c '$command2run'"
    sudo bash -c "$command2run"
  else
    squawk 5 "ssh -n -p $this_port $this_user@$this_host \"$PSEUDO bash -l -c '$command2run'\""
    ssh -n -p $this_port $this_user@$this_host "$PSEUDO bash -l -c '$command2run'"
  fi
}

copy_in_parallel_to_all () {
  copy_in_to_all_tmp_para=$(mktemp -d)
  file2copy=$1
  destination=$2
  touch $copy_in_to_all_tmp_para/hopper
  squawk 3 " copy_in_parallel_to_all"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do 
    squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_provisionerPort' $file2copy $K8S_provisionerUser@$K8S_ip1:$destination"
    echo "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_provisionerPort' $file2copy $K8S_provisionerUser@$K8S_ip1:$destination"\
      >> $copy_in_to_all_tmp_para/hopper
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_in_to_all_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_in_to_all_tmp_para/hopper
  else
    bash $copy_in_to_all_tmp_para/hopper
  fi
  rm -Rf $copy_in_to_all_tmp_para
}

copy_in_parallel_to_role () {
  copy_in_to_role_tmp_para=$(mktemp -d)
  role2copy2=$1
  file2copy=$2
  destination=$3
  touch $copy_in_to_role_tmp_para/hopper
  squawk 3 " copy_in_parallel_to_role"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do 
    if [[ "$K8S_role" == "$role2copy2" ]]; then
      squawk 3 " count $countzero_do_nodes"
      squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_provisionerPort' $file2copy $K8S_provisionerUser@$K8S_ip1:$destination"
      echo "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_provisionerPort' $file2copy $K8S_provisionerUser@$K8S_ip1:$destination"\
        >> $copy_in_to_role_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_in_to_role_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_in_to_role_tmp_para/hopper
  else
    bash $copy_in_to_role_tmp_para/hopper
  fi
  rm -Rf $copy_in_to_role_tmp_para
}

copy_in_parallel_to_os () {
  copy_in_to_os_tmp_para=$(mktemp -d)
  os2copy2=$1
  file2copy=$2
  destination=$3
  touch $copy_in_to_os_tmp_para/hopper
  squawk 3 " copy_in_parallel_to_os"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do 
    if [[ "$K8S_os" == "$os2copy2" ]]; then
      squawk 3 " count $countzero_do_nodes"
      squawk 5 "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_provisionerPort' $file2copy $K8S_provisionerUser@$K8S_ip1:$destination"
      echo "rsync $KUBASH_RSYNC_OPTS 'ssh -p $K8S_provisionerPort' $file2copy $K8S_provisionerUser@$K8S_ip1:$destination"\
        >> $copy_in_to_os_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $copy_in_to_os_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $copy_in_to_os_tmp_para/hopper
  else
    bash $copy_in_to_os_tmp_para/hopper
  fi
  rm -Rf $copy_in_to_os_tmp_para
}

do_command_in_parallel_on_role () {
  do_command_on_role_tmp_para=$(mktemp -d)
  role2runiton=$1
  command2run=$2
  touch $do_command_on_role_tmp_para/hopper
  squawk 3 " do_command_in_parallel"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do 
    if [[ "$K8S_role" == "$role2runiton" ]]; then
      squawk 19 " count $countzero_do_nodes"
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"sudo bash -c '$command2run'\""
      echo "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"sudo bash -c '$command2run'\""\
        >> $do_command_on_role_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_command_on_role_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_command_on_role_tmp_para/hopper
  else
    bash $do_command_on_role_tmp_para/hopper
  fi
  rm -Rf $do_command_on_role_tmp_para
}

do_test () {
  squawk 3 " do_command_in_parallel"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do 
    echo "K8S_node=$K8S_node
K8S_role=$K8S_role
K8S_cpuCount=$K8S_cpuCount
K8S_Memory=$K8S_Memory
K8S_network1=$K8S_network1
K8S_mac1=$K8S_mac1
K8S_ip1=$K8S_ip1
K8S_provisionerHost=$K8S_provisionerHost
K8S_provisionerUser=$K8S_provisionerUser
K8S_provisionerPort=$K8S_provisionerPort
K8S_provisionerBasePath=$K8S_provisionerBasePath
K8S_os=$K8S_os
K8S_virt=$K8S_virt
K8S_network2=$K8S_network2
K8S_mac2=$K8S_mac2
K8S_ip2=$K8S_ip2
K8S_network3=$K8S_network3
K8S_mac3=$K8S_mac3
K8S_ip3=$K8S_ipv3"
  done <<< "$kubash_hosts_csv_slurped"
}

do_command_in_parallel_on_os () {
  do_command_on_os_tmp_para=$(mktemp -d)
  os2runiton=$1
  command2run=$2
  touch $do_command_on_os_tmp_para/hopper
  squawk 3 " do_command_in_parallel"
  if [[ -z "$kubash_hosts_csv_slurped" ]]; then
    hosts_csv_slurp
  fi
  while IFS="," read -r $csv_columns
  do 
    if [[ "$K8S_os" == "$os2runiton" ]]; then
      squawk 19 " count $countzero_do_nodes"
      squawk 5 "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"sudo bash -c '$command2run'\""
      echo "ssh -n -p $K8S_provisionerPort $K8S_provisionerUser@$K8S_ip1 \"sudo bash -c '$command2run'\""\
        >> $do_command_on_os_tmp_para/hopper
    fi
  done <<< "$kubash_hosts_csv_slurped"

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $do_command_on_os_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $do_command_on_os_tmp_para/hopper
  else
    bash $do_command_on_os_tmp_para/hopper
  fi
  rm -Rf $do_command_on_os_tmp_para
}

process_hosts_csv () {
  squawk 3 " process_hosts_csv"
  do_etcd
  start_etcd
  do_primary_master
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    do_masters_in_parallel
    do_nodes_in_parallel
  else
    do_masters
    do_nodes
  fi
}

prep () {
  squawk 5 " prep"
  while IFS="," read -r $csv_columns
  do
    preppy $K8S_node $K8S_ip1 $K8S_provisionerPort
  done < $KUBASH_HOSTS_CSV
}

preppy () {
  squawk 7 " preppy"
  node_name=$1
  node_ip=$2
  node_port=$3
  removestalekeys $node_ip
  ssh-keyscan -p $node_port $node_ip >> ~/.ssh/known_hosts
}

do_decom () {
  if [[ "$ANSWER_YES" == "yes" ]]; then
    decom_kvm
    rm -f $KUBASH_HOSTS_CSV
    rm -f $KUBASH_ANSIBLE_HOSTS
    rm -f $KUBASH_CLUSTER_CONFIG
  else
    read -p "This will destroy all VMs defined in the $KUBASH_HOSTS_CSV. Are you sure? [y/N] " -n 1 -r
    echo    # (optional) move to a new line
    if [[ $REPLY =~ ^[Yy]$ ]]
    then
      decom_kvm
      rm -f $KUBASH_HOSTS_CSV
      rm -f $KUBASH_ANSIBLE_HOSTS
      rm -f $KUBASH_CLUSTER_CONFIG
    fi
  fi
}

do_coreos_initialization () {
  CNI_VERSION="v0.6.0"
  RELEASE="$(curl -sSL https://dl.k8s.io/release/stable.txt)"
  CORETMP=$KUBASH_DIR/tmp
  cd $CORETMP

  do_command_in_parallel_on_os 'coreos' "mkdir -p /opt/cni/bin"
  wget -c "https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-amd64-${CNI_VERSION}.tgz"
  copy_in_parallel_to_os "coreos" $CORETMP/cni-plugins-amd64-${CNI_VERSION}.tgz /tmp/
  #rm $CORETMP/cni-plugins-amd64-${CNI_VERSION}.tgz
  do_command_in_parallel_on_os "coreos" "tar -C /opt/cni/bin -xzf /tmp/cni-plugins-amd64-${CNI_VERSION}.tgz"
  do_command_in_parallel_on_os "coreos" "rm -f /tmp/cni-plugins-amd64-${CNI_VERSION}.tgz"

  do_command_in_parallel_on_os "coreos" "mkdir -p /opt/bin"

  if [[ -e "$CORETMP/kubelet" ]]; then
    squawk 9 "kubelet has no headers and will not continue skipping for now"
  else
    wget -c https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/amd64/{kubeadm,kubelet,kubectl}
  fi
  # cd /opt/bin
  copy_in_parallel_to_os "coreos" $CORETMP/kubeadm /tmp/
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubeadm /opt/bin/"
  #rm $CORETMP/kubeadm
  copy_in_parallel_to_os "coreos" $CORETMP/kubelet /tmp/
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubelet /opt/bin/"
  #rm $CORETMP/kubelet
  copy_in_parallel_to_os "coreos" $CORETMP/kubectl /tmp/
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubectl /opt/bin/"
  #rm $CORETMP/kubectl
  do_command_in_parallel_on_os "coreos" "cd /opt/bin; chmod +x {kubeadm,kubelet,kubectl}"

  if [[ -e "$CORETMP/kubelet.service" ]]; then
    squawk 9 "already retrieved"
  else
    wget -c "https://raw.githubusercontent.com/kubernetes/kubernetes/${RELEASE}/build/debs/kubelet.service"
    sed -i 's:/usr/bin:/opt/bin:g' $CORETMP/kubelet.service
  fi
  copy_in_parallel_to_os "coreos" $CORETMP/kubelet.service /tmp/kubelet.service
  do_command_in_parallel_on_os "coreos" "mv /tmp/kubelet.service /etc/systemd/system/kubelet.service"
  rm $CORETMP/kubelet.service
  do_command_in_parallel_on_os "coreos" "mkdir -p /etc/systemd/system/kubelet.service.d"
  if [[ -e "$CORETMP/10-kubeadm.conf" ]]; then
    squawk 9 "already retrieved"
  else
    wget -c "https://raw.githubusercontent.com/kubernetes/kubernetes/${RELEASE}/build/debs/10-kubeadm.conf"
    sed -i 's:/usr/bin:/opt/bin:g' $CORETMP/10-kubeadm.conf
  fi
  copy_in_parallel_to_os "coreos" $CORETMP/10-kubeadm.conf /tmp/10-kubeadm.conf
  do_command_in_parallel_on_os "coreos" " mv /tmp/10-kubeadm.conf /etc/systemd/system/kubelet.service.d/10-kubeadm.conf"
  rm $CORETMP/10-kubeadm.conf

  do_command_in_parallel_on_os "coreos" " systemctl restart docker.service ; systemctl enable docker.service"

  #do_command_in_parallel_on_os "coreos" "systemctl unmask kubelet.service ; systemctl restart kubelet.service ; systemctl enable kubelet.service"
  do_command_in_parallel_on_os "coreos" "systemctl restart kubelet.service ; systemctl enable kubelet.service"

  #rmdir $CORETMP
}

do_openebs () {
  kubectl --kubeconfig=$KUBECONFIG create -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-operator.yaml
  kubectl --kubeconfig=$KUBECONFIG create -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-storageclasses.yaml
}

coreos_build  () {
  build_virt=$1
  target_os=$2
  CHANNEL=$3
  chkdir $KVM_builderDir
  chkdir $KVM_builderTMP

  command2run="cd $KVM_builderTMP"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="wget -c https://$CHANNEL.release.core-os.net/amd64-usr/current/coreos_production_qemu_image.img.bz2{,.sig}"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="gpg --verify coreos_production_qemu_image.img.bz2.sig"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="rm coreos_production_qemu_image.img.bz2.sig"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="bunzip2 coreos_production_qemu_image.img.bz2"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"

  TARGET_FILE="$KVM_builderTMP/coreos_production_qemu_image.img"
  DESTINATION_FILE="$KVM_builderBasePath/$target_os-$KVM_BASE_IMG"
  command2run="$MV_CMD $TARGET_FILE $DESTINATION_FILE"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
}

packer_build  () {
  build_virt=$1
  target_os=$2
  target_build=$3
  chkdir $KVM_builderDir
  chkdir $KVM_builderTMP

  if [[ $VERBOSITY -gt '1' ]]; then
    LN_CMD='ln -fsv'
  else
    LN_CMD='ln -fs'
  fi

  command2run="cd $KUBASH_DIR/pax;if [ ! -e "$KUBASH_DIR/pax/build" ]; then $LN_CMD $KVM_builderDir $KUBASH_DIR/pax/builds; fi"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"

  cd $KUBASH_DIR/pax/$target_os
  squawk 2 " Executing packer build..."

  if [[ "$debug" == "true" ]]; then
    debug_flag='-debug -on-error=ask'
    PACKER_LOG=1
  else
    debug_flag=''
    PACKER_LOG=0
  fi
  squawk 2 "TMPDIR=$KVM_builderTMP packer build -only=$build_virt $debug_flag $target_build.json"
  packer_build_cmd="packer build -only=$build_virt $debug_flag $target_build.json"
  command2run="cd $KUBASH_DIR/pax/$target_os; PACKER_LOG=$PACKER_LOG TMPDIR=$KVM_builderTMP $packer_build_cmd"
  do_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"

  TARGET_FILE=$KVM_builderDir/packer-$target_build-$build_virt/$target_build
  DESTINATION_FILE=$KVM_builderBasePath/$target_os-$KVM_BASE_IMG
  command2run="$MV_CMD $TARGET_FILE $DESTINATION_FILE"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="rmdir $KVM_builderDir/packer-$target_build-$build_virt/$target_build"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
  command2run="rmdir $KVM_builderDir/packer-$target_build-$build_virt"
  sudo_command $KVM_builderPort $KVM_builderUser $KVM_builderHost "$command2run"
}

activate_monitoring () {
  # Prometheus
  KUBECONFIG=$KUBECONFIG helm install stable/prometheus
}

build_all_in_parallel () {
  squawk 1 'Building all targets in parallel'
  $PSEUDO rm -Rf $KVM_builderTMP
  $PSEUDO rm -Rf $KVM_builderDir
  build_all_tmp_para=$(mktemp -d --suffix='.para.tmp')
  touch $build_all_tmp_para/hopper
  OS_LIST=(centos kubeadm kubeadm2ha kubespray openshift ubuntu debian coreos)
  build_count=0
  while [ "x${OS_LIST[build_count]}" != "x" ]
  do
    command2run="kubash build --target-os=${OS_LIST[build_count]} -y"
    squawk 5 "$command2run"
    echo "$command2run" >> $build_all_tmp_para/hopper
    ((++build_count))
  done

  if [[ "$VERBOSITY" -gt "9" ]] ; then
    cat $build_all_tmp_para/hopper
  fi
  if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    $PARALLEL  -j $PARALLEL_JOBS -- < $build_all_tmp_para/hopper
  else
    bash $build_all_tmp_para/hopper
  fi
  rm -Rf $build_all_tmp_para
  squawk 1 'Done Building all targets'
}

yaml2cluster () {
  yaml2cluster_tmp=$(mktemp -d)
  if [[ -z "$1" ]]; then
    echo 'yaml2cluster requires an argument'
    exit 1
  fi
  this_yaml=$1
  this_json=$yaml2cluster_tmp/this.json
  yaml2json $this_yaml > $this_json
  json2cluster $this_json
  rm $this_json
  rm -Rf $yaml2cluster_tmp
}

json2cluster () {
  json2cluster_tmp=$(mktemp -d)
  if [[ -z "$1" ]]; then
    echo 'json2cluster requires an argument'
    exit 1
  fi
  this_json=$1

  if [[ -e $KUBASH_DIR/clusters/$KUBASH_CLUSTER_NAME ]]; then
    horizontal_rule
    echo "The cluster directory already exists! $KUBASH_DIR/clusters/$KUBASH_CLUSTER_NAME"
    horizontal_rule
    exit 1
  fi

  # provision.csv
  jq -r \
    '.hosts[] | "\(.hostname),\(.role),\(.cpuCount),\(.Memory),\(.network1.network),\(.network1.mac),\(.network1.ip),\(.provisioner.Host),\(.provisioner.User),\(.provisioner.Port),\(.provisioner.BasePath),\(.os),\(.virt),\(.network2.network),\(.network2.mac),\(.network2.ip),\(.network3.network),\(.network3.mac),\(.network3.ip) "' \
    $this_json >  $json2cluster_tmp/tmp.csv

  while IFS="," read -r $csv_columns
  do
    if [[ "$K8S_mac1" == 'null' ]]; then
      K8S_mac1=$(VERBOSITY=0 kubash --verbosity=1 genmac)
    fi
    if [[ "$K8S_network2" != 'null' ]]; then
      if [[ "$K8S_mac2" == 'null' ]]; then
        K8S_mac2=$(VERBOSITY=0 kubash --verbosity=1 genmac)
      fi
    fi
    if [[ "$K8S_network3" != 'null' ]]; then
      if [[ "$K8S_mac3" == 'null' ]]; then
        K8S_mac3=$(VERBOSITY=0 kubash --verbosity=1 genmac)
      fi
    fi
    echo "$K8S_node,$K8S_role,$K8S_cpuCount,$K8S_Memory,$K8S_network1,$K8S_mac1,$K8S_ip1,$K8S_provisionerHost,$K8S_provisionerUser,$K8S_provisionerPort,$K8S_provisionerBasePath,$K8S_os,$K8S_virt,$K8S_network2,$K8S_mac2,$K8S_ip2,$K8S_network3,$K8S_mac3,$K8S_ip3" \
      >>  $json2cluster_tmp/provision.csv
  done < "$json2cluster_tmp/tmp.csv"

  rm $json2cluster_tmp/tmp.csv
  squawk 5 "$(cat $json2cluster_tmp/provision.csv)"

  # ca-data.yaml
#### BEGIN --> Indention break warning <-- BEGIN
  jq -r \
    '.ca[] | "CERT_COMMON_NAME: \(.CERT_COMMON_NAME)
CERT_COUNTRY: \(.CERT_COUNTRY)
CERT_LOCALITY: \(.CERT_LOCALITY)
CERT_ORGANISATION: \(.CERT_ORGANISATION)
CERT_STATE: \(.CERT_STATE)
CERT_ORG_UNIT: \(.CERT_ORG_UNIT)"' \
    $this_json >  $json2cluster_tmp/ca-data.yaml
#### END --> Indention break warning <-- END
  squawk 5 "$(cat $json2cluster_tmp/ca-data.yaml)"

  # net_set
  jq -r '.net_set | "\(.)" ' \
    $this_json >  $json2cluster_tmp/net_set
  squawk 7 "$(cat $json2cluster_tmp/net_set)"

  # users.csv
  jq -r '.users | to_entries[] | "\(.key),\(.value.role)"' \
    $this_json >  $json2cluster_tmp/users.csv

  $CP_CMD $KUBASH_DIR/templates/ca-csr.json $json2cluster_tmp/
  $CP_CMD $KUBASH_DIR/templates/ca-config.json $json2cluster_tmp/
  $CP_CMD $KUBASH_DIR/templates/client.json $json2cluster_tmp/

  $MV_CMD $json2cluster_tmp $KUBASH_DIR/clusters/$KUBASH_CLUSTER_NAME
}

main () {
  # save original io
  exec 3>&1 4>&2
  # Let's display everything on stderr.
  exec 1>&2

  # If cmd empty print usage
  if [[ -z "$1" ]]; then
    horizontal_rule
    squawk 5 "No Args found printing usage"
    usage
    exit 1
  fi

  squawk 5 'parse opts'

  # Execute getopt on the arguments passed to this program, identified by the special character $@
  short_opts="c:hvyn:"
  long_opts="version,oidc,clustername:,initializer:,csv:,help,yes,verbose,verbosity:,target-os:,target-build:,build-virt:,node-join-name:,node-join-user:,node-join-ip:,node-join-port:,node-join-role:,parallel:,builder:,debug"
  PARSED_OPTIONS=$(getopt -n "$0" -o "$short_opts" --long "$long_opts" -- "$@")

  #Bad arguments, something has gone wrong with the getopt command.
  if [[ $? -ne 0 ]];
  then
    horizontal_rule
    echo 'bad argruments'
    exit 1
  fi

  # A little magic, necessary when using getopt.
  eval set -- "$PARSED_OPTIONS"

  squawk 5 'loop through opts'

  opt_loop_count=1
  while true; do
    squawk 5 "$opt_loop_count $@"
    opt_loop_count=`expr $opt_loop_count + 1`
    case "$1" in
      -h|--help)
        print_help=true
        shift;;
      --debug)
        debug=true
        shift;;
      --version)
        echo "Kubash, version $KUBASH_VERSION"
        exit 0
        shift;;
      -y|--yes)
  ANSWER_YES=yes
        shift;;
      -n|--clustername)
        KUBASH_CLUSTER_NAME="$2"
        KUBASH_CLUSTER_DIR=$KUBASH_CLUSTERS_DIR/$KUBASH_CLUSTER_NAME
        KUBASH_CLUSTER_CONFIG=$KUBASH_CLUSTER_DIR/config
        export KUBECONFIG=$KUBASH_CLUSTER_CONFIG
        KUBASH_HOSTS_CSV=$KUBASH_CLUSTER_DIR/hosts.csv
        KUBASH_ANSIBLE_HOSTS=$KUBASH_CLUSTER_DIR/hosts
        KUBASH_PROVISION_CSV=$KUBASH_CLUSTER_DIR/provision.csv
        KUBASH_USERS_CSV=$KUBASH_CLUSTER_DIR/users.csv
        net_set
        shift 2 ;;
      -c|--csv)
        KUBASH_HOSTS_CSV="$2"
        RAISON=true
        shift 2 ;;
      --initializer)
        initializer="$2"
        shift 2 ;;
      --parallel)
        PARALLEL_JOBS="$2"
        shift 2 ;;
      --node-join-name)
        node_join_name="$2"
        shift 2 ;;
      --node-join-user)
        node_join_user="$2"
        shift 2 ;;
      --node-join-ip)
        node_join_ip="$2"
        shift 2 ;;
      --node-join-port)
        node_join_port="$2"
        shift 2 ;;
      --node-join-role)
        node_join_role="$2"
        shift 2 ;;
      --target-os)
  target_os="$2"
        shift 2 ;;
      --target-build)
  target_build="$2"
        shift 2 ;;
      --build-virt)
  build_virt="$2"
        shift 2 ;;
      -v|--verbose)
        VERBOSITY=`expr $VERBOSITY + 1`
        squawk 2 " verbosity is now $VERBOSITY"
        shift;;
      --verbosity)
        VERBOSITY=`expr $VERBOSITY + $2`
        squawk 2 " verbosity is now $VERBOSITY"
        shift 2 ;;
      --oidc)
        KUBASH_OIDC_AUTH=true
        squawk 2 "OIDC Auth turned on"
        shift;;
      --builder)
        builder=$2
        shift 2 ;;
      --)
        shift
        break;;
    esac
  done

  if [[ $VERBOSITY -gt '1' ]]; then
    KUBASH_RSYNC_OPTS='-H -azve'
    if [[ "$ANSWER_YES" == "yes" ]]; then
      MV_CMD='mv -v'
      CP_CMD='cp -v'
    else
      MV_CMD='mv -iv'
      CP_CMD='cp -iv'
    fi
  else
    if [[ "$ANSWER_YES" == "yes" ]]; then
      MV_CMD='mv'
      CP_CMD='cp'
    else
      MV_CMD='mv -i'
      CP_CMD='cp -i'
    fi
  fi

  chkdir $KUBASH_CLUSTERS_DIR

  squawk 7 "Check args"

  if [[ $# -eq 0 ]]; then
    horizontal_rule
    usage
    exit 1
  fi
  RAISON=$1
  squawk 5 "Raison set to $RAISON"
  shift

  checks

  if [[ $RAISON = "false" || "$RAISON" = "help" ]]; then
    horizontal_rule
    usage
    exit 1
  fi

  if [[ $RAISON == "auto" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
  squawk 1 "Full auto engaged"
  kubash provision \
          -n $KUBASH_CLUSTER_NAME
  kubash ping \
          -n $KUBASH_CLUSTER_NAME
  kubash init \
          -n $KUBASH_CLUSTER_NAME
  sleep 10
  kubash openebs \
          -n $KUBASH_CLUSTER_NAME
  sleep 10
  kubash tiller  \
          -n $KUBASH_CLUSTER_NAME
  sleep 10
  kubash ingress \
          -n $KUBASH_CLUSTER_NAME
  squawk 1 "Full auto finished"
      exit
  elif [[ $RAISON == "grab" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
        do_grab
  elif [[ $RAISON == "grant" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    if [[ $# -eq 0 ]]; then
      grant_users
    elif [[ $# -eq 2 ]]; then
      grant $1 $2
    else
      horizontal_rule
      usage
      exit 1
    fi
    exit 0
  elif [[ $RAISON == "openebs" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
        do_openebs
  elif [[ $RAISON == "genmac" ]]; then
    genmac
  elif [[ $RAISON == "dry" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
        VERBOSITY=`expr $VERBOSITY + 1`
        do_test
  elif [[ $RAISON == "hosts" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    write_ansible_hosts
    exit 0
  elif [[ $RAISON == "dotfiles" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    squawk 5 'Adjusting dotfiles'
    dotfiles_install
    exit 0
  elif [[ $RAISON == "show" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    VERBOSITY=`expr $VERBOSITY + 10`
    read_csv
  elif [[ $RAISON == "test" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    VERBOSITY=`expr $VERBOSITY + 10`
    do_test
  elif [[ $RAISON == "ping" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    if [[ "$PARALLEL_JOBS" -gt "1" ]] ; then
    ping_in_parallel
    else
      ping
    fi
  elif [[ $RAISON == "aping" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    write_ansible_hosts
    ansible-ping
  elif [[ $RAISON == "monitoring" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    activate_monitoring
  elif [[ $RAISON == "prep" ]]; then
    prep
  elif [[ $RAISON == "provision" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      provision_usage
      exit 1
    fi
    copy_image_to_all_provisioning_hosts
    provisioner
    squawk 1 "wating on hosts to come up"
    sleep 33
    refresh_network_addresses
    prep
    remove_vagrant_user
    hostname_in_parallel
  elif [[ $RAISON == "hostnamer" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    hostname_in_parallel
  elif [[ $RAISON == "decommission" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      decom_usage
      exit 1
    fi
    do_decom
  elif [[ $RAISON == "demo" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    demo
  elif [[ $RAISON == "ingress" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    do_nginx_ingress $KUBASH_INGRESS_NAME
  elif [[ $RAISON == "masters" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    DO_MASTER_JOIN=true
    initialize
    do_grab
  elif [[ $RAISON == "nodes" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    DO_NODE_JOIN=true
    initialize
    do_grab
  elif [[ $RAISON == "init" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    if [[ -z "$initializer" ]]; then
     initializer=kubeadm
      DO_NODE_JOIN=true
      DO_MASTER_JOIN=true
      kubeadm_reset
      initialize
      do_grab
    elif [[ "$initializer" == "kubespray" ]]; then
      kubespray_initialize
      exit 0
    elif [[ "$initializer" == "openshift" ]]; then
      openshift_initialize
      exit 0
    elif [[ "$initializer" == "kubeadm2ha" ]]; then
      kubeadm2ha_initialize
      exit 0
    fi
  elif [[ $RAISON == "extras" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    do_tiller
  elif [[ $RAISON == "yaml2cluster" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    yaml2cluster $@
  elif [[ $RAISON == "json2cluster" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    json2cluster $@
  elif [[ $RAISON == "tiller" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      init_usage
      exit 1
    fi
    do_tiller
  elif [[ $RAISON == "refresh" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    refresh_network_addresses
  elif [[ $RAISON == "armor_fix" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    apparmor_fix_all_provisioning_hosts
  elif [[ $RAISON == "prepetcd" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    prep_etcd $@
  elif [[ $RAISON == "copy" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    copy_image_to_all_provisioning_hosts
  elif [[ $RAISON == "reset" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    kubeadm_reset
  elif [[ $RAISON == "build-all" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      usage
      exit 1
    fi
    build_all_in_parallel
  elif [[ $RAISON == "build" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      build_usage
      exit 1
    fi
    if [[ -z "$builder" ]]; then
      builder='packer'
    fi
    if [[ -z "$target_os" ]]; then
      target_os=ubuntu
      if [[ -z "$target_build" ]]; then
        target_build=ubuntu-16.04-amd64
      fi
    elif [[ "$target_os" == "ubuntu" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=ubuntu-16.04-amd64
      fi
    elif [[ "$target_os" == "debian" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=debian-9.3-amd64
      fi
    elif [[ "$target_os" == "centos" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=centos-7.4-x86_64
      fi
    elif [[ "$target_os" == "openshift" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=openshift-7.4-x86_64
      fi
    elif [[ "$target_os" == "kubespray" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=kubespray-7.4-x86_64
      fi
    elif [[ "$target_os" == "kubeadm2ha" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=kubeadm2ha-7.4-x86_64
      fi
    elif [[ "$target_os" == "kubeadm" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=kubeadm-7.4-x86_64
      fi
    elif [[ "$target_os" == "fedora" ]]; then
      if [[ -z "$target_build" ]]; then
        target_build=fedora-27-x86_64
      fi
    elif [[ "$target_os" == "coreos" ]]; then
      #override packer atm
      builder=coreos
      if [[ $builder == "packer" ]]; then
        horizontal_rule
        echo 'packer not supported for coreos at this time'
        exit 1
      elif [[ $builder == "coreos" ]]; then
        if [[ -z "$target_build" ]]; then
    squawk 5 "Setting coreos channel to stable"
          target_build=stable
        fi
      fi
    fi
    if [[ -z "$target_build" ]]; then
      target_build=ubuntu-16.04-amd64
    fi
    if [[ -z "$build_virt" ]]; then
      build_virt=qemu
    fi
    if [[ $builder == "packer" ]]; then
      squawk 5 "packer_build $build_virt $target_os $target_build"
      packer_build $build_virt $target_os $target_build
    elif [[ $builder == "coreos" ]]; then
      squawk 5 "coreos_build $build_virt $target_os $target_build"
      coreos_build $build_virt $target_os $target_build
    elif [[ $builder == "veewee" ]]; then
      squawk 2 " Executing vee wee build..."
      # veewee_build
      horizontal_rule
      echo 'VeeWee support not built yet :('
      exit 1
    else
      horizontal_rule
      echo 'builder not recognized'
      exit 1
    fi
    exit 0
  elif [[ $RAISON == "node_join" ]]; then
    if [[ $print_help == "true" ]]; then
      horizontal_rule
      node_usage
      exit 1
    fi
    if [[ -z "$node_join_name" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-name option'
      exit 1
    fi
    if [[ -z "$node_join_ip" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-ip option'
      exit 1
    fi
    if [[ -z "$node_join_user" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-user option'
      exit 1
    fi
    if [[ -z "$node_join_port" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-port option'
      exit 1
    fi
    if [[ -z "$node_join_role" ]]; then
      horizontal_rule
      echo 'you must specify the --node-join-role option'
      exit 1
    fi
    if [[ $node_join_role == "node" ]]; then
      squawk 2 " Executing node join..."
      DO_NODE_JOIN=true
      node_join $node_join_name $node_join_ip $node_join_user $node_join_port
    elif [[ $node_join_role == "master" ]]; then
      squawk 2 " Executing master join..."
      DO_MASTER_JOIN=true
      master_join $node_join_name $node_join_ip $node_join_user $node_join_port
    fi
    exit 0
  elif [[ $RAISON == "true" ]]; then
    squawk 8 'passthru'
  else
    horizontal_rule
    echo "Command \"$RAISON\" unknown!!! printing usage."
    horizontal_rule
    sleep 2
    usage
    exit 1
  fi

  if [[ $print_help == "true" ]]; then
    horizontal_rule
    usage
    exit 1
  fi

  exit 0
  # End main block
}

main "$@"
